{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import create_table\n",
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "# uri = 'mysql+pymysql://root:password@localhost:3308/news_oil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from models import db_connect,create_table\n",
    "from check_pro import return_no_processed_df\n",
    "from utils import wash_process, extract_img_links, read_xlsx, gen_keywords_pair, match_keyword, match_country_region, \\\n",
    "    chopoff, match_company,rematch_keywords,match_topic,match_storage,get_mark_urls,mark_url,add_same_key,\\\n",
    "    remove_intell_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    start_time = time.time()\n",
    "    table_name = ['news_oil_oe']\n",
    "    table_name_pro = ['news_oil_oe_pro']\n",
    "    engine = db_connect()\n",
    "    create_table(engine)\n",
    "    cate_file = 'input_data/categories_list.xlsx'\n",
    "    df_dicts = read_xlsx(cate_file)\n",
    "\n",
    "    #==================== generate all the keyword and category pair==================================\n",
    "    # country section\n",
    "    df_dicts['country'].columns = ['region', 'country', 'key_words_chinese', 'key_words_english']  ## rename cols\n",
    "    country_keywords_pair = gen_keywords_pair(df_dicts['country'], 2, [3, 4])\n",
    "    # region section\n",
    "    df_dicts['region'].columns = ['region', 'chinese_keywords', 'english_keywords']\n",
    "    region_df = df_dicts['region']\n",
    "    region_df.columns = ['region', 'chinese_keywords', 'english_keywords']\n",
    "    region_df['chinese_keywords'] = region_df['chinese_keywords'].apply(lambda x: x.split('，')[0])\n",
    "    region_df['english_keywords'] = region_df['english_keywords'].apply(lambda x: x.split('、')[0])\n",
    "    state_keywords_pair = gen_keywords_pair(region_df, 1, [2, 3])\n",
    "    ##genreate the country-region dictionay data for adding the region data from country list\n",
    "    countries = df_dicts['country']['country'].values\n",
    "    regions = df_dicts['country']['region'].values\n",
    "    country_region = {}\n",
    "    for country, region in zip(countries, regions):\n",
    "        country_region[country] = region\n",
    "    ## company section\n",
    "    df_company = df_dicts['company']\n",
    "    df_company.columns = ['country', 'business', 'company', 'keywords']\n",
    "    df_company['keywords'] = df_company['keywords']. \\\n",
    "        apply(lambda x: chopoff(x)). \\\n",
    "        apply(lambda x: x.strip()).apply(lambda x: x.strip().split('、'))\n",
    "    company_keyword_pair = {}\n",
    "    companies = df_company['company'].values\n",
    "    keywords = df_company['keywords'].values\n",
    "    for company, keyword in zip(companies, keywords):\n",
    "        company_keyword_pair[company] = keyword\n",
    "    # print(company_keyword)\n",
    "    company_business = {}\n",
    "    companies = df_company['company'].values\n",
    "    business = df_company['business'].values\n",
    "    for company, business in zip(companies, business):\n",
    "        company_business[company] = business\n",
    "\n",
    "    company_country = {}\n",
    "    companies = df_company['company'].values\n",
    "    counties = df_company['country'].values\n",
    "    for company, country in zip(companies, counties):\n",
    "        company_country[company] = country\n",
    "\n",
    "    ## topic section\n",
    "\n",
    "    df_dicts['subcategory'].columns = ['subset', 'topic', 'chinese_keywords', 'english_keywords']\n",
    "    df_cate = df_dicts['subcategory']\n",
    "    df_cate.iloc[28].topic = '其他能源类型'\n",
    "    df_cate.dropna(inplace=True)\n",
    "    df_cate['english_keywords'] = df_cate['english_keywords'].astype('str').apply(lambda x: x.split('、'))\n",
    "    df_cate['chinese_keywords'] = df_cate['chinese_keywords'].astype('str').apply(lambda x: x.split('、'))\n",
    "\n",
    "    ## rename all the chinese and english keywords\n",
    "    geologies = df_cate.iloc[4].chinese_keywords\n",
    "    smart_geology = df_cate.iloc[16].chinese_keywords\n",
    "    drilling = df_cate.iloc[5].chinese_keywords\n",
    "    smart_drilling = df_cate.iloc[17].chinese_keywords\n",
    "    well_test = df_cate.iloc[6].chinese_keywords\n",
    "    smart_test = df_cate.iloc[18].chinese_keywords\n",
    "    production = df_cate.iloc[7].chinese_keywords\n",
    "    smart_production = df_cate.iloc[19].chinese_keywords\n",
    "    transport = df_cate.iloc[12].chinese_keywords + \\\n",
    "                df_cate.iloc[13].chinese_keywords + \\\n",
    "                df_cate.iloc[14].chinese_keywords + \\\n",
    "                df_cate.iloc[15].chinese_keywords\n",
    "    smart_transport = df_cate.iloc[20].chinese_keywords\n",
    "\n",
    "    geologies_english = df_cate.iloc[4].english_keywords\n",
    "    smart_geology_english = df_cate.iloc[16].english_keywords\n",
    "    drilling_english = df_cate.iloc[5].english_keywords\n",
    "    smart_drilling_english = df_cate.iloc[17].english_keywords\n",
    "    well_test_english = df_cate.iloc[6].english_keywords\n",
    "    smart_test_english = df_cate.iloc[18].english_keywords\n",
    "    production_english = df_cate.iloc[7].english_keywords\n",
    "    smart_production_english = df_cate.iloc[19].english_keywords\n",
    "    transport_english = df_cate.iloc[12].english_keywords + \\\n",
    "                        df_cate.iloc[13].english_keywords + \\\n",
    "                        df_cate.iloc[14].english_keywords + \\\n",
    "                        df_cate.iloc[15].english_keywords\n",
    "    smart_transport_english = df_cate.iloc[20].english_keywords\n",
    "\n",
    "    ##generate mixed keywords\n",
    "    smart_geologies_chinese_mixed = rematch_keywords(geologies, smart_geology)\n",
    "    smart_drill_chinese_mixed = rematch_keywords(drilling, smart_drilling)\n",
    "    smart_well_test_chinese_mixed = rematch_keywords(well_test, smart_test)\n",
    "    smart_production_chinese_mixed = rematch_keywords(production, smart_production)\n",
    "    smart_transport_chinese_mixed = rematch_keywords(transport, smart_transport)\n",
    "    smart_geologies_english_mixed = rematch_keywords(geologies_english, smart_geology_english)\n",
    "    smart_drill_english_mixed = rematch_keywords(drilling_english, smart_drilling_english)\n",
    "    smart_well_test_english_mixed = rematch_keywords(well_test_english, smart_test_english)\n",
    "    smart_production_english_mixed = rematch_keywords(production_english, smart_production_english)\n",
    "    smart_transport_english_mixed = rematch_keywords(transport_english, smart_transport_english)\n",
    "    ## change the keywords with such mixed ones\n",
    "    df_cate.iloc[16].chinese_keywords = smart_geologies_chinese_mixed\n",
    "    df_cate.iloc[17].chinese_keywords = smart_drill_chinese_mixed\n",
    "    df_cate.iloc[18].chinese_keywords = smart_well_test_chinese_mixed\n",
    "    df_cate.iloc[19].chinese_keywords = smart_production_chinese_mixed\n",
    "    df_cate.iloc[20].chinese_keywords = smart_transport_chinese_mixed\n",
    "    df_cate.iloc[16].english_keywords = smart_geologies_english_mixed\n",
    "    df_cate.iloc[17].english_keywords = smart_drill_english_mixed\n",
    "    df_cate.iloc[18].english_keywords = smart_well_test_english_mixed\n",
    "    df_cate.iloc[19].english_keywords = smart_production_english_mixed\n",
    "    df_cate.iloc[20].english_keywords = smart_transport_english_mixed\n",
    "\n",
    "    df_cate['keywords'] = df_cate['chinese_keywords'] + df_cate['english_keywords']\n",
    "    ## preparing the category-keywords pair\n",
    "    topic_keywords = {}\n",
    "    topics = df_cate['topic'].values\n",
    "    keywords = df_cate['keywords'].values\n",
    "    for topic, keyword in zip(topics, keywords):\n",
    "        topic_keywords[topic] = keyword\n",
    "    topic_subcategory = {}\n",
    "\n",
    "    topics = df_cate['topic'].values\n",
    "    subcategory = df_cate['subset'].values\n",
    "    for topic, keyword in zip(topics, subcategory):\n",
    "        topic_subcategory[topic] = keyword\n",
    "    topic_subcategory['石油公司'] = '能源公司'\n",
    "    topic_subcategory['油服公司'] = '能源公司'\n",
    "    ## field section\n",
    "    df_dicts['field'].columns = ['field', 'keyword']\n",
    "    df_field = df_dicts['field']\n",
    "    df_field['merged_keywords'] = df_field['keyword']. \\\n",
    "        apply(lambda x: chopoff(x)). \\\n",
    "        apply(lambda x: x.strip()).apply(lambda x: x.strip().split('、'))\n",
    "    field_keyword = {}\n",
    "    field = df_field['field'].values\n",
    "    keyword = df_field['merged_keywords'].values\n",
    "    for fie, key in zip(field, keyword):\n",
    "        field_keyword[fie] = key\n",
    "    field_keyword['MESSLAH'] = ['MESSLAH', 'MESSLA'] ## some correction of data\n",
    "    ## storage section\n",
    "    df_dicts['storage'].columns = ['country', 'storage', 'keyword']\n",
    "    df_storage = df_dicts['storage']\n",
    "    storage_keyword = {}\n",
    "    storage = df_storage['storage'].values\n",
    "    keyword = df_storage['keyword'].values\n",
    "    for stor, key in zip(storage, keyword):\n",
    "        if re.search('/', key):\n",
    "            storage_keyword[stor] = key.split('/')\n",
    "        else:\n",
    "            storage_keyword[stor] = [key.strip()]\n",
    "    storage_keyword['MOLDOVA  (FALTICENI)'] = 'MOLDOVA'\n",
    "    storage_keyword['CHESHIRE (HOLFORD GS)'] = 'Cheshire'\n",
    "    storage_keyword['HILL TOP FARM  (CHESHIRE EXISTING)'] = 'Hill Top Farm'\n",
    "    storage_keyword['HILL TOP FARM  (CHESHIRE EXPANSION)'] = 'Hill Top Farm'\n",
    "    storage_keyword['KIRK RANCH  (BOBBY BURNS #1)'] = 'KIRK RANCH'\n",
    "    storage_keyword['CLEMENS NE  (FRIO B)'] = 'CLEMENS,N.E.'\n",
    "    ## get country according to the storage\n",
    "    storage_country = {}\n",
    "    storage = df_storage['storage'].values\n",
    "    country = df_storage['country'].values\n",
    "    for stor, coun in zip(storage, country):\n",
    "        storage_country[stor] = coun\n",
    "\n",
    "    mark_urls = get_mark_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage_country  #dictionary of one-one\n",
    "# country_region\n",
    "# company_business\n",
    "# topic_subcategory\n",
    "# company_country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_keywords_pair\n",
    "# state_keywords_pair\n",
    "# company_keyword_pair\n",
    "# topic_keywords\n",
    "# field_keyword\n",
    "# storage_keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ==================== reach the process section for each category==================================\n",
    "\n",
    "    for table_pair in zip(table_name, table_name_pro):\n",
    "        pre_data = return_no_processed_df(table_pair[0], table_pair[1], engine)\n",
    "        print(pre_data.head())\n",
    "#         print(pre_data.head(),pre_data.info(),type(pre_data))\n",
    "        if len(pre_data) == 0:  ## no dataframe needed to be processed\n",
    "            break\n",
    "        else:\n",
    "            raw_df = pre_data.iloc[0:1]  ##make the dataframe name consistent\n",
    "            # print(raw_df['url'][0],raw_df['content'],raw_df['content'][0],type(raw_df['content'][0]))\n",
    "            # break\n",
    "            raw_df['new_content'] = raw_df['content'].apply(lambda x: wash_process(x))\n",
    "            raw_df['img_urls_new'] = raw_df['new_content'].apply(lambda x: extract_img_links(x))\n",
    "            # raw_df['new_content'] =\n",
    "            raw_df['format_pub_time'] = raw_df['pub_time']\\\n",
    "            .apply(lambda x: datetime.strptime(x, \"%B %d, %Y\").strftime('%Y/%m/%d'))\\\n",
    "            .apply(lambda x:datetime.strptime(x,\"%Y/%m/%d\"))\n",
    "            raw_df['format_crawl_time'] = raw_df['crawl_time'].apply(lambda x: x.strip()[:10]) \\\n",
    "                .apply(lambda x: datetime.strptime(x, \"%m/%d/%Y\").strftime('%Y/%m/%d')) \\\n",
    "                .apply(lambda x:datetime.strptime(x,\"%Y/%m/%d\"))\n",
    "#             print(raw_df.head())\n",
    "\n",
    "            df = raw_df[['id', 'author', 'categories', 'preview_img_link',\n",
    "                             'title', 'url', 'new_content', 'img_urls_new',\n",
    "                             'format_pub_time', 'format_crawl_time']]\n",
    "            ## create first checkpoint\n",
    "            ## country keyword section\n",
    "            df['country_keyword'] = df['new_content'].astype('str'). \\\n",
    "                apply(lambda x: match_keyword(x, country_keywords_pair))\n",
    "            ## region keyword sections\n",
    "            ## perform the matching according to the region keywords\n",
    "            df['region_keywords'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_keyword(x, state_keywords_pair))\n",
    "\n",
    "            ## determin the region according to the country keyword\n",
    "            df['regions_country'] = df['country_keyword'] \\\n",
    "                .apply(lambda x: match_country_region(x, country_region))\n",
    "            print('reach to process company section')\n",
    "            ## company sections\n",
    "            df['company_keyword'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_company(x, company_keyword_pair))\n",
    "            df['business_company'] = df['company_keyword']. \\\n",
    "                apply(lambda x: match_country_region(x, company_business))\n",
    "            df['country_matched_by_company'] = df['company_keyword']. \\\n",
    "                apply(lambda x: match_country_region(x, company_country))\n",
    "\n",
    "            ## topic section\n",
    "            df['topic_keyword'] = df['new_content'].astype('str').apply(lambda x: match_topic(x, topic_keywords))\n",
    "            df['topic_keyword'] = df['business_company'] + df['topic_keyword']\n",
    "            df['subcategory_by_topic'] = df['topic_keyword']. \\\n",
    "                apply(lambda x: match_country_region(x, topic_subcategory))\n",
    "\n",
    "            ##field section\n",
    "            df['field_keyword'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_company(x, field_keyword))\n",
    "\n",
    "            ## storage section\n",
    "            df['storage_keyword'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_storage(x, storage_keyword))\n",
    "            df['country_storage'] = df['storage_keyword'] \\\n",
    "                .apply(lambda x: match_country_region(x, storage_country))\n",
    "            ## mark or not\n",
    "            df['mark_note_by_url'] = df['url'].apply(lambda x: mark_url(x, mark_urls))\n",
    "\n",
    "            print('reach to post process of data')\n",
    "            ##post process\n",
    "            df['regions'] = df['region_keywords'] + df['regions_country']\n",
    "            df['country'] = df['country_keyword']\n",
    "            df['company_merged'] = df['company_keyword'].apply(lambda x: add_same_key(x))\n",
    "            df['regions_merged'] = df['regions'].apply(lambda x: add_same_key(x))\n",
    "            df['country_merged'] = df['country'].apply(lambda x: add_same_key(x))\n",
    "            df['topic_merged'] = df['topic_keyword'].apply(lambda x: add_same_key(x))\n",
    "            df['subcategory_merged'] = df['subcategory_by_topic'].apply(lambda x: add_same_key(x))\n",
    "            df['country_matched_by_company_merged'] = df['country_matched_by_company'].apply(lambda x: add_same_key(x))\n",
    "\n",
    "            df['new_content'] = raw_df['new_content'] \\\n",
    "                .apply(lambda x: '\\n'.join([str(ele).strip() for ele in x]))\n",
    "\n",
    "            df['topic_merged'] = df['topic_merged'].astype('str').apply(lambda x: remove_intell_topic(x))\n",
    "            df['topic_merged'] = df['topic_merged'].astype('str')\n",
    "            spend_time = round(time.time() -start_time,1)\n",
    "#             print('spend time',spend_time,' to process data',df.info())\n",
    "            df['source'] = 'www.oedigital.com'\n",
    "            df['abstracts'] = df['title']\n",
    "\n",
    "            result = df[['source', 'title', 'abstracts', 'preview_img_link', 'url', 'format_pub_time',\n",
    "                         'author', 'new_content', 'categories',\n",
    "                         'img_urls_new', 'format_crawl_time', 'regions_merged',\n",
    "                         'country_merged', 'company_keyword', 'country_matched_by_company_merged',\n",
    "                         'subcategory_merged', 'topic_merged', 'field_keyword', 'storage_keyword', 'mark_note_by_url'\n",
    "                         ]]\n",
    "            result['orig_id']=df['id']\n",
    "#             result.index =df.index\n",
    "#             print('the column name of result is',result.columns)\n",
    "            # print(result.head(),result.columns,result.info(),result[0:1].values)\n",
    "            result['preview_img_link'] = result['preview_img_link'].astype('str')\n",
    "            result['img_urls_new'] = result['img_urls_new'].astype('str')\n",
    "            result['regions_merged'] = result['regions_merged'].astype('str')\n",
    "            result['country_merged'] = result['country_merged'].astype('str')\n",
    "            result['company_keyword'] = result['company_keyword'].astype('str')\n",
    "            result['country_matched_by_company_merged'] = result['country_matched_by_company_merged'].astype('str')\n",
    "            result['subcategory_merged'] = result['subcategory_merged'].astype('str')\n",
    "            result['field_keyword'] = result['field_keyword'].astype('str')\n",
    "            result['storage_keyword'] = result['storage_keyword'].astype('str')\n",
    "            result['mark_note_by_url'] = result['mark_note_by_url'].astype('str')\n",
    "            # test = result[0:1].values\n",
    "#             print(result.info())\n",
    "#             result.to_csv('oe_backup.csv')\n",
    "            # print(result.iloc[0:1].values)\n",
    "#             print(result.columns)\n",
    "#             result_post =pd.read_csv('oe_backup.csv')\n",
    "\n",
    "\n",
    "            result.to_sql(table_pair[1],engine,if_exists='append',index=False)\n",
    "#             result_post.to_sql('test_table_1',engine,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
