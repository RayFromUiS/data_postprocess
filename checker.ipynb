{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import create_table\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "uri = 'mysql+pymysql://root:jinzheng1706@139.198.191.224:3308/news_oil'\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models import OilAndGas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(pymysql.err.OperationalError) (2013, 'Lost connection to MySQL server during query ([Errno 60] Operation timed out)')\n[SQL: SELECT oil_and_gas_pro.id AS oil_and_gas_pro_id, oil_and_gas_pro.orig_id AS oil_and_gas_pro_orig_id, oil_and_gas_pro.source AS oil_and_gas_pro_source, oil_and_gas_pro.title AS oil_and_gas_pro_title, oil_and_gas_pro.abstracts AS oil_and_gas_pro_abstracts, oil_and_gas_pro.preview_img_link AS oil_and_gas_pro_preview_img_link, oil_and_gas_pro.url AS oil_and_gas_pro_url, oil_and_gas_pro.format_pub_time AS oil_and_gas_pro_format_pub_time, oil_and_gas_pro.author AS oil_and_gas_pro_author, oil_and_gas_pro.new_content AS oil_and_gas_pro_new_content, oil_and_gas_pro.categories AS oil_and_gas_pro_categories, oil_and_gas_pro.img_urls_new AS oil_and_gas_pro_img_urls_new, oil_and_gas_pro.format_crawl_time AS oil_and_gas_pro_format_crawl_time, oil_and_gas_pro.regions_merged AS oil_and_gas_pro_regions_merged, oil_and_gas_pro.country_merged AS oil_and_gas_pro_country_merged, oil_and_gas_pro.company_keyword AS oil_and_gas_pro_company_keyword, oil_and_gas_pro.country_matched_by_company_merged AS oil_and_gas_pro_country_matched_by_company_merged, oil_and_gas_pro.subcategory_merged AS oil_and_gas_pro_subcategory_merged, oil_and_gas_pro.topic_merged AS oil_and_gas_pro_topic_merged, oil_and_gas_pro.field_keyword AS oil_and_gas_pro_field_keyword, oil_and_gas_pro.storage_keyword AS oil_and_gas_pro_storage_keyword, oil_and_gas_pro.mark_note_by_url AS oil_and_gas_pro_mark_note_by_url \nFROM oil_and_gas_pro \nWHERE oil_and_gas_pro.url = %(url_1)s \n LIMIT %(param_1)s]\n[parameters: {'url_1': 'https://www.oilandgas360.com/1-3-million-new-u-s-oil-gas-jobs-2030-api/', 'param_1': 1}]\n(Background on this error at: http://sqlalche.me/e/13/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(self, num_bytes)\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1278\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_query_result\u001b[0;34m(self, unbuffered)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMySQLResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m             \u001b[0mfirst_packet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0mpacket_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0;31m#if DEBUG: dump_packet(packet_header)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(self, num_bytes)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 raise err.OperationalError(\n\u001b[0m\u001b[1;32m    690\u001b[0m                     \u001b[0mCR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCR_SERVER_LOST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (2013, 'Lost connection to MySQL server during query ([Errno 60] Operation timed out)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-d2e5b10973ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOilAndGas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOilAndGas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtest_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3395\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3396\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3397\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3399\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3169\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3170\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3171\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3172\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoflush\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_populate_existing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3502\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autoflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3503\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_and_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m_execute_and_instances\u001b[0;34m(self, querycontext)\u001b[0m\n\u001b[1;32m   3526\u001b[0m         )\n\u001b[1;32m   3527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerycontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3529\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquerycontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquerycontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             )\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1125\u001b[0m             )\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1128\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_compiled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1318\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1509\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   1512\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1275\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1278\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m                     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogateescape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_query_result\u001b[0;34m(self, unbuffered)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMySQLResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_status\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m             \u001b[0mfirst_packet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst_packet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ok_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mbuff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0mpacket_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0;31m#if DEBUG: dump_packet(packet_header)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(self, num_bytes)\u001b[0m\n\u001b[1;32m    687\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 raise err.OperationalError(\n\u001b[0m\u001b[1;32m    690\u001b[0m                     \u001b[0mCR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCR_SERVER_LOST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \"Lost connection to MySQL server during query (%s)\" % (e,))\n",
      "\u001b[0;31mOperationalError\u001b[0m: (pymysql.err.OperationalError) (2013, 'Lost connection to MySQL server during query ([Errno 60] Operation timed out)')\n[SQL: SELECT oil_and_gas_pro.id AS oil_and_gas_pro_id, oil_and_gas_pro.orig_id AS oil_and_gas_pro_orig_id, oil_and_gas_pro.source AS oil_and_gas_pro_source, oil_and_gas_pro.title AS oil_and_gas_pro_title, oil_and_gas_pro.abstracts AS oil_and_gas_pro_abstracts, oil_and_gas_pro.preview_img_link AS oil_and_gas_pro_preview_img_link, oil_and_gas_pro.url AS oil_and_gas_pro_url, oil_and_gas_pro.format_pub_time AS oil_and_gas_pro_format_pub_time, oil_and_gas_pro.author AS oil_and_gas_pro_author, oil_and_gas_pro.new_content AS oil_and_gas_pro_new_content, oil_and_gas_pro.categories AS oil_and_gas_pro_categories, oil_and_gas_pro.img_urls_new AS oil_and_gas_pro_img_urls_new, oil_and_gas_pro.format_crawl_time AS oil_and_gas_pro_format_crawl_time, oil_and_gas_pro.regions_merged AS oil_and_gas_pro_regions_merged, oil_and_gas_pro.country_merged AS oil_and_gas_pro_country_merged, oil_and_gas_pro.company_keyword AS oil_and_gas_pro_company_keyword, oil_and_gas_pro.country_matched_by_company_merged AS oil_and_gas_pro_country_matched_by_company_merged, oil_and_gas_pro.subcategory_merged AS oil_and_gas_pro_subcategory_merged, oil_and_gas_pro.topic_merged AS oil_and_gas_pro_topic_merged, oil_and_gas_pro.field_keyword AS oil_and_gas_pro_field_keyword, oil_and_gas_pro.storage_keyword AS oil_and_gas_pro_storage_keyword, oil_and_gas_pro.mark_note_by_url AS oil_and_gas_pro_mark_note_by_url \nFROM oil_and_gas_pro \nWHERE oil_and_gas_pro.url = %(url_1)s \n LIMIT %(param_1)s]\n[parameters: {'url_1': 'https://www.oilandgas360.com/1-3-million-new-u-s-oil-gas-jobs-2030-api/', 'param_1': 1}]\n(Background on this error at: http://sqlalche.me/e/13/e3q8)"
     ]
    }
   ],
   "source": [
    "t = session.query(OilAndGas).filter(OilAndGas.url==test_url).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = 'https://www.oilandgas360.com/1-3-million-new-u-s-oil-gas-jobs-2030-api/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.oilandgas360.com/1-3-million-new-u-s-oil-gas-jobs-2030-api/'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_url.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url ='https://www.oilandgas360.com/ \\\n",
    "new-york-hedge-fund-buys-stake-in-noble-energy-eyes-to-nix-chevron-acquisition/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(uri)\n",
    "create_table(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from bs4 import Tag\n",
    "import requests as req\n",
    "from datetime import datetime\n",
    "from models import db_connect,create_table\n",
    "from check_pro import return_no_processed_df\n",
    "from utils import wash_process, extract_img_links, read_xlsx, gen_keywords_pair, match_keyword, match_country_region, \\\n",
    "    chopoff, match_company,rematch_keywords,match_topic,match_storage,get_mark_urls,mark_url,add_same_key,\\\n",
    "    remove_intell_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function utils.wash_process(x)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wash_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    start_time = time.time()\n",
    "    table_name = ['news_oil_oe','world_oil']\n",
    "    table_name_pro = ['news_oil_oe_pro','world_oil_pro']\n",
    "    engine = db_connect()\n",
    "    create_table(engine)\n",
    "    cate_file = 'input_data/categories_list.xlsx'\n",
    "    df_dicts = read_xlsx(cate_file)\n",
    "\n",
    "    #==================== generate all the keyword and category pair==================================\n",
    "    # country section\n",
    "    df_dicts['country'].columns = ['region', 'country', 'key_words_chinese', 'key_words_english']  ## rename cols\n",
    "    country_keywords_pair = gen_keywords_pair(df_dicts['country'], 2, [3, 4])\n",
    "    # region section\n",
    "    df_dicts['region'].columns = ['region', 'chinese_keywords', 'english_keywords']\n",
    "    region_df = df_dicts['region']\n",
    "    region_df.columns = ['region', 'chinese_keywords', 'english_keywords']\n",
    "    region_df['chinese_keywords'] = region_df['chinese_keywords'].apply(lambda x: x.split('，')[0])\n",
    "    region_df['english_keywords'] = region_df['english_keywords'].apply(lambda x: x.split('、')[0])\n",
    "    state_keywords_pair = gen_keywords_pair(region_df, 1, [2, 3])\n",
    "    ##genreate the country-region dictionay data for adding the region data from country list\n",
    "    countries = df_dicts['country']['country'].values\n",
    "    regions = df_dicts['country']['region'].values\n",
    "    country_region = {}\n",
    "    for country, region in zip(countries, regions):\n",
    "        country_region[country] = region\n",
    "    ## company section\n",
    "    df_company = df_dicts['company']\n",
    "    df_company.columns = ['country', 'business', 'company', 'keywords']\n",
    "    df_company['keywords'] = df_company['keywords']. \\\n",
    "        apply(lambda x: chopoff(x)). \\\n",
    "        apply(lambda x: x.strip()).apply(lambda x: x.strip().split('、'))\n",
    "    company_keyword_pair = {}\n",
    "    companies = df_company['company'].values\n",
    "    keywords = df_company['keywords'].values\n",
    "    for company, keyword in zip(companies, keywords):\n",
    "        company_keyword_pair[company] = keyword\n",
    "    # print(company_keyword)\n",
    "    company_business = {}\n",
    "    companies = df_company['company'].values\n",
    "    business = df_company['business'].values\n",
    "    for company, business in zip(companies, business):\n",
    "        company_business[company] = business\n",
    "\n",
    "    company_country = {}\n",
    "    companies = df_company['company'].values\n",
    "    counties = df_company['country'].values\n",
    "    for company, country in zip(companies, counties):\n",
    "        company_country[company] = country\n",
    "\n",
    "    ## topic section\n",
    "\n",
    "    df_dicts['subcategory'].columns = ['subset', 'topic', 'chinese_keywords', 'english_keywords']\n",
    "    df_cate = df_dicts['subcategory']\n",
    "    df_cate.iloc[28].topic = '其他能源类型'\n",
    "    df_cate.dropna(inplace=True)\n",
    "    df_cate['english_keywords'] = df_cate['english_keywords'].astype('str').apply(lambda x: x.split('、'))\n",
    "    df_cate['chinese_keywords'] = df_cate['chinese_keywords'].astype('str').apply(lambda x: x.split('、'))\n",
    "\n",
    "    ## rename all the chinese and english keywords\n",
    "    geologies = df_cate.iloc[4].chinese_keywords\n",
    "    smart_geology = df_cate.iloc[16].chinese_keywords\n",
    "    drilling = df_cate.iloc[5].chinese_keywords\n",
    "    smart_drilling = df_cate.iloc[17].chinese_keywords\n",
    "    well_test = df_cate.iloc[6].chinese_keywords\n",
    "    smart_test = df_cate.iloc[18].chinese_keywords\n",
    "    production = df_cate.iloc[7].chinese_keywords\n",
    "    smart_production = df_cate.iloc[19].chinese_keywords\n",
    "    transport = df_cate.iloc[12].chinese_keywords + \\\n",
    "                df_cate.iloc[13].chinese_keywords + \\\n",
    "                df_cate.iloc[14].chinese_keywords + \\\n",
    "                df_cate.iloc[15].chinese_keywords\n",
    "    smart_transport = df_cate.iloc[20].chinese_keywords\n",
    "\n",
    "    geologies_english = df_cate.iloc[4].english_keywords\n",
    "    smart_geology_english = df_cate.iloc[16].english_keywords\n",
    "    drilling_english = df_cate.iloc[5].english_keywords\n",
    "    smart_drilling_english = df_cate.iloc[17].english_keywords\n",
    "    well_test_english = df_cate.iloc[6].english_keywords\n",
    "    smart_test_english = df_cate.iloc[18].english_keywords\n",
    "    production_english = df_cate.iloc[7].english_keywords\n",
    "    smart_production_english = df_cate.iloc[19].english_keywords\n",
    "    transport_english = df_cate.iloc[12].english_keywords + \\\n",
    "                        df_cate.iloc[13].english_keywords + \\\n",
    "                        df_cate.iloc[14].english_keywords + \\\n",
    "                        df_cate.iloc[15].english_keywords\n",
    "    smart_transport_english = df_cate.iloc[20].english_keywords\n",
    "\n",
    "    ##generate mixed keywords\n",
    "    smart_geologies_chinese_mixed = rematch_keywords(geologies, smart_geology)\n",
    "    smart_drill_chinese_mixed = rematch_keywords(drilling, smart_drilling)\n",
    "    smart_well_test_chinese_mixed = rematch_keywords(well_test, smart_test)\n",
    "    smart_production_chinese_mixed = rematch_keywords(production, smart_production)\n",
    "    smart_transport_chinese_mixed = rematch_keywords(transport, smart_transport)\n",
    "    smart_geologies_english_mixed = rematch_keywords(geologies_english, smart_geology_english)\n",
    "    smart_drill_english_mixed = rematch_keywords(drilling_english, smart_drilling_english)\n",
    "    smart_well_test_english_mixed = rematch_keywords(well_test_english, smart_test_english)\n",
    "    smart_production_english_mixed = rematch_keywords(production_english, smart_production_english)\n",
    "    smart_transport_english_mixed = rematch_keywords(transport_english, smart_transport_english)\n",
    "    ## change the keywords with such mixed ones\n",
    "    df_cate.iloc[16].chinese_keywords = smart_geologies_chinese_mixed\n",
    "    df_cate.iloc[17].chinese_keywords = smart_drill_chinese_mixed\n",
    "    df_cate.iloc[18].chinese_keywords = smart_well_test_chinese_mixed\n",
    "    df_cate.iloc[19].chinese_keywords = smart_production_chinese_mixed\n",
    "    df_cate.iloc[20].chinese_keywords = smart_transport_chinese_mixed\n",
    "    df_cate.iloc[16].english_keywords = smart_geologies_english_mixed\n",
    "    df_cate.iloc[17].english_keywords = smart_drill_english_mixed\n",
    "    df_cate.iloc[18].english_keywords = smart_well_test_english_mixed\n",
    "    df_cate.iloc[19].english_keywords = smart_production_english_mixed\n",
    "    df_cate.iloc[20].english_keywords = smart_transport_english_mixed\n",
    "\n",
    "    df_cate['keywords'] = df_cate['chinese_keywords'] + df_cate['english_keywords']\n",
    "    ## preparing the category-keywords pair\n",
    "    topic_keywords = {}\n",
    "    topics = df_cate['topic'].values\n",
    "    keywords = df_cate['keywords'].values\n",
    "    for topic, keyword in zip(topics, keywords):\n",
    "        topic_keywords[topic] = keyword\n",
    "    topic_subcategory = {}\n",
    "\n",
    "    topics = df_cate['topic'].values\n",
    "    subcategory = df_cate['subset'].values\n",
    "    for topic, keyword in zip(topics, subcategory):\n",
    "        topic_subcategory[topic] = keyword\n",
    "    topic_subcategory['石油公司'] = '能源公司'\n",
    "    topic_subcategory['油服公司'] = '能源公司'\n",
    "    ## field section\n",
    "    df_dicts['field'].columns = ['field', 'keyword']\n",
    "    df_field = df_dicts['field']\n",
    "    df_field['merged_keywords'] = df_field['keyword']. \\\n",
    "        apply(lambda x: chopoff(x)). \\\n",
    "        apply(lambda x: x.strip()).apply(lambda x: x.strip().split('、'))\n",
    "    field_keyword = {}\n",
    "    field = df_field['field'].values\n",
    "    keyword = df_field['merged_keywords'].values\n",
    "    for fie, key in zip(field, keyword):\n",
    "        field_keyword[fie] = key\n",
    "    field_keyword['MESSLAH'] = ['MESSLAH', 'MESSLA'] ## some correction of data\n",
    "    ## storage section\n",
    "    df_dicts['storage'].columns = ['country', 'storage', 'keyword']\n",
    "    df_storage = df_dicts['storage']\n",
    "    storage_keyword = {}\n",
    "    storage = df_storage['storage'].values\n",
    "    keyword = df_storage['keyword'].values\n",
    "    for stor, key in zip(storage, keyword):\n",
    "        if re.search('/', key):\n",
    "            storage_keyword[stor] = key.split('/')\n",
    "        else:\n",
    "            storage_keyword[stor] = [key.strip()]\n",
    "    storage_keyword['MOLDOVA  (FALTICENI)'] = 'MOLDOVA'\n",
    "    storage_keyword['CHESHIRE (HOLFORD GS)'] = 'Cheshire'\n",
    "    storage_keyword['HILL TOP FARM  (CHESHIRE EXISTING)'] = 'Hill Top Farm'\n",
    "    storage_keyword['HILL TOP FARM  (CHESHIRE EXPANSION)'] = 'Hill Top Farm'\n",
    "    storage_keyword['KIRK RANCH  (BOBBY BURNS #1)'] = 'KIRK RANCH'\n",
    "    storage_keyword['CLEMENS NE  (FRIO B)'] = 'CLEMENS,N.E.'\n",
    "    ## get country according to the storage\n",
    "    storage_country = {}\n",
    "    storage = df_storage['storage'].values\n",
    "    country = df_storage['country'].values\n",
    "    for stor, coun in zip(storage, country):\n",
    "        storage_country[stor] = coun\n",
    "\n",
    "    mark_urls = get_mark_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage_country  #dictionary of one-one\n",
    "# country_region\n",
    "# company_business\n",
    "# topic_subcategory\n",
    "# company_country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_keywords_pair\n",
    "# state_keywords_pair\n",
    "# company_keyword_pair\n",
    "# topic_keywords\n",
    "# field_keyword\n",
    "# storage_keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b1846f22adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_df' is not defined"
     ]
    }
   ],
   "source": [
    "raw_df['new_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ==================== reach the process section for each category==================================\n",
    "    df= pd.DataFrame()\n",
    "    for table_pair in zip(table_name, table_name_pro):\n",
    "        pre_data = return_no_processed_df(table_pair[0], table_pair[1], engine)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = return_no_processed_df('hart_energy', 'hart_energy_pro', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_sql_table('hart_energy_pro',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'orig_id', 'source', 'title', 'abstracts', 'preview_img_link',\n",
       "       'url', 'format_pub_time', 'author', 'new_content', 'categories',\n",
       "       'img_urls_new', 'format_crawl_time', 'regions_merged', 'country_merged',\n",
       "       'company_keyword', 'country_matched_by_company_merged',\n",
       "       'subcategory_merged', 'topic_merged', 'field_keyword',\n",
       "       'storage_keyword', 'mark_note_by_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['new_content'] = raw['new_content'].apply(lambda x: extract_hart_energy_img_links(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<img alt=\"A&amp;D Transactions From The Week Of July 17, 2019\" height=\"723\" src=\"/sites/default/files/styles/news_article_image/public/image/2019/07/ad-transactions-week-july-17-2019.jpg?itok=OrDrtNdq\" width=\"1000\"/>\\nAlso, the buyer in last week’s deal for Encana’s Arkoma Basin assets is revealed.(Source: Hart Energy/Shutterstock.com)\\nHere’s a snapshot of energy deals from the past week featuring the $3.2 billion acquisition of Carrizo Oil & Gas by Callon Petroleum that included core positions in the Permian Basin and Eagle Ford Shale plus the buyer of Encana’s Arkoma Basin assets is revealed.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['new_content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    []\n",
       "1    []\n",
       "Name: new_content, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['new_content'].apply(lambda x: extract_hart_energy_img_links(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020/12/04'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(pre_data['pub_time'][0].replace(' ','-').replace(',',''),\\\n",
    "                  '%A-%d-%B-%Y-%H:%S').strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hart_energy_img_links(x):\n",
    "    '''extract img_links from content\n",
    "    '''\n",
    "    img_links = []\n",
    "    for ele in x:\n",
    "        if isinstance(ele, Tag):\n",
    "            if ele.name == 'img' and ele.has_attr('src') :\n",
    "                img_link = ele.attrs['src']\n",
    "                if re.match(r'^/', img_link):\n",
    "                    img_links.append((str(img_link), ele.attrs['alt']))\n",
    "\n",
    "    return img_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>pre_title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_time</th>\n",
       "      <th>preview_img_link</th>\n",
       "      <th>content</th>\n",
       "      <th>categories</th>\n",
       "      <th>crawl_time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Denmark to end exploration and production by 2050</td>\n",
       "      <td>Denmark has cancelled its latest licensing rou...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Friday, 04 December 2020 13:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chevron makes cuts to capital budget</td>\n",
       "      <td>Chevron has cut billions off its long-term cap...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Thursday, 03 December 2020 16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Equinor drills dry well in Barents Sea</td>\n",
       "      <td>The well was drilled about 100 km southwest of...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Friday, 04 December 2020 09:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Shearwater awarded OBN 4D baseline survey by P...</td>\n",
       "      <td>The survey will take place over the Jubarte fi...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Thursday, 26 November 2020 09:30</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>PGS resuming Campos Basin seismic survey in De...</td>\n",
       "      <td>The survey will provide the first 3D seismic d...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Monday, 30 November 2020 16:15</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>272</td>\n",
       "      <td>Johan Sverdrup field increases production capa...</td>\n",
       "      <td>The Johan Sverdrup field is increasing its dai...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Wednesday, 18 November 2020 16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Offshore &amp; subsea</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/offshore-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>273</td>\n",
       "      <td>Spirit Energy drills dry well near Ivar Aasen ...</td>\n",
       "      <td>The objective of the well was to prove petrole...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Wednesday, 05 August 2020 10:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>274</td>\n",
       "      <td>Neptune Energy confirms commercial oil discove...</td>\n",
       "      <td>The volumes are estimated to be in the range o...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Tuesday, 04 August 2020 09:30</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>275</td>\n",
       "      <td>Halliburton digital services to support Petron...</td>\n",
       "      <td>Halliburton Landmark will deliver DecisionSpac...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Tuesday, 04 August 2020 10:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>276</td>\n",
       "      <td>KCA Deutag awarded Oman drilling contracts</td>\n",
       "      <td>KCA Deutag has been awarded contracts worth mo...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Tuesday, 13 October 2020 11:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Drilling &amp; production</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/drilling-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0      1  Denmark to end exploration and production by 2050   \n",
       "1      2               Chevron makes cuts to capital budget   \n",
       "2      3             Equinor drills dry well in Barents Sea   \n",
       "3      4  Shearwater awarded OBN 4D baseline survey by P...   \n",
       "4      5  PGS resuming Campos Basin seismic survey in De...   \n",
       "..   ...                                                ...   \n",
       "271  272  Johan Sverdrup field increases production capa...   \n",
       "272  273  Spirit Energy drills dry well near Ivar Aasen ...   \n",
       "273  274  Neptune Energy confirms commercial oil discove...   \n",
       "274  275  Halliburton digital services to support Petron...   \n",
       "275  276         KCA Deutag awarded Oman drilling contracts   \n",
       "\n",
       "                                             pre_title             author  \\\n",
       "0    Denmark has cancelled its latest licensing rou...  Nicholas Woodroof   \n",
       "1    Chevron has cut billions off its long-term cap...  Nicholas Woodroof   \n",
       "2    The well was drilled about 100 km southwest of...  Nicholas Woodroof   \n",
       "3    The survey will take place over the Jubarte fi...  Nicholas Woodroof   \n",
       "4    The survey will provide the first 3D seismic d...  Nicholas Woodroof   \n",
       "..                                                 ...                ...   \n",
       "271  The Johan Sverdrup field is increasing its dai...  Nicholas Woodroof   \n",
       "272  The objective of the well was to prove petrole...  Nicholas Woodroof   \n",
       "273  The volumes are estimated to be in the range o...  Nicholas Woodroof   \n",
       "274  Halliburton Landmark will deliver DecisionSpac...  Nicholas Woodroof   \n",
       "275  KCA Deutag has been awarded contracts worth mo...  Nicholas Woodroof   \n",
       "\n",
       "                              pub_time preview_img_link  \\\n",
       "0       Friday, 04 December 2020 13:00             None   \n",
       "1     Thursday, 03 December 2020 16:00             None   \n",
       "2       Friday, 04 December 2020 09:00             None   \n",
       "3     Thursday, 26 November 2020 09:30             None   \n",
       "4       Monday, 30 November 2020 16:15             None   \n",
       "..                                 ...              ...   \n",
       "271  Wednesday, 18 November 2020 16:00             None   \n",
       "272    Wednesday, 05 August 2020 10:00             None   \n",
       "273      Tuesday, 04 August 2020 09:30             None   \n",
       "274      Tuesday, 04 August 2020 10:00             None   \n",
       "275     Tuesday, 13 October 2020 11:00             None   \n",
       "\n",
       "                                               content             categories  \\\n",
       "0    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "1    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "2    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "3    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "4    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "..                                                 ...                    ...   \n",
       "271  <div itemprop=\"articleBody\">\\r\\n              ...      Offshore & subsea   \n",
       "272  <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "273  <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "274  <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "275  <div itemprop=\"articleBody\">\\r\\n              ...  Drilling & production   \n",
       "\n",
       "           crawl_time                                                url  \n",
       "0    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "1    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "2    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "3    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "4    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "..                ...                                                ...  \n",
       "271  12/21/2020 22:29  https://www.oilfieldtechnology.com/offshore-an...  \n",
       "272  12/21/2020 22:29  https://www.oilfieldtechnology.com/exploration...  \n",
       "273  12/21/2020 22:29  https://www.oilfieldtechnology.com/exploration...  \n",
       "274  12/21/2020 22:29  https://www.oilfieldtechnology.com/exploration...  \n",
       "275  12/21/2020 22:29  https://www.oilfieldtechnology.com/drilling-an...  \n",
       "\n",
       "[276 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data['pub_time'] = pre_data['pub_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"sj-main\">\\n        \\n          <div class=\"as04\" style=\" display:block; width:650px;\">\\n\\n          \\t <p style=\"text-align:left\"><strong>\\u3000\\u3000中国石油网消息</strong>（特约记者李冬铃\\xa0通讯员于春晶）抚顺石化石油二厂组织干部员工开动脑筋集思广益，用智慧实现持续挖潜创效。7月31日统计数据显示，上半年，石油二厂制氢车间员工通过优化、改造水系统，创效达490余万元。</p>\\r\\n\\r\\n<p style=\"text-align:left\">\\u3000\\u3000制氢车间在生产过程中，一方面要利用脱盐水生产蒸汽，另一方面装置产生的凝结水还要排放掉，如何让两者合二为一用凝结水产生蒸汽，成为这个车间做活“水文章”的主要攻关方向。这个厂强化自产凝结水管理，解决了自产凝结水电导率超标的问题，然后将其回收到除氧器代替新鲜脱盐水生产蒸汽。项目实施后，每小时回收凝结水36吨、节省除盐水36吨，降低了生产成本。</p>\\r\\n\\r\\n<p style=\"text-align:left\">\\u3000\\u3000不仅如此，这个车间又将循环利用的着眼点放在排水上。技术人员对自产排水进行水质分析后发现，各项指标优于循环水场的补水指标，对工艺流程进行改造后，将排水接入循环水管线，用作循环水场补水使用，实施后每小时可节约循环水4吨。在此基础上，这个车间合理整定配汽控制阀PID参数，实现了制氢装置自产中压蒸汽稳定并网，解决了低压蒸汽过剩、中压蒸汽不足的问题，每月为企业节省外购中压蒸汽费用。</p>\\r\\n\\r\\n<p style=\"text-align:left\">\\u3000\\u3000制氢装置转化炉是原料与水蒸气发生转化反应的关键场所，炉膛负压的高低直接关系到装置安全生产、能耗和转化反应完成情况。这个车间严格控制转化炉氧含量及排烟温度，及时调整逆放调节阀开度，适时调整PIC-4005压力控制值，控制解吸气流量相对平稳。通过这一系列优化措施，避免了炉膛负压波动引起装置联锁停车的风险，同时提高了氢气收率，转化炉热效率也提升至92.8%，为企业节能创效增添了新的增长点。</p>\\r\\n \\r\\n\\r\\n\\r\\n\\r\\n          \\t\\n          \\t</div>\\n        </div>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wash_hart_energy_process(x,class_name):\n",
    "    '''\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div',attrs={'class':class_name})\n",
    "#     print(an)\n",
    "    for child in [child for child in ancestor.children if not isinstance(child,NavigableString)][:2]:\n",
    "        for desc in child.descendants:\n",
    "            if desc.name == 'img' and desc.has_attr('src'):\n",
    "                contents.append(desc)\n",
    "            if desc.name == 'p' and not desc.has_attr('class'):\n",
    "                contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "            if desc.name == 'div' and desc.has_attr('class') and desc.attrs['class']==\"userAlready\":\n",
    "                break\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_oil(x,attrs):\n",
    "    '''grab \n",
    "    '''\n",
    "    contents = []\n",
    "    chop_index = None\n",
    "    soup = BeautifulSoup(test, 'lxml')\n",
    "    ancestor = soup.find('div',attrs={'id':'news'})\n",
    "    # print(list(ancestor.children))\n",
    "    for child in [child for child in ancestor.children if not isinstance(child,NavigableString)]:\n",
    "    #     print(child)\n",
    "        if child.name=='p'and not child.has_attr('class')  :\n",
    "            contents.append(child.text.replace(u'\\xa0', u''))\n",
    "    #     elif child.name=='p'and child.find('strong') and not child.find('strong'):\n",
    "    #         break\n",
    "        elif child.name=='div':\n",
    "            for desc in child.descendants:\n",
    "                if not isinstance(desc,NavigableString):\n",
    "                    if desc.name == 'img' and desc.has_attr('src') and re.search('/media',desc.attrs['src']):\n",
    "                        contents.append(desc)\n",
    "        elif child.name=='h2' and re.search(r'Related News',child.string):\n",
    "            break\n",
    "\n",
    "    if contents.index('REFERENCES'):\n",
    "        chop_index = contents.index('REFERENCES')\n",
    "    contents = contents[:chop_index]\n",
    "        \n",
    "    return contents\n",
    "\n",
    "    \n",
    "\n",
    "#     else:\n",
    "#         continue\n",
    "#         if desc.name == 'p' and not desc.has_attr('class'):\n",
    "#             contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "#         if desc.name =='p' and desc.find('strong'):\n",
    "#             break\n",
    "#         if desc.name == 'p' and desc.has('class') and desc.attrs['class']==\"userAlready\":\n",
    "#             break\n",
    "\n",
    "# return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = world_oil(test,attrs={'id':'news'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = req.get('https://www.worldoil.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_oil_hot():\n",
    "    '''get front page url'''\n",
    "    ele_urls = []\n",
    "    host='https://www.worldoil.com'\n",
    "    res = req.get(host)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    cols = soup.find_all('div',attrs={'class':'col-sm-6'})[:2]\n",
    "    for col in cols:\n",
    "    #     print(col)\n",
    "        urls = col.find_all('a')\n",
    "        for url in urls:\n",
    "            ele_urls.append(host+url['href'])\n",
    "    return ele_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hart_energy_hot():\n",
    "    \n",
    "    ele_urls = []\n",
    "    host='https://www.hartenergy.com'\n",
    "    res = req.get(host)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    latest = soup.find('div',attrs={'id':'homepage-latest'})\n",
    "    rows  = latest.find_all('a')\n",
    "    for row in rows[:-1]:\n",
    "        ele_urls.append(host+row['href'])\n",
    "    return ele_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_cnpc_hot():\n",
    "    '''compare with the tiltes'''\n",
    "    titles=[]\n",
    "    host='http://news.cnpc.com.cn/toutiao/'\n",
    "    res = req.get(host)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    lists = soup.find('div',attrs={'class':'list18'})\n",
    "    for row in lists.find_all('li',attrs={'class':'ejli'}):\n",
    "        title = row.find('a').text.strip()\n",
    "        titles.append(title)\n",
    "        \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '10/23/2020' does not match format '%d/%m/%Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-192432522654>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# '10/23/2020' does not match format '%d/%m/%Y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'10/23/2020'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%d/%m/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[1;32m    567\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0m\u001b[1;32m    350\u001b[0m                          (data_string, format))\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data '10/23/2020' does not match format '%d/%m/%Y'"
     ]
    }
   ],
   "source": [
    "# '10/23/2020' does not match format '%d/%m/%Y'\n",
    "datetime.strptime('10/23/2020','%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wash_process(x,class_name):\n",
    "    '''\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div',attrs={'class':class_name})\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "            contents.append(desc)\n",
    "        if desc.name == 'p' and not desc.has_attr('class'):\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "        if desc.name == 'div' and desc.has_attr('class') and desc.attrs['class']==\"userAlready\":\n",
    "            break\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = pd.read_sql_table('hart_energy',engine,columns=['id','title','content','url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_content = pre_data['content'].apply(lambda x:wash_hart_energy_process(x,'article-content-wrapper'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-183da3c1cdd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ==================== reach the process section for each category==================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtable_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name_pro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpre_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_no_processed_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table_name' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "        print(pre_data.head())\n",
    "#         print(pre_data.head(),pre_data.info(),type(pre_data))\n",
    "        if len(pre_data) == 0:  ## no dataframe needed to be processed\n",
    "            break\n",
    "        else:\n",
    "            raw_df = pre_data.iloc[0:1]\n",
    "            if re.search(r'_oe',table_pair[0]): ## oedigital form of data\n",
    "                raw_df['format_pub_time'] = raw_df['pub_time']\\\n",
    "                .apply(lambda x: datetime.strptime(x, \"%B %d, %Y\").strftime('%Y/%m/%d'))\\\n",
    "                .apply(lambda x:datetime.strptime(x,\"%Y/%m/%d\"))\n",
    "                  ##make the dataframe name consistent\n",
    "                # print(raw_df['url'][0],raw_df['content'],raw_df['content'][0],type(raw_df['content'][0]))\n",
    "                # break\n",
    "            raw_df['new_content'] = raw_df['content'].apply(lambda x: wash_process(x, div_class_name))\n",
    "            raw_df['img_urls_new'] = raw_df['new_content'].apply(lambda x: extract_img_links(x))\n",
    "            # raw_df['new_content'] =\n",
    "\n",
    "            raw_df['format_crawl_time'] = raw_df['crawl_time'].apply(lambda x: x.strip()[:10]) \\\n",
    "                .apply(lambda x: datetime.strptime(x, \"%m/%d/%Y\").strftime('%Y/%m/%d')) \\\n",
    "                .apply(lambda x:datetime.strptime(x,\"%Y/%m/%d\"))\n",
    "#             print(raw_df.head())\n",
    "            \n",
    "\n",
    "            df = raw_df[['id', 'author', 'categories', 'preview_img_link',\n",
    "                             'title', 'url', 'new_content', 'img_urls_new',\n",
    "                             'format_pub_time', 'format_crawl_time']]\n",
    "\n",
    "            ## create first checkpoint\n",
    "            ## country keyword section\n",
    "            df['country_keyword'] = df['new_content'].astype('str'). \\\n",
    "                apply(lambda x: match_keyword(x, country_keywords_pair))\n",
    "            ## region keyword sections\n",
    "            ## perform the matching according to the region keywords\n",
    "            df['region_keywords'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_keyword(x, state_keywords_pair))\n",
    "\n",
    "            ## determin the region according to the country keyword\n",
    "            df['regions_country'] = df['country_keyword'] \\\n",
    "                .apply(lambda x: match_country_region(x, country_region))\n",
    "            print('reach to process company section')\n",
    "            ## company sections\n",
    "            df['company_keyword'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_company(x, company_keyword_pair))\n",
    "            df['business_company'] = df['company_keyword']. \\\n",
    "                apply(lambda x: match_country_region(x, company_business))\n",
    "            df['country_matched_by_company'] = df['company_keyword']. \\\n",
    "                apply(lambda x: match_country_region(x, company_country))\n",
    "\n",
    "            ## topic section\n",
    "            df['topic_keyword'] = df['new_content'].astype('str').apply(lambda x: match_topic(x, topic_keywords))\n",
    "            df['topic_keyword'] = df['business_company'] + df['topic_keyword']\n",
    "            df['subcategory_by_topic'] = df['topic_keyword']. \\\n",
    "                apply(lambda x: match_country_region(x, topic_subcategory))\n",
    "\n",
    "            ##field section\n",
    "            df['field_keyword'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_company(x, field_keyword))\n",
    "\n",
    "            ## storage section\n",
    "            df['storage_keyword'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_storage(x, storage_keyword))\n",
    "            df['country_storage'] = df['storage_keyword'] \\\n",
    "                .apply(lambda x: match_country_region(x, storage_country))\n",
    "            ## mark or not\n",
    "            df['mark_note_by_url'] = df['url'].apply(lambda x: mark_url(x, mark_urls))\n",
    "\n",
    "            print('reach to post process of data')\n",
    "            ##post process\n",
    "            df['regions'] = df['region_keywords'] + df['regions_country']\n",
    "            df['country'] = df['country_keyword']\n",
    "            df['company_merged'] = df['company_keyword'].apply(lambda x: add_same_key(x))\n",
    "            df['regions_merged'] = df['regions'].apply(lambda x: add_same_key(x))\n",
    "            df['country_merged'] = df['country'].apply(lambda x: add_same_key(x))\n",
    "            df['topic_merged'] = df['topic_keyword'].apply(lambda x: add_same_key(x))\n",
    "            df['subcategory_merged'] = df['subcategory_by_topic'].apply(lambda x: add_same_key(x))\n",
    "            df['country_matched_by_company_merged'] = df['country_matched_by_company'].apply(lambda x: add_same_key(x))\n",
    "\n",
    "            df['new_content'] = raw_df['new_content'] \\\n",
    "                .apply(lambda x: '\\n'.join([str(ele).strip() for ele in x]))\n",
    "\n",
    "            df['topic_merged'] = df['topic_merged'].astype('str').apply(lambda x: remove_intell_topic(x))\n",
    "            df['topic_merged'] = df['topic_merged'].astype('str')\n",
    "            spend_time = round(time.time() -start_time,1)\n",
    "#             print('spend time',spend_time,' to process data',df.info())\n",
    "            df['source'] = 'www.oedigital.com'\n",
    "            df['abstracts'] = df['title']\n",
    "\n",
    "            result = df[['source', 'title', 'abstracts', 'preview_img_link', 'url', 'format_pub_time',\n",
    "                         'author', 'new_content', 'categories',\n",
    "                         'img_urls_new', 'format_crawl_time', 'regions_merged',\n",
    "                         'country_merged', 'company_keyword', 'country_matched_by_company_merged',\n",
    "                         'subcategory_merged', 'topic_merged', 'field_keyword', 'storage_keyword', 'mark_note_by_url'\n",
    "                         ]]\n",
    "            result['orig_id']=df['id']\n",
    "#             result.index =df.index\n",
    "#             print('the column name of result is',result.columns)\n",
    "            # print(result.head(),result.columns,result.info(),result[0:1].values)\n",
    "            result['preview_img_link'] = result['preview_img_link'].astype('str')\n",
    "            result['img_urls_new'] = result['img_urls_new'].astype('str')\n",
    "            result['regions_merged'] = result['regions_merged'].astype('str')\n",
    "            result['country_merged'] = result['country_merged'].astype('str')\n",
    "            result['company_keyword'] = result['company_keyword'].astype('str')\n",
    "            result['country_matched_by_company_merged'] = result['country_matched_by_company_merged'].astype('str')\n",
    "            result['subcategory_merged'] = result['subcategory_merged'].astype('str')\n",
    "            result['field_keyword'] = result['field_keyword'].astype('str')\n",
    "            result['storage_keyword'] = result['storage_keyword'].astype('str')\n",
    "            result['mark_note_by_url'] = result['mark_note_by_url'].astype('str')\n",
    "            # test = result[0:1].values\n",
    "#             print(result.info())\n",
    "#             result.to_csv('oe_backup.csv')\n",
    "            # print(result.iloc[0:1].values)\n",
    "#             print(result.columns)\n",
    "#             result_post =pd.read_csv('oe_backup.csv')\n",
    "\n",
    "\n",
    "            result.to_sql(table_pair[1],engine,if_exists='append',index=False)\n",
    "#             result_post.to_sql('test_table_1',engine,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_abstracts = df['new_content'][0][:340]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstracts'] = df['new_content'].apply(lambda) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_abstracts = df['new_content'][0]\n",
    "def gen_abstracts(x):\n",
    "    '''generate new abstracts'''\n",
    "    span_length = 0\n",
    "    if re.search('<img .+>',x):\n",
    "        img_tags = re.findall('<img .+>',x)\n",
    "        for img_tag in img_tags:\n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tags = re.finditer('<img .+>',df['new_content'][0])\n",
    "\n",
    "tags = [img_tag for img_tag in img_tags]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 309)\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "taken_length = 0\n",
    "## if length>340:\n",
    "for i in range(len(tags)):\n",
    "    take_by_img = tag.span()\n",
    "    if take_by_img[0]<340:\n",
    "        print(take_by_img)\n",
    "        img_tag_length = take_by_img[1] - take_by_img[0]\n",
    "        print(img_tag_length)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['new_content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Karen Boman speaks with Prasantha Jayakody of Bsquare about the benefits of condition-based maintenance and the challenges of implementation in the oil and gas industry.\\n\\nGraphic from Bsquare.\\nReducing non-productive time related to equipment maintenance and breakdowns is necessary during the downturn as companies seek cost reductions. To'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('<img .+>','',df['new_content'][0])[:340]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(6786, 6924), match='<img alt=\"\" src=\"images/items/2017-08/auto_karen/>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                              title  \\\n",
      "0   1                              Improving maintenance   \n",
      "1   2  Eidesvik Equips Fleet with Energy Efficiency S...   \n",
      "2   3  Caterpillar to Buy Weir's Oil and Gas Business...   \n",
      "3   4  PHOTO: Heerema's Heavy Lifter Installs Yaxche-...   \n",
      "4   5  Olympic, Safeway Team Up for Offshore Wind Far...   \n",
      "\n",
      "                                           pre_title                 author  \\\n",
      "0                              Improving maintenance            Karen Boman   \n",
      "1  Eidesvik Equips Fleet with Energy Efficiency S...                   None   \n",
      "2  Caterpillar to Buy Weir's Oil and Gas Business...  Aakash Jagadeesh Babu   \n",
      "3  PHOTO: Heerema's Heavy Lifter Installs Yaxche-...               OE Staff   \n",
      "4  Olympic, Safeway Team Up for Offshore Wind Far...                   None   \n",
      "\n",
      "            pub_time                                   preview_img_link  \\\n",
      "0     August 1, 2017                                               None   \n",
      "1      June 16, 2020  https://images.oedigital.com/images/maritime/w...   \n",
      "2    October 5, 2020  https://images.oedigital.com/images/maritime/w...   \n",
      "3    August 21, 2020  https://images.oedigital.com/images/maritime/w...   \n",
      "4  November 24, 2020  https://images.oedigital.com/images/maritime/w...   \n",
      "\n",
      "                                             content  \\\n",
      "0  <div class=\"article\">\\r\\n    <h1 itemprop=\"nam...   \n",
      "1  <div class=\"article\">\\r\\n    <h1 itemprop=\"nam...   \n",
      "2  <div class=\"article\">\\r\\n    <h1 itemprop=\"nam...   \n",
      "3  <div class=\"article\">\\r\\n    <h1 itemprop=\"nam...   \n",
      "4  <div class=\"article\">\\r\\n    <h1 itemprop=\"nam...   \n",
      "\n",
      "                                          categories        crawl_time  \\\n",
      "0                                        Maintenance  12/03/2020 20:01   \n",
      "1  ['Technology', 'Offshore', 'Energy', 'Vessels'...  12/03/2020 20:14   \n",
      "2  ['Equipment', 'Technology', 'Energy', 'Mergers...  12/03/2020 20:14   \n",
      "3  ['Energy', 'Industry News', 'Activity', 'South...  12/03/2020 20:14   \n",
      "4  ['Vessels', 'Offshore Wind', 'Europe', 'German...  12/03/2020 20:14   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.oedigital.com/news/446021-improvin...  \n",
      "1  https://www.oedigital.com/news/479368-eidesvik...  \n",
      "2  https://www.oedigital.com/news/482173-caterpil...  \n",
      "3  https://www.oedigital.com/news/481122-photo-he...  \n",
      "4  https://www.oedigital.com/news/483458-olympic-...  \n",
      "    orig_id             source  \\\n",
      "id                               \n",
      "1         1  www.oedigital.com   \n",
      "2       101  www.oedigital.com   \n",
      "3       201  www.oedigital.com   \n",
      "4       301  www.oedigital.com   \n",
      "5       401  www.oedigital.com   \n",
      "\n",
      "                                                title  \\\n",
      "id                                                      \n",
      "1                               Improving maintenance   \n",
      "2                                 Stepping on the gas   \n",
      "3   Brent Crude Tops $40 as Biden's Win Buoys Risk...   \n",
      "4       Ashtead recognized for safety, quality in GoM   \n",
      "5   Colloquy: Offshore helicopters (commuting on a...   \n",
      "\n",
      "                                            abstracts  \\\n",
      "id                                                      \n",
      "1                               Improving maintenance   \n",
      "2                                 Stepping on the gas   \n",
      "3   Brent Crude Tops $40 as Biden's Win Buoys Risk...   \n",
      "4       Ashtead recognized for safety, quality in GoM   \n",
      "5   Colloquy: Offshore helicopters (commuting on a...   \n",
      "\n",
      "                                     preview_img_link  \\\n",
      "id                                                      \n",
      "1                                                None   \n",
      "2                                                None   \n",
      "3   https://images.oedigital.com/images/maritime/w...   \n",
      "4                                                None   \n",
      "5                                                None   \n",
      "\n",
      "                                                  url format_pub_time  \\\n",
      "id                                                                      \n",
      "1   https://www.oedigital.com/news/446021-improvin...      2017-08-01   \n",
      "2   https://www.oedigital.com/news/460034-stepping...      2010-08-09   \n",
      "3   https://www.oedigital.com/news/483037-brent-cr...      2020-11-09   \n",
      "4   https://www.oedigital.com/news/451398-ashtead-...      2015-09-17   \n",
      "5   https://www.oedigital.com/news/454245-colloquy...      2014-11-03   \n",
      "\n",
      "           author                                        new_content  \\\n",
      "id                                                                     \n",
      "1     Karen Boman  Karen Boman speaks with Prasantha Jayakody of ...   \n",
      "2   Meg Chesshyre  Gas is part of the solution to the global ener...   \n",
      "3    Florence Tan  <img alt=\"Joe Biden / Credit: Gage Skidmore - ...   \n",
      "4        OE Staff  Ashtead Technology’s Houston office has secure...   \n",
      "5       Nina Rach  \\n<img alt=\"\" src=\"https://www.oedigital.com/i...   \n",
      "\n",
      "                                           categories  ... format_crawl_time  \\\n",
      "id                                                     ...                     \n",
      "1                                         Maintenance  ...        2020-12-03   \n",
      "2                  ['Engineering', 'Europe', 'Shale']  ...        2020-12-03   \n",
      "3   ['Energy', 'Activity', 'North America', 'Oil P...  ...        2020-12-03   \n",
      "4   ['Activity', 'North America', 'Gulf of Mexico'...  ...        2020-12-03   \n",
      "5   ['Vessels', 'Asia', 'Rigs', 'Africa', 'Safety ...  ...        2020-12-03   \n",
      "\n",
      "                                       regions_merged  \\\n",
      "id                                                      \n",
      "1                                                  []   \n",
      "2                                         [('欧洲', 6)]   \n",
      "3        [('亚洲', 2), ('拉美', 1), ('中东', 2), ('北美', 3)]   \n",
      "4                  [('亚洲', 1), ('北美', 1), ('大洋洲', 1)]   \n",
      "5   [('非洲', 1), ('拉美', 2), ('亚洲', 5), ('独联体', 6), ...   \n",
      "\n",
      "                                       country_merged  \\\n",
      "id                                                      \n",
      "1                                                  []   \n",
      "2                              [('德国', 1), ('挪威', 4)]   \n",
      "3      [('中国', 2), ('委内瑞拉', 1), ('伊朗', 2), ('美国', 3)]   \n",
      "4               [('新加坡', 1), ('墨西哥', 1), ('澳大利亚', 1)]   \n",
      "5   [('俄罗斯', 6), ('中国', 2), ('印度', 2), ('墨西哥', 1),...   \n",
      "\n",
      "                            company_keyword country_matched_by_company_merged  \\\n",
      "id                                                                              \n",
      "1                                        []                                []   \n",
      "2   [('Equinor', 4), ('Aker Solutions', 2)]                       [('挪威', 6)]   \n",
      "3                                        []                                []   \n",
      "4                                        []                                []   \n",
      "5                     [('Marathon Oil', 1)]                       [('美国', 1)]   \n",
      "\n",
      "                                   subcategory_merged  \\\n",
      "id                                                      \n",
      "1                                      [('勘探开发', 16)]   \n",
      "2   [('能源公司', 6), ('行业市场', 4), ('勘探开发', 14), ('油气储...   \n",
      "3                          [('行业市场', 3), ('勘探开发', 3)]   \n",
      "4                                       [('勘探开发', 6)]   \n",
      "5   [('能源公司', 1), ('行业市场', 1), ('勘探开发', 12), ('油气储...   \n",
      "\n",
      "                                         topic_merged  \\\n",
      "id                                                      \n",
      "1   [('钻完井', 2), ('油气生产', 2), ('海上油气', 11), ('HSE'...   \n",
      "2   [('石油公司', 4), ('油服公司', 2), ('资产交易', 3), ('招投标'...   \n",
      "3   [('行业趋势', 2), ('政策法规', 1), ('钻完井', 1), ('油气生产'...   \n",
      "4                           [('海上油气', 2), ('HSE', 4)]   \n",
      "5   [('石油公司', 1), ('资产交易', 1), ('油气生产', 1), ('海上油气...   \n",
      "\n",
      "                               field_keyword storage_keyword mark_note_by_url  \n",
      "id                                                                             \n",
      "1                    [('AUGILA-NAFOORA', 8)]              []            False  \n",
      "2   [('AUGILA-NAFOORA', 13), ('POMPANO', 1)]              []            False  \n",
      "3     [('AUGILA-NAFOORA', 4), ('POPEYE', 1)]              []            False  \n",
      "4                    [('AUGILA-NAFOORA', 1)]              []            False  \n",
      "5                    [('AUGILA-NAFOORA', 6)]              []            False  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Index(['id', 'title', 'pre_title', 'author', 'pub_time', 'preview_img_link',\n",
      "       'content', 'categories', 'crawl_time', 'url'],\n",
      "      dtype='object')\n",
      "Index(['orig_id', 'source', 'title', 'abstracts', 'preview_img_link', 'url',\n",
      "       'format_pub_time', 'author', 'new_content', 'categories',\n",
      "       'img_urls_new', 'format_crawl_time', 'regions_merged', 'country_merged',\n",
      "       'company_keyword', 'country_matched_by_company_merged',\n",
      "       'subcategory_merged', 'topic_merged', 'field_keyword',\n",
      "       'storage_keyword', 'mark_note_by_url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pre_data = return_no_processed_df(table_pair[0], table_pair[1], engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_no_processed_df(table_name, pro_table_name, engine):\n",
    "    '''\n",
    "    compare with two table extract such row has not processed\n",
    "    '''\n",
    "    ori_df = pd.read_sql_table(table_name, engine)\n",
    "    pro_df = pd.read_sql_table(pro_table_name, engine, index_col='id')\n",
    "    \n",
    "#     print(orid_df.head(),pro_df.head())\n",
    "    ## column id has been processed\n",
    "    id_list = pro_df.orig_id.values.tolist()\n",
    "    print(id_list,len(id_list))\n",
    "\n",
    "    # # if len(ori_df) == len(pro_df)\n",
    "    # if len(id_list) == 0:\n",
    "    #     return ori_df\n",
    "    # else:\n",
    "#     print(id_list)\n",
    "    return ori_df[~(ori_df['id'].isin(id_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table_pair' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-4dc7a778cf2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sql = f\"\"\"UPDATE {table_pair[1]} \n\u001b[0m\u001b[1;32m      2\u001b[0m                         SET {table_pair[1]}.field_keyword = (\n\u001b[1;32m      3\u001b[0m                             \u001b[0mSELECT\u001b[0m \u001b[0mtemp_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield_keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mFROM\u001b[0m \u001b[0mtemp_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtable_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mWHERE\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtable_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table_pair' is not defined"
     ]
    }
   ],
   "source": [
    "sql = f\"\"\"UPDATE news_oil_oe_pro \n",
    "                        SET news_oil_oe_pro.field_keyword = (\n",
    "                            SELECT temp_table.field_keyword\n",
    "                            FROM temp_table,news_oil_oe_pro \n",
    "                            WHERE temp_table.id = news_oil_oe_pro.id\n",
    "                        )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =pd.read_sql_table('oil_and_gas',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"col-12 col-lg article-content-wrapper\">\\n                              <div class=\"field_image_container\">\\n              \\n            <div class=\"field_image_wrapper\">\\n        <div class=\"field_image\">  <img src=\"/sites/default/files/styles/news_article_image/public/image/2019/03/top12wells_14.jpg?itok=087Xb9TO\" width=\"1000\" height=\"736\" alt=\"TopIPwells\">\\n\\n\\n</div>\\n      </div>\\n      \\n              \\n            </div>\\n                          <div class=\"row article-content\">\\n          <div class=\"article-body col-md-9 order-md-12\">\\n                                                                                                              \\n            <div class=\"field_teaser_wrapper\">\\n        <div class=\"field_teaser\"><p>Top 12 I.P. Wells in Bakken Shale FlowOperatorWell #County, StateSection, SurveyComp. Date7,088 Boe/d (4,815 bo, 13.16 MMcf)Whiting Oil &amp; Gas Corp.21-4H Tarpon-FederalMcKenzie , ND4-152n-97wNov. 20117,013 Boe/d (6,800 bo, 1.28 MMcf)Burlington Resources Co.34-34H LlanoMcKenzie , ND34-153n-95wJune 20126.755 Boe/d (5,130 bo, 9.57 MMcf)Burlington Resources Co.24-34H BrazosMcKenzie , ND34-153n-95wJune 20125,330 Boe/d (4,661 bo, 4.01 MMcf)Brigham Exploration Co.2-H Sorenson 29-32Mountrail, ND20-155n-92wMar. 20115,237.67 Boe/d (4,341 bo, 5.38 MMcf)Oasis Petroleum North America LLC13-30B Casey 5200McKenzie, ND30-152n-100wJuly 20125,200 Boe/d (3,731 bo, 8.8 MMcf)*Newfield Exploration Co.152-96-4-2H Wisness-FederalMcKenzie, ND4-152n-96wJuly 20115,133 Boe/d (4,335 bo, 4.79 MMcf)Brigham Exploration Co.1-H Sorenson 29-32Mountrail, ND29-155n-92wMar....</p></div>\\n      </div>\\n      \\n                                                  <div class=\"click_to_continue\">\\n\\t<div class=\"userAlready\">Already have an account? <a href=\"/user/login\">Log In</a></div>\\n\\t<div class=\"buttons\">\\t\\t\\n\\t\\t\\t<h2>Thanks for reading Hart Energy.</h2>\\n\\t\\t\\t<h3>Subscribe now to get unmatched coverage of the oil and gas industry’s entire landscape.</h3>\\n\\t\\t<a href=\"/subscribe\" class=\"btn btn-primary\">Get Access</a>\\n\\t\\t\\n\\t</div>\\n\\t<div class=\"click_to_continue_footer\">\\n\\t\\tNeed more than one account? <a href=\"/group-subscriptions\">See Group Subscription options</a>\\n\\n\\t</div>\\n</div>\\n\\n                        \\n                                                  <div class=\"go-deeper\">\\n                <hr>\\n                \\n      <div class=\"field_region\">\\n              <div class=\"field_region_wrapper\">\\n          <div><a href=\"/regions/united-states\" hreflang=\"en\">United States</a></div>\\n        </div>\\n          </div>\\n  \\n                \\n            <div class=\"field_shore_type_wrapper\">\\n        <div class=\"field_shore_type\"><a href=\"/shore-types/onshore\" hreflang=\"en\">Onshore</a></div>\\n      </div>\\n      \\n                \\n      <div class=\"field_plays\">\\n              <div class=\"field_plays_wrapper\">\\n          <div><a href=\"/shale-plays/williston\" hreflang=\"en\">Williston</a></div>\\n        </div>\\n              <div class=\"field_plays_wrapper\">\\n          <div><a href=\"/shale-plays/williston/bakken\" hreflang=\"en\">Bakken</a></div>\\n        </div>\\n          </div>\\n  \\n              </div>\\n            \\n          </div>\\n          <aside class=\"article-left col-md-3 order-md-1\">\\n            <div class=\"share-buttons\">\\n              <h2>Share this article</h2><span class=\"a2a_kit a2a_kit_size_16 addtoany_list\" data-a2a-url=\"https://www.hartenergy.com/exclusives/updated-top-12-ip-wells-bakken-174756\" data-a2a-title=\"Updated: Top 12 IP Wells in the Bakken\"><ul class=\"list-unstyled\"><li><a class=\"a2a_button_facebook\"><i class=\"icon ion-logo-facebook\"></i> Facebook</a></li><li><a class=\"a2a_button_twitter\"><i class=\"icon ion-logo-twitter\"></i> Twitter</a></li><li><a class=\"a2a_button_linkedin\"><i class=\"icon ion-logo-linkedin\"></i> LinkedIn</a></li><li><a class=\"a2a_button_email\"><i class=\"icon ion-ios-mail\"></i> Email</a></li></ul></span>\\n              <div class=\"article_meta\">\\n                                  <div>\\n                    <i class=\"icon ion-md-eye\"></i>\\n                    42\\n                  </div>\\n                                                  <div>\\n                    <i class=\"icon ion-md-share\"></i>\\n                    21\\n                  </div>\\n                              </div>\\n            </div>\\n                      </aside>\\n        </div>\\n\\n                  <div class=\"author_profile_wrapper\">\\n                          <div class=\"views-element-container\"><div class=\"js-view-dom-id-45486d8222a8d5bc4e062edec8c6c25afa5fdb270e90ac2d0e215acfcba94296\">\\n  \\n  \\n  \\n\\n  \\n  \\n  \\n\\n      <div class=\"views-row\">\\n    <div id=\"author-bio\">\\n    <div class=\"author-profile-image\">  <a href=\"/larryprado\" hreflang=\"en\"><img src=\"/sites/default/files/styles/medium/public/pictures/2020-02/larry-prado.jpg?itok=eb58xQ-i\" width=\"220\" height=\"220\" alt=\"\">\\n\\n</a>\\n</div>\\n    <div class=\"author-info\">\\n      <h3><a href=\"https://www.hartenergy.com/larryprado\"><span class=\"first-name\">Larry</span>\\xa0<span class=\"last-name\">Prado</span></a></h3>\\n      <div class=\"author-bio\">\\n        <p>Larry Prado writes activity highlights for Hart Energy\\'s upstream franchises and covers E&amp;P news. He holds an AA in electronics engineering technology and a BA in technical communications.</p>\\n      </div>\\n    </div>\\n</div>\\n  </div>\\n\\n  \\n  \\n\\n  \\n  \\n\\n  \\n  \\n</div>\\n</div>\\n\\n                      </div>\\n        \\n                  <div class=\"recommended_reading\">\\n            <h2 class=\"section_title\">Recommended Reading</h2>\\n            <div id=\"block-recommendedblock\" class=\"block block-hart-parsely block-recommended-block\">\\n  \\n    \\n        <div class=\"recommended_item\">\\n        <div class=\"text-wrap\">\\n      <h3><a href=\"/exclusives/brent-surges-above-50-first-time-march-covid-19-vaccine-hopes-191334?utm_source=Internal&amp;utm_medium=Popular&amp;utm_campaign=reccoengine&amp;utm_content=/exclusives/brent-surges-above-50-first-time-march-covid-19-vaccine-hopes-191334\">Brent Surges Above $50 for First Time Since March on COVID-19 Vaccine Hopes</a></h3>\\n      <p>Oil prices rose on Dec. 10, with Brent surging above $50/bbl for the first time since early March, fueled by hopes of a faster demand recovery as countries start to roll out COVID-19 vaccines.</p>\\n    </div>\\n  </div>\\n  <div class=\"recommended_item\">\\n        <div class=\"text-wrap\">\\n      <h3><a href=\"/news/brent-rises-highest-march-following-opec-oil-deal-191214?utm_source=Internal&amp;utm_medium=Popular&amp;utm_campaign=reccoengine&amp;utm_content=/news/brent-rises-highest-march-following-opec-oil-deal-191214\">Brent Rises to Highest Since March Following OPEC+ Oil Deal</a></h3>\\n      <p>OPEC+ had been expected to extend existing cuts until at least March, after backing down from earlier plans to boost oil output by 2 million bbl/d.</p>\\n    </div>\\n  </div>\\n  <div class=\"recommended_item\">\\n        <div class=\"text-wrap\">\\n      <h3><a href=\"/news/oil-prices-hit-five-month-high-hurricane-laura-cuts-us-production-189375?utm_source=Internal&amp;utm_medium=Popular&amp;utm_campaign=reccoengine&amp;utm_content=/news/oil-prices-hit-five-month-high-hurricane-laura-cuts-us-production-189375\">Oil Prices Hit Five-month High As Hurricane Laura Cuts US Production</a></h3>\\n      <p>Oil prices rose toward\\xa0$46/bbl on Aug. 26, near the highest since March, lifted by U.S. producers shutting most of their offshore Gulf of Mexico output ahead of Hurricane Laura.</p>\\n    </div>\\n  </div>\\n\\n  </div>\\n\\n          </div>\\n              </div>'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = test['content'].apply(lambda x:wash_oil_gas_process(x,attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_oil_gas_process(x,attrs):\n",
    "    '''\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "            desc.attrs['src'] = 'https://www.oilandgas360.com/'+desc.attrs['src']\n",
    "            contents.append(desc)\n",
    "        elif desc.name == 'p' and not desc.has_attr('class') \\\n",
    "            and not 'a' in [child.name for child in desc.children]:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_links(x):\n",
    "    '''extract img_links from content\n",
    "    '''\n",
    "    img_links = []\n",
    "    for ele in x:\n",
    "        if isinstance(ele, Tag):\n",
    "            if ele.name == 'img' and ele.has_attr('src') and ele.has_attr('alt'):\n",
    "                img_link = ele.attrs['src']\n",
    "                if re.match(r'^http', img_link):\n",
    "                    img_links.append((str(img_link), ele.attrs['alt']))\n",
    "\n",
    "    return img_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['content'] = test['content']. \\\n",
    "        apply(lambda x: wash_oil_gas_process(x,{'class':'entry'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['images'] = test['content'].apply(lambda x:extract_img_links(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.oilandgas360.com/wp-content/uploads/2020/07/california-resources-300x226.png',\n",
       "  'California Resources Corporation agrees on comprehensive balance sheet restructuring with key creditors- oil and gas 360')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['images'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'descendants'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-beb0780242f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mancestor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'entry'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mancestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescendants\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'img'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'descendants'"
     ]
    }
   ],
   "source": [
    "contents = []\n",
    "soup = BeautifulSoup(test['content'][0], 'lxml')\n",
    "ancestor = soup.find('div', attrs={'class':'entry'})\n",
    "for desc in ancestor.descendants:\n",
    "    if desc.name == 'img' and desc.has_attr('src'):\n",
    "        contents.append(desc)\n",
    "    elif desc.name == 'p' and not desc.has_attr('class') \\\n",
    "        and not 'a' in [child.name for child in desc.children]:\n",
    "        contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['content'] = test['content']. \\\n",
    "            apply(lambda x:wash_process(x,{'itemprop':\"articleBody\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oil_gas_hot():\n",
    "    headers= {'user-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0'}\n",
    "    titles = []\n",
    "    host = 'https://www.oilandgas360.com/'\n",
    "    res = req.get(host,headers =headers)\n",
    "    soup = BeautifulSoup(res.text, 'lxml')\n",
    "    ancestor = soup.find('div',attrs={'class':'main-area'}).descendants\n",
    "    for child in ancestor:\n",
    "        if child.name=='a' and child.has_attr('title'):\n",
    "            titles.append(child.attrs['title'])\n",
    "    titles =set(titles)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_hart_energy_process(x,attrs):\n",
    "    '''\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div',attrs=attrs)\n",
    "    if ancestor is not None:\n",
    "        for child in [child for child in ancestor.children if not isinstance(child,NavigableString)][:2]:\n",
    "            for desc in child.descendants:\n",
    "                if desc.name == 'img' and desc.has_attr('src'):\n",
    "                    desc.attrs['src'] = 'https://www.hartenergy.com'+desc.attrs['src']\n",
    "                    contents.append(desc)\n",
    "                if desc.name == 'p' and not desc.has_attr('class'):\n",
    "                    contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "                if desc.name == 'div' and desc.has_attr('class') and desc.attrs['class']==\"userAlready\":\n",
    "                    break\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = test['content'].apply(lambda x:wash_hart_energy_process(x,{'class':'article-content-wrapper'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"TopIPwells\" height=\"736\" src=\"https://www.hartenergy.com/sites/default/files/styles/news_article_image/public/image/2019/03/top12wells_14.jpg?itok=087Xb9TO\" width=\"1000\"/>,\n",
       " 'Top 12 I.P. Wells in Bakken Shale FlowOperatorWell #County, StateSection, SurveyComp. Date7,088 Boe/d (4,815 bo, 13.16 MMcf)Whiting Oil & Gas Corp.21-4H Tarpon-FederalMcKenzie , ND4-152n-97wNov. 20117,013 Boe/d (6,800 bo, 1.28 MMcf)Burlington Resources Co.34-34H LlanoMcKenzie , ND34-153n-95wJune 20126.755 Boe/d (5,130 bo, 9.57 MMcf)Burlington Resources Co.24-34H BrazosMcKenzie , ND34-153n-95wJune 20125,330 Boe/d (4,661 bo, 4.01 MMcf)Brigham Exploration Co.2-H Sorenson 29-32Mountrail, ND20-155n-92wMar. 20115,237.67 Boe/d (4,341 bo, 5.38 MMcf)Oasis Petroleum North America LLC13-30B Casey 5200McKenzie, ND30-152n-100wJuly 20125,200 Boe/d (3,731 bo, 8.8 MMcf)*Newfield Exploration Co.152-96-4-2H Wisness-FederalMcKenzie, ND4-152n-96wJuly 20115,133 Boe/d (4,335 bo, 4.79 MMcf)Brigham Exploration Co.1-H Sorenson 29-32Mountrail, ND29-155n-92wMar....']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
