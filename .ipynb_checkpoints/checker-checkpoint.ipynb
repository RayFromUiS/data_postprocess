{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import create_table\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "uri = 'mysql+pymysql://root:jinzheng1706@139.198.191.224:3308/news_oil'\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models import OilAndGas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session = sessionmaker(engine)\n",
    "# session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(uri)\n",
    "create_table(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [Errno 61] Connection refused, Timeout: 30s, Topology Description: <TopologyDescription id: 600a3079ce98287d85e61fbc, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 61] Connection refused')>]>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-979e40b1303b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'petroleum_news'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'InEn_items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0m_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__session\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_ensure_session\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1814\u001b[0m             \u001b[0;31m# Don't make implicit sessions causally consistent. Applications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m             \u001b[0;31m# should always opt-in.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1816\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__start_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausal_consistency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1817\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConfigurationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInvalidOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m             \u001b[0;31m# Sessions not supported, or multiple users authenticated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m__start_session\u001b[0;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;31m# Raises ConfigurationError if sessions are not supported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m         \u001b[0mserver_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_server_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m         \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSessionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m         return client_session.ClientSession(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_get_server_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_server_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m         \u001b[0;34m\"\"\"Internal: start or resume a _ServerSession.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_topology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_server_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_return_server_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36mget_server_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTOPOLOGY_TYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_known_servers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                         self._select_servers_loop(\n\u001b[0m\u001b[1;32m    486\u001b[0m                             \u001b[0many_server_selector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_selection_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pymongo/topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# No suitable servers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 raise ServerSelectionTimeoutError(\n\u001b[0m\u001b[1;32m    216\u001b[0m                     \u001b[0;34m\"%s, Timeout: %ss, Topology Description: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                     (self._error_message(selector), timeout, self.description))\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [Errno 61] Connection refused, Timeout: 30s, Topology Description: <TopologyDescription id: 600a3079ce98287d85e61fbc, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 61] Connection refused')>]>"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "uri='mongodb://root:password@localhost:27017'\n",
    "client = MongoClient(uri)\n",
    "db = client['petroleum_news']\n",
    "df = pd.DataFrame.from_records(list(db['InEn_items'].find()),index ='_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from bs4 import Tag\n",
    "import requests as req\n",
    "from datetime import datetime\n",
    "from models import db_connect,create_table\n",
    "from check_pro import return_no_processed_df\n",
    "from utils import wash_process, extract_img_links, read_xlsx, gen_keywords_pair, match_keyword, match_country_region, \\\n",
    "    chopoff, match_company,rematch_keywords,match_topic,match_storage,get_mark_urls,add_same_key,\\\n",
    "    remove_intell_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function utils.wash_process(x, attrs)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wash_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    start_time = time.time()\n",
    "    table_name = ['news_oil_oe','world_oil']\n",
    "    table_name_pro = ['news_oil_oe_pro','world_oil_pro']\n",
    "    engine = db_connect()\n",
    "    create_table(engine)\n",
    "    cate_file = 'input_data/categories_list.xlsx'\n",
    "    df_dicts = read_xlsx(cate_file)\n",
    "\n",
    "    #==================== generate all the keyword and category pair==================================\n",
    "    # country section\n",
    "    df_dicts['country'].columns = ['region', 'country', 'key_words_chinese', 'key_words_english']  ## rename cols\n",
    "    country_keywords_pair = gen_keywords_pair(df_dicts['country'], 2, [3, 4])\n",
    "    # region section\n",
    "    df_dicts['region'].columns = ['region', 'chinese_keywords', 'english_keywords']\n",
    "    region_df = df_dicts['region']\n",
    "    region_df.columns = ['region', 'chinese_keywords', 'english_keywords']\n",
    "    region_df['chinese_keywords'] = region_df['chinese_keywords'].apply(lambda x: x.split('，')[0])\n",
    "    region_df['english_keywords'] = region_df['english_keywords'].apply(lambda x: x.split('、')[0])\n",
    "    state_keywords_pair = gen_keywords_pair(region_df, 1, [2, 3])\n",
    "    ##genreate the country-region dictionay data for adding the region data from country list\n",
    "    countries = df_dicts['country']['country'].values\n",
    "    regions = df_dicts['country']['region'].values\n",
    "    country_region = {}\n",
    "    for country, region in zip(countries, regions):\n",
    "        country_region[country] = region\n",
    "    ## company section\n",
    "    df_company = df_dicts['company']\n",
    "    df_company.columns = ['country', 'business', 'company', 'keywords']\n",
    "    df_company['keywords'] = df_company['keywords']. \\\n",
    "        apply(lambda x: chopoff(x)). \\\n",
    "        apply(lambda x: x.strip()).apply(lambda x: x.strip().split('、'))\n",
    "    company_keyword_pair = {}\n",
    "    companies = df_company['company'].values\n",
    "    keywords = df_company['keywords'].values\n",
    "    for company, keyword in zip(companies, keywords):\n",
    "        company_keyword_pair[company] = keyword\n",
    "    # print(company_keyword)\n",
    "    company_business = {}\n",
    "    companies = df_company['company'].values\n",
    "    business = df_company['business'].values\n",
    "    for company, business in zip(companies, business):\n",
    "        company_business[company] = business\n",
    "\n",
    "    company_country = {}\n",
    "    companies = df_company['company'].values\n",
    "    counties = df_company['country'].values\n",
    "    for company, country in zip(companies, counties):\n",
    "        company_country[company] = country\n",
    "\n",
    "    ## topic section\n",
    "\n",
    "    df_dicts['subcategory'].columns = ['subset', 'topic', 'chinese_keywords', 'english_keywords']\n",
    "    df_cate = df_dicts['subcategory']\n",
    "    df_cate.iloc[28].topic = '其他能源类型'\n",
    "    df_cate.dropna(inplace=True)\n",
    "    df_cate['english_keywords'] = df_cate['english_keywords'].astype('str').apply(lambda x: x.split('、'))\n",
    "    df_cate['chinese_keywords'] = df_cate['chinese_keywords'].astype('str').apply(lambda x: x.split('、'))\n",
    "\n",
    "    ## rename all the chinese and english keywords\n",
    "    geologies = df_cate.iloc[4].chinese_keywords\n",
    "    smart_geology = df_cate.iloc[16].chinese_keywords\n",
    "    drilling = df_cate.iloc[5].chinese_keywords\n",
    "    smart_drilling = df_cate.iloc[17].chinese_keywords\n",
    "    well_test = df_cate.iloc[6].chinese_keywords\n",
    "    smart_test = df_cate.iloc[18].chinese_keywords\n",
    "    production = df_cate.iloc[7].chinese_keywords\n",
    "    smart_production = df_cate.iloc[19].chinese_keywords\n",
    "    transport = df_cate.iloc[12].chinese_keywords + \\\n",
    "                df_cate.iloc[13].chinese_keywords + \\\n",
    "                df_cate.iloc[14].chinese_keywords + \\\n",
    "                df_cate.iloc[15].chinese_keywords\n",
    "    smart_transport = df_cate.iloc[20].chinese_keywords\n",
    "\n",
    "    geologies_english = df_cate.iloc[4].english_keywords\n",
    "    smart_geology_english = df_cate.iloc[16].english_keywords\n",
    "    drilling_english = df_cate.iloc[5].english_keywords\n",
    "    smart_drilling_english = df_cate.iloc[17].english_keywords\n",
    "    well_test_english = df_cate.iloc[6].english_keywords\n",
    "    smart_test_english = df_cate.iloc[18].english_keywords\n",
    "    production_english = df_cate.iloc[7].english_keywords\n",
    "    smart_production_english = df_cate.iloc[19].english_keywords\n",
    "    transport_english = df_cate.iloc[12].english_keywords + \\\n",
    "                        df_cate.iloc[13].english_keywords + \\\n",
    "                        df_cate.iloc[14].english_keywords + \\\n",
    "                        df_cate.iloc[15].english_keywords\n",
    "    smart_transport_english = df_cate.iloc[20].english_keywords\n",
    "\n",
    "    ##generate mixed keywords\n",
    "    smart_geologies_chinese_mixed = rematch_keywords(geologies, smart_geology)\n",
    "    smart_drill_chinese_mixed = rematch_keywords(drilling, smart_drilling)\n",
    "    smart_well_test_chinese_mixed = rematch_keywords(well_test, smart_test)\n",
    "    smart_production_chinese_mixed = rematch_keywords(production, smart_production)\n",
    "    smart_transport_chinese_mixed = rematch_keywords(transport, smart_transport)\n",
    "    smart_geologies_english_mixed = rematch_keywords(geologies_english, smart_geology_english)\n",
    "    smart_drill_english_mixed = rematch_keywords(drilling_english, smart_drilling_english)\n",
    "    smart_well_test_english_mixed = rematch_keywords(well_test_english, smart_test_english)\n",
    "    smart_production_english_mixed = rematch_keywords(production_english, smart_production_english)\n",
    "    smart_transport_english_mixed = rematch_keywords(transport_english, smart_transport_english)\n",
    "    ## change the keywords with such mixed ones\n",
    "    df_cate.iloc[16].chinese_keywords = smart_geologies_chinese_mixed\n",
    "    df_cate.iloc[17].chinese_keywords = smart_drill_chinese_mixed\n",
    "    df_cate.iloc[18].chinese_keywords = smart_well_test_chinese_mixed\n",
    "    df_cate.iloc[19].chinese_keywords = smart_production_chinese_mixed\n",
    "    df_cate.iloc[20].chinese_keywords = smart_transport_chinese_mixed\n",
    "    df_cate.iloc[16].english_keywords = smart_geologies_english_mixed\n",
    "    df_cate.iloc[17].english_keywords = smart_drill_english_mixed\n",
    "    df_cate.iloc[18].english_keywords = smart_well_test_english_mixed\n",
    "    df_cate.iloc[19].english_keywords = smart_production_english_mixed\n",
    "    df_cate.iloc[20].english_keywords = smart_transport_english_mixed\n",
    "\n",
    "    df_cate['keywords'] = df_cate['chinese_keywords'] + df_cate['english_keywords']\n",
    "    ## preparing the category-keywords pair\n",
    "    topic_keywords = {}\n",
    "    topics = df_cate['topic'].values\n",
    "    keywords = df_cate['keywords'].values\n",
    "    for topic, keyword in zip(topics, keywords):\n",
    "        topic_keywords[topic] = keyword\n",
    "    topic_subcategory = {}\n",
    "\n",
    "    topics = df_cate['topic'].values\n",
    "    subcategory = df_cate['subset'].values\n",
    "    for topic, keyword in zip(topics, subcategory):\n",
    "        topic_subcategory[topic] = keyword\n",
    "    topic_subcategory['石油公司'] = '能源公司'\n",
    "    topic_subcategory['油服公司'] = '能源公司'\n",
    "    ## field section\n",
    "    df_dicts['field'].columns = ['field', 'keyword']\n",
    "    df_field = df_dicts['field']\n",
    "    df_field['merged_keywords'] = df_field['keyword']. \\\n",
    "        apply(lambda x: chopoff(x)). \\\n",
    "        apply(lambda x: x.strip()).apply(lambda x: x.strip().split('、'))\n",
    "    field_keyword = {}\n",
    "    field = df_field['field'].values\n",
    "    keyword = df_field['merged_keywords'].values\n",
    "    for fie, key in zip(field, keyword):\n",
    "        field_keyword[fie] = key\n",
    "    field_keyword['MESSLAH'] = ['MESSLAH', 'MESSLA'] ## some correction of data\n",
    "    ## storage section\n",
    "    df_dicts['storage'].columns = ['country', 'storage', 'keyword']\n",
    "    df_storage = df_dicts['storage']\n",
    "    storage_keyword = {}\n",
    "    storage = df_storage['storage'].values\n",
    "    keyword = df_storage['keyword'].values\n",
    "    for stor, key in zip(storage, keyword):\n",
    "        if re.search('/', key):\n",
    "            storage_keyword[stor] = key.split('/')\n",
    "        else:\n",
    "            storage_keyword[stor] = [key.strip()]\n",
    "    storage_keyword['MOLDOVA  (FALTICENI)'] = 'MOLDOVA'\n",
    "    storage_keyword['CHESHIRE (HOLFORD GS)'] = 'Cheshire'\n",
    "    storage_keyword['HILL TOP FARM  (CHESHIRE EXISTING)'] = 'Hill Top Farm'\n",
    "    storage_keyword['HILL TOP FARM  (CHESHIRE EXPANSION)'] = 'Hill Top Farm'\n",
    "    storage_keyword['KIRK RANCH  (BOBBY BURNS #1)'] = 'KIRK RANCH'\n",
    "    storage_keyword['CLEMENS NE  (FRIO B)'] = 'CLEMENS,N.E.'\n",
    "    ## get country according to the storage\n",
    "    storage_country = {}\n",
    "    storage = df_storage['storage'].values\n",
    "    country = df_storage['country'].values\n",
    "    for stor, coun in zip(storage, country):\n",
    "        storage_country[stor] = coun\n",
    "\n",
    "    mark_urls = get_mark_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage_country  #dictionary of one-one\n",
    "# country_region\n",
    "# company_business\n",
    "# topic_subcategory\n",
    "# company_country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_keywords_pair\n",
    "# state_keywords_pair\n",
    "# company_keyword_pair\n",
    "# topic_keywords\n",
    "# field_keyword\n",
    "# storage_keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b1846f22adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_df' is not defined"
     ]
    }
   ],
   "source": [
    "raw_df['new_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ==================== reach the process section for each category==================================\n",
    "    df= pd.DataFrame()\n",
    "    for table_pair in zip(table_name, table_name_pro):\n",
    "        pre_data = return_no_processed_df(table_pair[0], table_pair[1], engine)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = return_no_processed_df('hart_energy', 'hart_energy_pro', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_sql_table('hart_energy_pro',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'orig_id', 'source', 'title', 'abstracts', 'preview_img_link',\n",
       "       'url', 'format_pub_time', 'author', 'new_content', 'categories',\n",
       "       'img_urls_new', 'format_crawl_time', 'regions_merged', 'country_merged',\n",
       "       'company_keyword', 'country_matched_by_company_merged',\n",
       "       'subcategory_merged', 'topic_merged', 'field_keyword',\n",
       "       'storage_keyword', 'mark_note_by_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['new_content'] = raw['new_content'].apply(lambda x: extract_hart_energy_img_links(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<img alt=\"A&amp;D Transactions From The Week Of July 17, 2019\" height=\"723\" src=\"/sites/default/files/styles/news_article_image/public/image/2019/07/ad-transactions-week-july-17-2019.jpg?itok=OrDrtNdq\" width=\"1000\"/>\\nAlso, the buyer in last week’s deal for Encana’s Arkoma Basin assets is revealed.(Source: Hart Energy/Shutterstock.com)\\nHere’s a snapshot of energy deals from the past week featuring the $3.2 billion acquisition of Carrizo Oil & Gas by Callon Petroleum that included core positions in the Permian Basin and Eagle Ford Shale plus the buyer of Encana’s Arkoma Basin assets is revealed.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['new_content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    []\n",
       "1    []\n",
       "Name: new_content, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['new_content'].apply(lambda x: extract_hart_energy_img_links(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020/12/04'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(pre_data['pub_time'][0].replace(' ','-').replace(',',''),\\\n",
    "                  '%A-%d-%B-%Y-%H:%S').strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hart_energy_img_links(x):\n",
    "    '''extract img_links from content\n",
    "    '''\n",
    "    img_links = []\n",
    "    for ele in x:\n",
    "        if isinstance(ele, Tag):\n",
    "            if ele.name == 'img' and ele.has_attr('src') :\n",
    "                img_link = ele.attrs['src']\n",
    "                if re.match(r'^/', img_link):\n",
    "                    img_links.append((str(img_link), ele.attrs['alt']))\n",
    "\n",
    "    return img_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>pre_title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_time</th>\n",
       "      <th>preview_img_link</th>\n",
       "      <th>content</th>\n",
       "      <th>categories</th>\n",
       "      <th>crawl_time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Denmark to end exploration and production by 2050</td>\n",
       "      <td>Denmark has cancelled its latest licensing rou...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Friday, 04 December 2020 13:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chevron makes cuts to capital budget</td>\n",
       "      <td>Chevron has cut billions off its long-term cap...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Thursday, 03 December 2020 16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Equinor drills dry well in Barents Sea</td>\n",
       "      <td>The well was drilled about 100 km southwest of...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Friday, 04 December 2020 09:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Shearwater awarded OBN 4D baseline survey by P...</td>\n",
       "      <td>The survey will take place over the Jubarte fi...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Thursday, 26 November 2020 09:30</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>PGS resuming Campos Basin seismic survey in De...</td>\n",
       "      <td>The survey will provide the first 3D seismic d...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Monday, 30 November 2020 16:15</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 21:27</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>272</td>\n",
       "      <td>Johan Sverdrup field increases production capa...</td>\n",
       "      <td>The Johan Sverdrup field is increasing its dai...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Wednesday, 18 November 2020 16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Offshore &amp; subsea</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/offshore-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>273</td>\n",
       "      <td>Spirit Energy drills dry well near Ivar Aasen ...</td>\n",
       "      <td>The objective of the well was to prove petrole...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Wednesday, 05 August 2020 10:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>274</td>\n",
       "      <td>Neptune Energy confirms commercial oil discove...</td>\n",
       "      <td>The volumes are estimated to be in the range o...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Tuesday, 04 August 2020 09:30</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>275</td>\n",
       "      <td>Halliburton digital services to support Petron...</td>\n",
       "      <td>Halliburton Landmark will deliver DecisionSpac...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Tuesday, 04 August 2020 10:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Exploration</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/exploration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>276</td>\n",
       "      <td>KCA Deutag awarded Oman drilling contracts</td>\n",
       "      <td>KCA Deutag has been awarded contracts worth mo...</td>\n",
       "      <td>Nicholas Woodroof</td>\n",
       "      <td>Tuesday, 13 October 2020 11:00</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\\r\\n              ...</td>\n",
       "      <td>Drilling &amp; production</td>\n",
       "      <td>12/21/2020 22:29</td>\n",
       "      <td>https://www.oilfieldtechnology.com/drilling-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0      1  Denmark to end exploration and production by 2050   \n",
       "1      2               Chevron makes cuts to capital budget   \n",
       "2      3             Equinor drills dry well in Barents Sea   \n",
       "3      4  Shearwater awarded OBN 4D baseline survey by P...   \n",
       "4      5  PGS resuming Campos Basin seismic survey in De...   \n",
       "..   ...                                                ...   \n",
       "271  272  Johan Sverdrup field increases production capa...   \n",
       "272  273  Spirit Energy drills dry well near Ivar Aasen ...   \n",
       "273  274  Neptune Energy confirms commercial oil discove...   \n",
       "274  275  Halliburton digital services to support Petron...   \n",
       "275  276         KCA Deutag awarded Oman drilling contracts   \n",
       "\n",
       "                                             pre_title             author  \\\n",
       "0    Denmark has cancelled its latest licensing rou...  Nicholas Woodroof   \n",
       "1    Chevron has cut billions off its long-term cap...  Nicholas Woodroof   \n",
       "2    The well was drilled about 100 km southwest of...  Nicholas Woodroof   \n",
       "3    The survey will take place over the Jubarte fi...  Nicholas Woodroof   \n",
       "4    The survey will provide the first 3D seismic d...  Nicholas Woodroof   \n",
       "..                                                 ...                ...   \n",
       "271  The Johan Sverdrup field is increasing its dai...  Nicholas Woodroof   \n",
       "272  The objective of the well was to prove petrole...  Nicholas Woodroof   \n",
       "273  The volumes are estimated to be in the range o...  Nicholas Woodroof   \n",
       "274  Halliburton Landmark will deliver DecisionSpac...  Nicholas Woodroof   \n",
       "275  KCA Deutag has been awarded contracts worth mo...  Nicholas Woodroof   \n",
       "\n",
       "                              pub_time preview_img_link  \\\n",
       "0       Friday, 04 December 2020 13:00             None   \n",
       "1     Thursday, 03 December 2020 16:00             None   \n",
       "2       Friday, 04 December 2020 09:00             None   \n",
       "3     Thursday, 26 November 2020 09:30             None   \n",
       "4       Monday, 30 November 2020 16:15             None   \n",
       "..                                 ...              ...   \n",
       "271  Wednesday, 18 November 2020 16:00             None   \n",
       "272    Wednesday, 05 August 2020 10:00             None   \n",
       "273      Tuesday, 04 August 2020 09:30             None   \n",
       "274      Tuesday, 04 August 2020 10:00             None   \n",
       "275     Tuesday, 13 October 2020 11:00             None   \n",
       "\n",
       "                                               content             categories  \\\n",
       "0    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "1    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "2    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "3    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "4    <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "..                                                 ...                    ...   \n",
       "271  <div itemprop=\"articleBody\">\\r\\n              ...      Offshore & subsea   \n",
       "272  <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "273  <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "274  <div itemprop=\"articleBody\">\\r\\n              ...            Exploration   \n",
       "275  <div itemprop=\"articleBody\">\\r\\n              ...  Drilling & production   \n",
       "\n",
       "           crawl_time                                                url  \n",
       "0    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "1    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "2    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "3    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "4    12/21/2020 21:27  https://www.oilfieldtechnology.com/exploration...  \n",
       "..                ...                                                ...  \n",
       "271  12/21/2020 22:29  https://www.oilfieldtechnology.com/offshore-an...  \n",
       "272  12/21/2020 22:29  https://www.oilfieldtechnology.com/exploration...  \n",
       "273  12/21/2020 22:29  https://www.oilfieldtechnology.com/exploration...  \n",
       "274  12/21/2020 22:29  https://www.oilfieldtechnology.com/exploration...  \n",
       "275  12/21/2020 22:29  https://www.oilfieldtechnology.com/drilling-an...  \n",
       "\n",
       "[276 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data['pub_time'] = pre_data['pub_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"sj-main\">\\n        \\n          <div class=\"as04\" style=\" display:block; width:650px;\">\\n\\n          \\t <p style=\"text-align:left\"><strong>\\u3000\\u3000中国石油网消息</strong>（特约记者李冬铃\\xa0通讯员于春晶）抚顺石化石油二厂组织干部员工开动脑筋集思广益，用智慧实现持续挖潜创效。7月31日统计数据显示，上半年，石油二厂制氢车间员工通过优化、改造水系统，创效达490余万元。</p>\\r\\n\\r\\n<p style=\"text-align:left\">\\u3000\\u3000制氢车间在生产过程中，一方面要利用脱盐水生产蒸汽，另一方面装置产生的凝结水还要排放掉，如何让两者合二为一用凝结水产生蒸汽，成为这个车间做活“水文章”的主要攻关方向。这个厂强化自产凝结水管理，解决了自产凝结水电导率超标的问题，然后将其回收到除氧器代替新鲜脱盐水生产蒸汽。项目实施后，每小时回收凝结水36吨、节省除盐水36吨，降低了生产成本。</p>\\r\\n\\r\\n<p style=\"text-align:left\">\\u3000\\u3000不仅如此，这个车间又将循环利用的着眼点放在排水上。技术人员对自产排水进行水质分析后发现，各项指标优于循环水场的补水指标，对工艺流程进行改造后，将排水接入循环水管线，用作循环水场补水使用，实施后每小时可节约循环水4吨。在此基础上，这个车间合理整定配汽控制阀PID参数，实现了制氢装置自产中压蒸汽稳定并网，解决了低压蒸汽过剩、中压蒸汽不足的问题，每月为企业节省外购中压蒸汽费用。</p>\\r\\n\\r\\n<p style=\"text-align:left\">\\u3000\\u3000制氢装置转化炉是原料与水蒸气发生转化反应的关键场所，炉膛负压的高低直接关系到装置安全生产、能耗和转化反应完成情况。这个车间严格控制转化炉氧含量及排烟温度，及时调整逆放调节阀开度，适时调整PIC-4005压力控制值，控制解吸气流量相对平稳。通过这一系列优化措施，避免了炉膛负压波动引起装置联锁停车的风险，同时提高了氢气收率，转化炉热效率也提升至92.8%，为企业节能创效增添了新的增长点。</p>\\r\\n \\r\\n\\r\\n\\r\\n\\r\\n          \\t\\n          \\t</div>\\n        </div>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data['content']laooly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wash_hart_energy_process(x,class_name):\n",
    "    '''\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div',attrs={'class':class_name})\n",
    "#     print(an)\n",
    "    for child in [child for child in ancestor.children if not isinstance(child,NavigableString)][:2]:\n",
    "        for desc in child.descendants:\n",
    "            if desc.name == 'img' and desc.has_attr('src'):\n",
    "                contents.append(desc)\n",
    "            if desc.name == 'p' and not desc.has_attr('class'):\n",
    "                contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "            if desc.name == 'div' and desc.has_attr('class') and desc.attrs['class']==\"userAlready\":\n",
    "                break\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_oil(x,attrs):\n",
    "    '''grab \n",
    "    '''\n",
    "    contents = []\n",
    "    chop_index = None\n",
    "    soup = BeautifulSoup(test, 'lxml')\n",
    "    ancestor = soup.find('div',attrs={'id':'news'})\n",
    "    # print(list(ancestor.children))\n",
    "    for child in [child for child in ancestor.children if not isinstance(child,NavigableString)]:\n",
    "    #     print(child)\n",
    "        if child.name=='p'and not child.has_attr('class')  :\n",
    "            contents.append(child.text.replace(u'\\xa0', u''))\n",
    "    #     elif child.name=='p'and child.find('strong') and not child.find('strong'):\n",
    "    #         break\n",
    "        elif child.name=='div':\n",
    "            for desc in child.descendants:\n",
    "                if not isinstance(desc,NavigableString):\n",
    "                    if desc.name == 'img' and desc.has_attr('src') and re.search('/media',desc.attrs['src']):\n",
    "                        contents.append(desc)\n",
    "        elif child.name=='h2' and re.search(r'Related News',child.string):\n",
    "            break\n",
    "\n",
    "    if contents.index('REFERENCES'):\n",
    "        chop_index = contents.index('REFERENCES')\n",
    "    contents = contents[:chop_index]\n",
    "        \n",
    "    return contents\n",
    "\n",
    "    \n",
    "\n",
    "#     else:\n",
    "#         continue\n",
    "#         if desc.name == 'p' and not desc.has_attr('class'):\n",
    "#             contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "#         if desc.name =='p' and desc.find('strong'):\n",
    "#             break\n",
    "#         if desc.name == 'p' and desc.has('class') and desc.attrs['class']==\"userAlready\":\n",
    "#             break\n",
    "\n",
    "# return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = world_oil(test,attrs={'id':'news'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = req.get('https://www.worldoil.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_oil_hot():\n",
    "    '''get front page url'''\n",
    "    ele_urls = []\n",
    "    host='https://www.worldoil.com'\n",
    "    res = req.get(host)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    cols = soup.find_all('div',attrs={'class':'col-sm-6'})[:2]\n",
    "    for col in cols:\n",
    "    #     print(col)\n",
    "        urls = col.find_all('a')\n",
    "        for url in urls:\n",
    "            ele_urls.append(host+url['href'])\n",
    "    return ele_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hart_energy_hot():\n",
    "    \n",
    "    ele_urls = []\n",
    "    host='https://www.hartenergy.com'\n",
    "    res = req.get(host)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    latest = soup.find('div',attrs={'id':'homepage-latest'})\n",
    "    rows  = latest.find_all('a')\n",
    "    for row in rows[:-1]:\n",
    "        ele_urls.append(host+row['href'])\n",
    "    return ele_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_cnpc_hot():\n",
    "    '''compare with the tiltes'''\n",
    "    titles=[]\n",
    "    host='http://news.cnpc.com.cn/toutiao/'\n",
    "    res = req.get(host)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    lists = soup.find('div',attrs={'class':'list18'})\n",
    "    for row in lists.find_all('li',attrs={'class':'ejli'}):\n",
    "        title = row.find('a').text.strip()\n",
    "        titles.append(title)\n",
    "        \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '10/23/2020' does not match format '%d/%m/%Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-192432522654>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# '10/23/2020' does not match format '%d/%m/%Y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'10/23/2020'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%d/%m/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[1;32m    567\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0m\u001b[1;32m    350\u001b[0m                          (data_string, format))\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data '10/23/2020' does not match format '%d/%m/%Y'"
     ]
    }
   ],
   "source": [
    "# '10/23/2020' does not match format '%d/%m/%Y'\n",
    "datetime.strptime('10/23/2020','%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wash_process(x,class_name):\n",
    "    '''\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div',attrs={'class':class_name})\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "            contents.append(desc)\n",
    "        if desc.name == 'p' and not desc.has_attr('class'):\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "        if desc.name == 'div' and desc.has_attr('class') and desc.attrs['class']==\"userAlready\":\n",
    "            break\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = pd.read_sql_table('hart_energy',engine,columns=['id','title','content','url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_content = pre_data['content'].apply(lambda x:wash_hart_energy_process(x,'article-content-wrapper'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-183da3c1cdd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ==================== reach the process section for each category==================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtable_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name_pro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpre_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_no_processed_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table_name' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "        print(pre_data.head())\n",
    "#         print(pre_data.head(),pre_data.info(),type(pre_data))\n",
    "        if len(pre_data) == 0:  ## no dataframe needed to be processed\n",
    "            break\n",
    "        else:\n",
    "            raw_df = pre_data.iloc[0:1]\n",
    "            if re.search(r'_oe',table_pair[0]): ## oedigital form of data\n",
    "                raw_df['format_pub_time'] = raw_df['pub_time']\\\n",
    "                .apply(lambda x: datetime.strptime(x, \"%B %d, %Y\").strftime('%Y/%m/%d'))\\\n",
    "                .apply(lambda x:datetime.strptime(x,\"%Y/%m/%d\"))\n",
    "                  ##make the dataframe name consistent\n",
    "                # print(raw_df['url'][0],raw_df['content'],raw_df['content'][0],type(raw_df['content'][0]))\n",
    "                # break\n",
    "            raw_df['new_content'] = raw_df['content'].apply(lambda x: wash_process(x, div_class_name))\n",
    "            raw_df['img_urls_new'] = raw_df['new_content'].apply(lambda x: extract_img_links(x))\n",
    "            # raw_df['new_content'] =\n",
    "\n",
    "            raw_df['format_crawl_time'] = raw_df['crawl_time'].apply(lambda x: x.strip()[:10]) \\\n",
    "                .apply(lambda x: datetime.strptime(x, \"%m/%d/%Y\").strftime('%Y/%m/%d')) \\\n",
    "                .apply(lambda x:datetime.strptime(x,\"%Y/%m/%d\"))\n",
    "#             print(raw_df.head())\n",
    "            \n",
    "\n",
    "            df = raw_df[['id', 'author', 'categories', 'preview_img_link',\n",
    "                             'title', 'url', 'new_content', 'img_urls_new',\n",
    "                             'format_pub_time', 'format_crawl_time']]\n",
    "\n",
    "            ## create first checkpoint\n",
    "            ## country keyword section\n",
    "            df['country_keyword'] = df['new_content'].astype('str'). \\\n",
    "                apply(lambda x: match_keyword(x, country_keywords_pair))\n",
    "            ## region keyword sections\n",
    "            ## perform the matching according to the region keywords\n",
    "            df['region_keywords'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_keyword(x, state_keywords_pair))\n",
    "\n",
    "            ## determin the region according to the country keyword\n",
    "            df['regions_country'] = df['country_keyword'] \\\n",
    "                .apply(lambda x: match_country_region(x, country_region))\n",
    "            print('reach to process company section')\n",
    "            ## company sections\n",
    "            df['company_keyword'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_company(x, company_keyword_pair))\n",
    "            df['business_company'] = df['company_keyword']. \\\n",
    "                apply(lambda x: match_country_region(x, company_business))\n",
    "            df['country_matched_by_company'] = df['company_keyword']. \\\n",
    "                apply(lambda x: match_country_region(x, company_country))\n",
    "\n",
    "            ## topic section\n",
    "            df['topic_keyword'] = df['new_content'].astype('str').apply(lambda x: match_topic(x, topic_keywords))\n",
    "            df['topic_keyword'] = df['business_company'] + df['topic_keyword']\n",
    "            df['subcategory_by_topic'] = df['topic_keyword']. \\\n",
    "                apply(lambda x: match_country_region(x, topic_subcategory))\n",
    "\n",
    "            ##field section\n",
    "            df['field_keyword'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_company(x, field_keyword))\n",
    "\n",
    "            ## storage section\n",
    "            df['storage_keyword'] = df['new_content'].astype('str') \\\n",
    "                .apply(lambda x: match_storage(x, storage_keyword))\n",
    "            df['country_storage'] = df['storage_keyword'] \\\n",
    "                .apply(lambda x: match_country_region(x, storage_country))\n",
    "            ## mark or not\n",
    "            df['mark_note_by_url'] = df['url'].apply(lambda x: mark_url(x, mark_urls))\n",
    "\n",
    "            print('reach to post process of data')\n",
    "            ##post process\n",
    "            df['regions'] = df['region_keywords'] + df['regions_country']\n",
    "            df['country'] = df['country_keyword']\n",
    "            df['company_merged'] = df['company_keyword'].apply(lambda x: add_same_key(x))\n",
    "            df['regions_merged'] = df['regions'].apply(lambda x: add_same_key(x))\n",
    "            df['country_merged'] = df['country'].apply(lambda x: add_same_key(x))\n",
    "            df['topic_merged'] = df['topic_keyword'].apply(lambda x: add_same_key(x))\n",
    "            df['subcategory_merged'] = df['subcategory_by_topic'].apply(lambda x: add_same_key(x))\n",
    "            df['country_matched_by_company_merged'] = df['country_matched_by_company'].apply(lambda x: add_same_key(x))\n",
    "\n",
    "            df['new_content'] = raw_df['new_content'] \\\n",
    "                .apply(lambda x: '\\n'.join([str(ele).strip() for ele in x]))\n",
    "\n",
    "            df['topic_merged'] = df['topic_merged'].astype('str').apply(lambda x: remove_intell_topic(x))\n",
    "            df['topic_merged'] = df['topic_merged'].astype('str')\n",
    "            spend_time = round(time.time() -start_time,1)\n",
    "#             print('spend time',spend_time,' to process data',df.info())\n",
    "            df['source'] = 'www.oedigital.com'\n",
    "            df['abstracts'] = df['title']\n",
    "\n",
    "            result = df[['source', 'title', 'abstracts', 'preview_img_link', 'url', 'format_pub_time',\n",
    "                         'author', 'new_content', 'categories',\n",
    "                         'img_urls_new', 'format_crawl_time', 'regions_merged',\n",
    "                         'country_merged', 'company_keyword', 'country_matched_by_company_merged',\n",
    "                         'subcategory_merged', 'topic_merged', 'field_keyword', 'storage_keyword', 'mark_note_by_url'\n",
    "                         ]]\n",
    "            result['orig_id']=df['id']\n",
    "#             result.index =df.index\n",
    "#             print('the column name of result is',result.columns)\n",
    "            # print(result.head(),result.columns,result.info(),result[0:1].values)\n",
    "            result['preview_img_link'] = result['preview_img_link'].astype('str')\n",
    "            result['img_urls_new'] = result['img_urls_new'].astype('str')\n",
    "            result['regions_merged'] = result['regions_merged'].astype('str')\n",
    "            result['country_merged'] = result['country_merged'].astype('str')\n",
    "            result['company_keyword'] = result['company_keyword'].astype('str')\n",
    "            result['country_matched_by_company_merged'] = result['country_matched_by_company_merged'].astype('str')\n",
    "            result['subcategory_merged'] = result['subcategory_merged'].astype('str')\n",
    "            result['field_keyword'] = result['field_keyword'].astype('str')\n",
    "            result['storage_keyword'] = result['storage_keyword'].astype('str')\n",
    "            result['mark_note_by_url'] = result['mark_note_by_url'].astype('str')\n",
    "            # test = result[0:1].values\n",
    "#             print(result.info())\n",
    "#             result.to_csv('oe_backup.csv')\n",
    "            # print(result.iloc[0:1].values)\n",
    "#             print(result.columns)\n",
    "#             result_post =pd.read_csv('oe_backup.csv')\n",
    "\n",
    "\n",
    "            result.to_sql(table_pair[1],engine,if_exists='append',index=False)\n",
    "#             result_post.to_sql('test_table_1',engine,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_abstracts = df['new_content'][0][:340]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstracts'] = df['new_content'].apply(lambda) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_abstracts = df['new_content'][0]\n",
    "def gen_abstracts(x):\n",
    "    '''generate new abstracts'''\n",
    "    span_length = 0\n",
    "    if re.search('<img .+>',x):\n",
    "        img_tags = re.findall('<img .+>',x)\n",
    "        for img_tag in img_tags:\n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tags = re.finditer('<img .+>',df['new_content'][0])\n",
    "\n",
    "tags = [img_tag for img_tag in img_tags]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 309)\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "taken_length = 0\n",
    "## if length>340:\n",
    "for i in range(len(tags)):\n",
    "    take_by_img = tag.span()\n",
    "    if take_by_img[0]<340:\n",
    "        print(take_by_img)\n",
    "        img_tag_length = take_by_img[1] - take_by_img[0]\n",
    "        print(img_tag_length)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_energy_china(x,attrs):\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src') and \\\n",
    "         not re.search('erweima',desc.attrs['src']):\n",
    "    #         contents.append(desc)\n",
    "            contents.append(desc)\n",
    "        if desc.name =='p' and re.search('新闻时间',desc.text):\n",
    "            break\n",
    "        if desc.name =='p' and re.search('来源：',desc.text):\n",
    "            continue\n",
    "        elif desc.name == 'p' and len(desc.text)>0:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_china_five(x,attrs):\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "            contents.append(desc)\n",
    "        elif desc.name=='p' and re.search(r'责任编辑',desc.text):\n",
    "            break\n",
    "        elif desc.name == 'p' and len(desc.text)>0:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_sql_table('offshore_energy',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_offshore_enregy(x,attributes):\n",
    "    '''wash energy year\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attributes)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "            contents.append(desc)\n",
    "    #         contents.append(desc)\n",
    "#         if desc.name=='p' and re.search(r'First published',desc.text):\n",
    "#             break\n",
    "        elif desc.name == 'p' and len(desc.text)>1:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "        elif desc.name=='div' and desc.has_attr('class') and  \\\n",
    "            'block-related-article' in desc.attrs['class']:\n",
    "            break\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['new_content'] = raw_df['content'].  \\\n",
    "                apply(lambda x:wash_offshore_enregy(x,{'class':'wp-content'}))\n",
    "raw_df['format_pub_time'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'January 22, 2021'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['pub_time'].values[1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data 'January 20, 2021' does not match format '%B %d,%Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-a6826dab9c59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'format_pub_time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pub_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%B %d,%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-a6826dab9c59>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mraw_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'format_pub_time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pub_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m                             \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%B %d,%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[1;32m    567\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0m\u001b[1;32m    350\u001b[0m                          (data_string, format))\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data 'January 20, 2021' does not match format '%B %d,%Y'"
     ]
    }
   ],
   "source": [
    "raw_df['format_pub_time'] = raw_df['pub_time'] \\\n",
    "                            .apply(lambda x: datetime.strptime(x[:-1],'%B %d,%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "soup = BeautifulSoup(raw_df['content'].values[0], 'lxml')\n",
    "ancestor = soup.find('div', attrs={'class':'wp-content'})\n",
    "for desc in ancestor.descendants:\n",
    "    if desc.name == 'img' and desc.has_attr('src'):\n",
    "        contents.append(desc)\n",
    "#         contents.append(desc)\n",
    "#         if desc.name=='p' and re.search(r'First published',desc.text):\n",
    "#             break\n",
    "    elif desc.name == 'p' and len(desc.text)>1:\n",
    "        contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "    elif desc.name=='div' and desc.has_attr('class') and  \\\n",
    "        'block-related-article' in desc.attrs['class']:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"wp-content\">\\n    \\n<p><strong>Elon Musk’s SpaceX, an aerospace manufacturer and space transportation services company, reportedly bought two Valaris rigs last year to convert them into floating launchpads for its Starship rockets. </strong></p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img src=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500.jpg\" alt=\"Valaris 8500 rig - Valaris\" class=\"wp-image-419609\" srcset=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500.jpg 673w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500-300x259.jpg 300w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500-151x130.jpg 151w\" sizes=\"(max-width: 673px) 100vw, 673px\"><figcaption>Valaris 8500 rig; Source: Valaris</figcaption></figure>\\n\\n\\n\\n<p>According to a <a rel=\"noreferrer noopener\" aria-label=\"Tuesday report by CNBC (opens in a new tab)\" href=\"https://www.cnbc.com/2021/01/19/spacex-bought-former-valaris-oil-rigs-to-build-starship-launchpads.html\" target=\"_blank\">Tuesday report by CNBC</a>, SpaceX bought two Valaris rigs, Valaris 8500 and Valaris 8501, to support the enormous Starship rockets that the company is developing.</p>\\n\\n\\n\\n<p>Before they were bought, the two rigs were preservation stacked in the U.S. Gulf of Mexico, Valaris’ fleet status report shows. They were built in 2008 and 2009, respectively.  </p>\\n\\n\\n\\n<p>Now, CNBC reported, the two rigs have been renamed Deimos and Phobos and they are located in the Port of Brownsville, near SpaceX’s Starship development facility in Boca Chica, Texas.</p>\\n\\n\\n\\n<p>Public records show that the two semi-submersible drilling rigs were sold for $3.5 million each before <a rel=\"noreferrer noopener\" aria-label=\"Valaris filed for Chapter 11 (opens in a new tab)\" href=\"https://www.offshore-energy.biz/valaris-declares-chapter-11-bankruptcy/\" target=\"_blank\">Valaris filed for Chapter 11</a> bankruptcy in August last year in an attempt to restructure its debt.</p>\\n\\n\\n<div class=\"section\">\\n\\t<div class=\"block block-related-article align-wide\">\\n\\t\\t<div class=\"block__header\">\\n\\t\\t\\t<h2 class=\"section__title section__title--bordered\">\\n\\t\\t\\t\\tRelated Article\\n\\t\\t\\t</h2>\\n\\t\\t</div>\\n\\t\\t\\t\\t\\t\\n\\n<div class=\"card-rich card-small \">\\n\\t<span class=\"card__lazyload card-rich__image\" style=\"background-image: url(\\'https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2020/08/20094958/Valaris-1024x676.jpg\\');\">\\n\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\t\\t<div class=\"card-rich__element card-rich__time-ago\">\\n\\t\\t\\t\\t<span class=\"screen-reader-text\">Posted:</span> 5 months ago\\n\\t\\t\\t</div>\\n\\t\\t\\t</span>\\n\\n\\t<div class=\"card-rich__content\">\\n\\t\\t\\n\\n\\t\\t<h3 class=\"card-rich__title\">\\n\\t\\t\\t<a href=\"https://www.offshore-energy.biz/valaris-declares-chapter-11-bankruptcy/\" class=\"card-small__link\" aria-label=\"Read more about Valaris declares Chapter 11 bankruptcy\">\\n\\t\\t\\t\\tValaris declares Chapter 11 bankruptcy\\n\\t\\t\\t</a>\\n\\t\\t</h3>\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"card-rich__element card-rich__meta\">\\n\\t\\t\\t\\t\\t<span class=\"screen-reader-text\">Categories:</span>\\n\\t\\t\\t\\t\\t<ul class=\"card-category-list no-list\">\\n\\t\\t\\t\\t\\t\\t<li class=\"card-category-list__item\">Business &amp; Finance</li>\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\n\\t\\t<div class=\"card__element card-rich__time-ago\">\\n\\t\\t\\t<span class=\"screen-reader-text\">Posted:</span> 5 months ago\\n\\t\\t</div>\\n\\t</div>\\n</div>\\n\\t\\t\\t</div>\\n</div>\\n\\n\\n\\n<p>Following the Chapter 11 filing, the rig owner received a notice of immediate <a rel=\"noreferrer noopener\" aria-label=\" (opens in a new tab)\" href=\"https://www.offshore-energy.biz/nyse-to-delist-valaris-stock-following-chapter-11-filing/\" target=\"_blank\">suspension of trading</a> and delisting of common stock from the New York Stock Exchange (NYSE).</p>\\n\\n\\n\\n<p>Effective 19 August 2020, the company’s common stock started trading on the OTC Pink marketplace under the symbol “VALPQ.”</p>\\n\\n\\n\\n<p>In late September 2020, <a rel=\"noreferrer noopener\" aria-label=\"Valaris gained access to additional liquidity (opens in a new tab)\" href=\"https://www.offshore-energy.biz/valaris-gains-access-to-additional-liquidity/\" target=\"_blank\">Valaris gained access to additional liquidity</a> following the execution of a new term loan credit agreement. </p>\\n\\n\\n\\n<p>According to SpaceX’s website, <a href=\"https://www.spacex.com/vehicles/starship/\" target=\"_blank\" rel=\"noreferrer noopener\" aria-label=\"Starship (opens in a new tab)\">Starship</a> spacecraft and Super Heavy rocket (collectively referred to as Starship) represent a fully reusable transportation system designed to carry both crew and cargo to Earth orbit, the Moon, Mars and beyond.</p>\\n\\n\\n\\n<p>The company’s Starship SN8 had a test flight last December.</p>\\n\\n\\n\\n<p>As detailed by CNBC, the two rigs were bought in July last year by limited liability corporation Lone Star Mineral Development, which was incorporated in June 2020 and registered in the name of SpaceX CFO <strong>Bret Johnsen</strong>.</p>\\n\\n\\n\\n<p>Offshore Energy has reached out to Valaris seeking confirmation about the sale of the two rigs but the rig owner declined to comment. </p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img src=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501.jpg\" alt=\"Valaris 8501 rig\" class=\"wp-image-419628\" srcset=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501.jpg 680w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501-300x259.jpg 300w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501-151x130.jpg 151w\" sizes=\"(max-width: 680px) 100vw, 680px\"><figcaption>Valaris 8501 rig; Source: Valaris</figcaption></figure>\\n\\n\\n\\n<p>In related news, U.S. oil company <a rel=\"noreferrer noopener\" aria-label=\"Occidental Petroleum (opens in a new tab)\" href=\"https://www.offshore-energy.biz/occidental-doing-more-than-tesla-to-reduce-carbon-emissions/\" target=\"_blank\">Occidental Petroleum</a> claims that it is doing more than Tesla, an American electric vehicle and clean energy company led by Elon Musk, to reduce greenhouse gas emissions.</p>\\n\\n\\n\\n<p>The statement reflects Occidental’s attempt to build up its carbon management business in response to investor demands over climate change.</p>\\n\\n</div>'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['content'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['new_content'] = raw_df['content'].  \\\n",
    "                apply(lambda x:wash_china_five(x,{'id':'showcontent'}))\n",
    "raw_df['format_pub_time'] = raw_df['pub_time'] \\\n",
    "            .apply(lambda x:datetime.strptime(x,'%Y-%m-%d'))\n",
    "raw_df['source'] =  'https://www.china5e.com/news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"wp-content\">\\n    \\n<p><strong>Elon Musk’s SpaceX, an aerospace manufacturer and space transportation services company, reportedly bought two Valaris rigs last year to convert them into floating launchpads for its Starship rockets. </strong></p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img src=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500.jpg\" alt=\"Valaris 8500 rig - Valaris\" class=\"wp-image-419609\" srcset=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500.jpg 673w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500-300x259.jpg 300w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500-151x130.jpg 151w\" sizes=\"(max-width: 673px) 100vw, 673px\"><figcaption>Valaris 8500 rig; Source: Valaris</figcaption></figure>\\n\\n\\n\\n<p>According to a <a rel=\"noreferrer noopener\" aria-label=\"Tuesday report by CNBC (opens in a new tab)\" href=\"https://www.cnbc.com/2021/01/19/spacex-bought-former-valaris-oil-rigs-to-build-starship-launchpads.html\" target=\"_blank\">Tuesday report by CNBC</a>, SpaceX bought two Valaris rigs, Valaris 8500 and Valaris 8501, to support the enormous Starship rockets that the company is developing.</p>\\n\\n\\n\\n<p>Before they were bought, the two rigs were preservation stacked in the U.S. Gulf of Mexico, Valaris’ fleet status report shows. They were built in 2008 and 2009, respectively.  </p>\\n\\n\\n\\n<p>Now, CNBC reported, the two rigs have been renamed Deimos and Phobos and they are located in the Port of Brownsville, near SpaceX’s Starship development facility in Boca Chica, Texas.</p>\\n\\n\\n\\n<p>Public records show that the two semi-submersible drilling rigs were sold for $3.5 million each before <a rel=\"noreferrer noopener\" aria-label=\"Valaris filed for Chapter 11 (opens in a new tab)\" href=\"https://www.offshore-energy.biz/valaris-declares-chapter-11-bankruptcy/\" target=\"_blank\">Valaris filed for Chapter 11</a> bankruptcy in August last year in an attempt to restructure its debt.</p>\\n\\n\\n<div class=\"section\">\\n\\t<div class=\"block block-related-article align-wide\">\\n\\t\\t<div class=\"block__header\">\\n\\t\\t\\t<h2 class=\"section__title section__title--bordered\">\\n\\t\\t\\t\\tRelated Article\\n\\t\\t\\t</h2>\\n\\t\\t</div>\\n\\t\\t\\t\\t\\t\\n\\n<div class=\"card-rich card-small \">\\n\\t<span class=\"card__lazyload card-rich__image\" style=\"background-image: url(\\'https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2020/08/20094958/Valaris-1024x676.jpg\\');\">\\n\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\t\\t<div class=\"card-rich__element card-rich__time-ago\">\\n\\t\\t\\t\\t<span class=\"screen-reader-text\">Posted:</span> 5 months ago\\n\\t\\t\\t</div>\\n\\t\\t\\t</span>\\n\\n\\t<div class=\"card-rich__content\">\\n\\t\\t\\n\\n\\t\\t<h3 class=\"card-rich__title\">\\n\\t\\t\\t<a href=\"https://www.offshore-energy.biz/valaris-declares-chapter-11-bankruptcy/\" class=\"card-small__link\" aria-label=\"Read more about Valaris declares Chapter 11 bankruptcy\">\\n\\t\\t\\t\\tValaris declares Chapter 11 bankruptcy\\n\\t\\t\\t</a>\\n\\t\\t</h3>\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"card-rich__element card-rich__meta\">\\n\\t\\t\\t\\t\\t<span class=\"screen-reader-text\">Categories:</span>\\n\\t\\t\\t\\t\\t<ul class=\"card-category-list no-list\">\\n\\t\\t\\t\\t\\t\\t<li class=\"card-category-list__item\">Business &amp; Finance</li>\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\n\\t\\t<div class=\"card__element card-rich__time-ago\">\\n\\t\\t\\t<span class=\"screen-reader-text\">Posted:</span> 5 months ago\\n\\t\\t</div>\\n\\t</div>\\n</div>\\n\\t\\t\\t</div>\\n</div>\\n\\n\\n\\n<p>Following the Chapter 11 filing, the rig owner received a notice of immediate <a rel=\"noreferrer noopener\" aria-label=\" (opens in a new tab)\" href=\"https://www.offshore-energy.biz/nyse-to-delist-valaris-stock-following-chapter-11-filing/\" target=\"_blank\">suspension of trading</a> and delisting of common stock from the New York Stock Exchange (NYSE).</p>\\n\\n\\n\\n<p>Effective 19 August 2020, the company’s common stock started trading on the OTC Pink marketplace under the symbol “VALPQ.”</p>\\n\\n\\n\\n<p>In late September 2020, <a rel=\"noreferrer noopener\" aria-label=\"Valaris gained access to additional liquidity (opens in a new tab)\" href=\"https://www.offshore-energy.biz/valaris-gains-access-to-additional-liquidity/\" target=\"_blank\">Valaris gained access to additional liquidity</a> following the execution of a new term loan credit agreement. </p>\\n\\n\\n\\n<p>According to SpaceX’s website, <a href=\"https://www.spacex.com/vehicles/starship/\" target=\"_blank\" rel=\"noreferrer noopener\" aria-label=\"Starship (opens in a new tab)\">Starship</a> spacecraft and Super Heavy rocket (collectively referred to as Starship) represent a fully reusable transportation system designed to carry both crew and cargo to Earth orbit, the Moon, Mars and beyond.</p>\\n\\n\\n\\n<p>The company’s Starship SN8 had a test flight last December.</p>\\n\\n\\n\\n<p>As detailed by CNBC, the two rigs were bought in July last year by limited liability corporation Lone Star Mineral Development, which was incorporated in June 2020 and registered in the name of SpaceX CFO <strong>Bret Johnsen</strong>.</p>\\n\\n\\n\\n<p>Offshore Energy has reached out to Valaris seeking confirmation about the sale of the two rigs but the rig owner declined to comment. </p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img src=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501.jpg\" alt=\"Valaris 8501 rig\" class=\"wp-image-419628\" srcset=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501.jpg 680w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501-300x259.jpg 300w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501-151x130.jpg 151w\" sizes=\"(max-width: 680px) 100vw, 680px\"><figcaption>Valaris 8501 rig; Source: Valaris</figcaption></figure>\\n\\n\\n\\n<p>In related news, U.S. oil company <a rel=\"noreferrer noopener\" aria-label=\"Occidental Petroleum (opens in a new tab)\" href=\"https://www.offshore-energy.biz/occidental-doing-more-than-tesla-to-reduce-carbon-emissions/\" target=\"_blank\">Occidental Petroleum</a> claims that it is doing more than Tesla, an American electric vehicle and clean energy company led by Elon Musk, to reduce greenhouse gas emissions.</p>\\n\\n\\n\\n<p>The statement reflects Occidental’s attempt to build up its carbon management business in response to investor demands over climate change.</p>\\n\\n</div>'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['content'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['原油价格大幅回升。2020年12月，布伦特原油均价50.0美元/桶，环比上升7.22美元/桶（16.87%），WTI原油均价47.1美元/桶，环比上升5.55美元/桶（13.36%），布伦特-WTI价差环比扩大至2.95美元/桶。',\n",
       " 'OPEC产量：12月产量环比增长28万桶/天；减产执行率102%，环比略降。',\n",
       " '根据OPEC1月月报中二手数据源显示，2020年12月，OPEC原油总产量2536万桶/天，环比增长28万桶/天，产量增长主要来自利比亚、伊拉克和阿联酋。',\n",
       " 'OPEC减产国整体维持全额减产，根据我们测算，OPEC减产国12月减产执行率102%，较上月略降2%。',\n",
       " '美国原油市场跟踪。根据EIA2021年1月短期能源展望，美国2020年12月原油产量达到1099万桶/日，同比下滑14.2%，环比减少0.2%；EIA预计美国2021年全年平均产量1110万桶/日，较12月预测持平，较2020年年均产量减少19万桶/日（-1.7%）。2020年12月底美国商业原油库存4.86亿桶，环比-3.5%。',\n",
       " 'EIA预计到2021年底将达到4.60亿桶，较上月预测下降790万桶，该库存水平处于2015-2019年同期库存范围内。',\n",
       " '2020年12月原油进口同比下降15.4%。2020年12月，我国进口原油3847万吨，同比-15.4%。2020年1-12月，我国累计进口原油5.42亿吨，同比增长7.2%。2020年12月，我国原油进口均价为44.05美元/桶。2020年12月，我国成品油出口量590万吨，同比-13.1%；成品油进口量218万吨，净出口量373万吨，同比7.2%。2020年1-12月，我国成品油出口量6186万吨，同比-7.5%；成品油进口量2849万吨，同比-6.8%；净出口量3337万吨，同比-8.1%。',\n",
       " '2020年12月天然气进口同比增长18.0%。2020年12月，我国进口天然气149.3亿方，同比增长18.0%。2020年1-12月，我国累计进口天然气1355.6亿方，同比上升5.1%。12月天然气进口金额为36.07亿美元，同比减少7.2%，按当月平均汇率计算，12月我国天然气进口均价为1.58元/方。',\n",
       " '12月乙烯-石脑油价差环比持续改善。2020年12月，在我们跟踪的19种石化产品中，有10种产品价差环比改善，值得关注的是其中乙烯-石脑油价差环比上涨8.3%，同比增加236.6%，延续上月升势。此外，丙烯-石脑油价差同比增长178.9%，丁二烯-石脑油价差同比增长155.5%，丙烯-1.2*丙烷价差同比增长172.1%，甲醇-1.5*无烟煤价差同比增长127.3%，环比上涨32.1%。']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['new_content'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['原油价格大幅回升。2020年12月，布伦特原油均价50.0美元/桶，环比上升7.22美元/桶（16.87%），WTI原油均价47.1美元/桶，环比上升5.55美元/桶（13.36%），布伦特-WTI价差环比扩大至2.95美元/桶。',\n",
       " 'OPEC产量：12月产量环比增长28万桶/天；减产执行率102%，环比略降。',\n",
       " '根据OPEC1月月报中二手数据源显示，2020年12月，OPEC原油总产量2536万桶/天，环比增长28万桶/天，产量增长主要来自利比亚、伊拉克和阿联酋。',\n",
       " 'OPEC减产国整体维持全额减产，根据我们测算，OPEC减产国12月减产执行率102%，较上月略降2%。',\n",
       " '美国原油市场跟踪。根据EIA2021年1月短期能源展望，美国2020年12月原油产量达到1099万桶/日，同比下滑14.2%，环比减少0.2%；EIA预计美国2021年全年平均产量1110万桶/日，较12月预测持平，较2020年年均产量减少19万桶/日（-1.7%）。2020年12月底美国商业原油库存4.86亿桶，环比-3.5%。',\n",
       " 'EIA预计到2021年底将达到4.60亿桶，较上月预测下降790万桶，该库存水平处于2015-2019年同期库存范围内。',\n",
       " '2020年12月原油进口同比下降15.4%。2020年12月，我国进口原油3847万吨，同比-15.4%。2020年1-12月，我国累计进口原油5.42亿吨，同比增长7.2%。2020年12月，我国原油进口均价为44.05美元/桶。2020年12月，我国成品油出口量590万吨，同比-13.1%；成品油进口量218万吨，净出口量373万吨，同比7.2%。2020年1-12月，我国成品油出口量6186万吨，同比-7.5%；成品油进口量2849万吨，同比-6.8%；净出口量3337万吨，同比-8.1%。',\n",
       " '2020年12月天然气进口同比增长18.0%。2020年12月，我国进口天然气149.3亿方，同比增长18.0%。2020年1-12月，我国累计进口天然气1355.6亿方，同比上升5.1%。12月天然气进口金额为36.07亿美元，同比减少7.2%，按当月平均汇率计算，12月我国天然气进口均价为1.58元/方。',\n",
       " '12月乙烯-石脑油价差环比持续改善。2020年12月，在我们跟踪的19种石化产品中，有10种产品价差环比改善，值得关注的是其中乙烯-石脑油价差环比上涨8.3%，同比增加236.6%，延续上月升势。此外，丙烯-石脑油价差同比增长178.9%，丁二烯-石脑油价差同比增长155.5%，丙烯-1.2*丙烷价差同比增长172.1%，甲醇-1.5*无烟煤价差同比增长127.3%，环比上涨32.1%。',\n",
       " '责任编辑：                                                                张学坤                                                                ',\n",
       " '\\n\\n\\n\\n\\n ']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['new_content'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['format_pub_time'] = raw_df['pub_time'].apply(lambda x:datetime.strptime(x,'%Y-%m-%d'))\n",
    "raw_df['new_contet'] = raw_df['content'].apply(lambda x:wash_energy_china(x,{'class':'mainBody'}))\n",
    "raw_df['source'] = 'http://cn.energychinaforum.com/news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['new_contet'] = raw_df['content'].apply(lambda x:wash_energy_china(x,{'class':'mainBody'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['source'] = 'http://cn.energychinaforum.com/news'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_energy_year(x,attrs):\n",
    "    '''wash energy year\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "    #     if desc.name == 'img' and desc.has_attr('src'):\n",
    "    # #         contents.append(desc)\n",
    "    #         contents.append(desc)\n",
    "        if desc.name=='p' and re.search(r'First published',desc.text):\n",
    "            break\n",
    "        elif desc.name == 'p' and len(desc.text)>1:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://theenergyyear.com/news/oil-down-over-rising-covid-19-cases/'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['format_pub_time'] = raw_df['pub_time']. \\\n",
    "    apply(lambda x :datetime.strptime(x.replace('-','').strip(),'%B %d, %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_class_name = {\n",
    "    'energy_year':{'class':\"page-interviews\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['new_content'] = raw_df['content'] \\\n",
    "    .apply(lambda x:wash_energy_year(x,div_class_name['energy_year']))\n",
    "\n",
    "raw_df['source'] = 'https://theenergyyear.com/news/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://d3jmgibn6sgz2k.cloudfront.net/wp-content/uploads/2015/11/22222104/iran.jpg'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['preview_img_link'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate_offshore_img_content(raw_df):\n",
    "    '''concatet the img link with the news content\n",
    "    '''\n",
    "    \n",
    "    for i in range(len(raw_df['new_content'])):\n",
    "        raw_df['new_content'].values[i].insert(0,raw_df['img_content'].values[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_src_img(x):\n",
    "    '''change src of main image\n",
    "    '''\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    img_soup = soup.img\n",
    "    try:\n",
    "        img_soup.attrs['src'] = img_soup.attrs['data-src']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return img_soup\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_offshore_tech(x,attrs):\n",
    "\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "            break\n",
    "    #         contents.append(desc)\n",
    "    #         contents.append(desc)\n",
    "        elif desc.name == 'p' and len(desc.text)>1:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u'').strip())\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['new_content'] = raw_df['content']. \\\n",
    "        apply(lambda x:wash_offshore_tech(x,{'class':'c-post-single__content'}))\n",
    "raw_df['img_content'] = raw_df['categories'].apply(lambda x:change_src_img(x))\n",
    "concate_offshore_img_content(raw_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<img src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\" data-src=\"https://www.offshore-technology.com/wp-content/uploads/sites/6/2021/01/oil-4713386_1280.jpg\" alt=\"Oil prices inch up despite rising concerns over fuel demand\" class=\"c-post-figure__image lazyload\">'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['categories'] = None\n",
    "raw_df['author'] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2021-01-19\n",
       "1   2021-01-15\n",
       "2   2021-01-18\n",
       "3   2021-01-19\n",
       "4   2021-01-18\n",
       "5   2021-01-15\n",
       "6   2021-01-18\n",
       "Name: pub_time, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['format_put_time'] = raw_df['pub_time'].apply(lambda x: datetime.strptime(x,'%d %b %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_datetime = pre_data['content'].apply(lambda x:wash_rig_zone(x,{'class':\"divArticleText\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = raw_df['preview_img_link'].apply(lambda x:BeautifulSoup(x,'lxml')).apply(lambda x:x.img if x else None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['format_pub_time'] = raw_df['pub_time'] \\\n",
    "            .apply(lambda x:datetime.strptime(x,'%A, %B %d, %Y') if x else x)\n",
    "raw_df['new_content'] = raw_df['content'].apply(lambda x:wash_rig_zone(x,{'class':\"divArticleText\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['new_content'] = raw_df['content']. \\\n",
    "        apply(lambda x:wash_offshore_tech(x,{'class':'c-post-single__content'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['new_content'].values[0].insert(0,raw_df['content_img'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"Oil prices inch up despite rising concerns over fuel demand\" class=\"c-post-figure__image lazyload\" data-src=\"https://www.offshore-technology.com/wp-content/uploads/sites/6/2021/01/oil-4713386_1280.jpg\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\"/>,\n",
       " 'Brent oil prices have edged up slightly in spite of rising concerns that renewed Covid-19 pandemic lockdowns could affect global fuel consumption.',\n",
       " 'Brent crude rose by $0.20, or 0.4%, to reach $54.95 a barrel by 03:51 GMT while US oil increased by $0.17, or 0.3%, to reach $52.19 a barrel, reported Reuters.',\n",
       " 'Oil settlement transaction was not made on 18 January in the US as a result of a public holiday.',\n",
       " 'According to data released on Monday, China’s refinery output increased 3% to a new record last year.',\n",
       " 'Australia’s CMC Markets chief market strategist Michael McCarthy was quoted by the news agency as saying: “Yesterday’s data out of China was a positive for oil prices.”',\n",
       " 'OANDA senior market analyst Jeffrey Halley was quoted by Reuters as saying: “Like other asset classes, oil has received a gentle US stimulus tailwind in Asia.”',\n",
       " 'ANZ Research analysts were cited by the news agency as saying that concerns are being raised about the reduced fuel sales in India in January 2021 from December 2020, as well as a surge in Covid-19 cases in Japan and China that could result in reduced oil demand.',\n",
       " 'ANZ analysts said that the oil prices have also been supported by additional supply cuts by Saudi Arabia in the next two months.',\n",
       " 'The move is expected to reduce global inventories by 1.1 million barrels a day in the first quarter of this year.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['new_content'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_df)):\n",
    "    raw_df['new_content'].values[i]. \\\n",
    "                    insert(0,raw_df['content_img'].values[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"Oil prices inch up despite rising concerns over fuel demand\" class=\"c-post-figure__image lazyload\" data-src=\"https://www.offshore-technology.com/wp-content/uploads/sites/6/2021/01/oil-4713386_1280.jpg\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\"/>,\n",
       " 'Brent oil prices have edged up slightly in spite of rising concerns that renewed Covid-19 pandemic lockdowns could affect global fuel consumption.',\n",
       " 'Brent crude rose by $0.20, or 0.4%, to reach $54.95 a barrel by 03:51 GMT while US oil increased by $0.17, or 0.3%, to reach $52.19 a barrel, reported Reuters.',\n",
       " 'Oil settlement transaction was not made on 18 January in the US as a result of a public holiday.',\n",
       " 'According to data released on Monday, China’s refinery output increased 3% to a new record last year.',\n",
       " 'Australia’s CMC Markets chief market strategist Michael McCarthy was quoted by the news agency as saying: “Yesterday’s data out of China was a positive for oil prices.”',\n",
       " 'OANDA senior market analyst Jeffrey Halley was quoted by Reuters as saying: “Like other asset classes, oil has received a gentle US stimulus tailwind in Asia.”',\n",
       " 'ANZ Research analysts were cited by the news agency as saying that concerns are being raised about the reduced fuel sales in India in January 2021 from December 2020, as well as a surge in Covid-19 cases in Japan and China that could result in reduced oil demand.',\n",
       " 'ANZ analysts said that the oil prices have also been supported by additional supply cuts by Saudi Arabia in the next two months.',\n",
       " 'The move is expected to reduce global inventories by 1.1 million barrels a day in the first quarter of this year.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['new_content'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_offshore_tech(x,attrs):\n",
    "\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "            break\n",
    "    #         contents.append(desc)\n",
    "    #         contents.append(desc)\n",
    "        elif desc.name == 'p' and len(desc.text)>1:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u'').strip())\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"c-post-single__content c-post-typography\">\\n                   <p>Brent oil prices have edged up slightly in spite of rising concerns that renewed Covid-19 pandemic lockdowns could affect global fuel consumption.\\n</p><p>Brent crude rose by $0.20, or 0.4%, to reach $54.95 a barrel by 03:51 GMT while US oil increased by $0.17, or 0.3%, to reach $52.19 a barrel, reported Reuters.\\n</p><p>Oil settlement transaction was not made on 18 January in the US as a result of a public holiday.\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t</p><div id=\"resultnew\"></div>\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\n<p>According to data released on Monday, China’s refinery output increased 3% to a new record last year.\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t            \\n</p><p>Australia’s CMC Markets chief market strategist Michael McCarthy was quoted by the news agency as saying: “Yesterday’s data out of China was a positive for oil prices.”<br></p><div class=\"dianomi_video\" data-dianomi-video-id=\"4675\" id=\"dv_4675\" style=\"margin: 0 auto; max-width: 800px;\"></div>\\n<p>OANDA senior market analyst Jeffrey Halley was quoted by Reuters as saying: “Like other asset classes, oil has received a gentle US stimulus tailwind in Asia.”\\n</p><p>ANZ Research analysts were cited by the news agency as saying that concerns are being raised about the reduced fuel sales in India in January 2021 from December 2020, as well as a surge in Covid-19 cases in Japan and China that could result in reduced oil demand.\\n</p><p>ANZ analysts said that the oil prices have also been supported by additional supply cuts by Saudi Arabia in the next two months.\\n</p><p>The move is expected to reduce global inventories by 1.1 million barrels a day in the first quarter of this year.\\t\\t\\t\\t\\t</p><div id=\"resultnew_secondary\">\\n\\t\\t\\t\\t                    <aside class=\"c-in-post-report new-tmt u-mb-5 u-px-0 u-py-0\">\\n                     \\n\\n                       <article class=\"c-in-post-report__article\">\\n                        <div class=\"c-in-post-report__wrapper u-border-0 u-px-0 u-py-0\">\\n                           <figure class=\"c-post-figure c-post-figure--4-3 c-post-figure--vertical c-post-figure--vertical tmt-img hide-for-small-only\">\\n                            <a href=\"https://hot-topics.globaldata.com/reports/tech-media-and-telecom-themes-2021-thematic-research/\" class=\"c-post-figure__link c-post-figure__image-container\" target=\"_blank\">\\n                              <img src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\" data-src=\"/wp-content/themes/goodlife-wp-B2B/assets/img/tmt-banner.png\" alt=\"Covid-19 chart\" class=\"c-post-figure__image lazyload\">\\n                            </a>\\n                          </figure> \\n\\n                          <div class=\"c-in-post-report__content u-pt-5\">\\n\\t\\t\\t\\t\\t\\t   <h6>Thematic Reports</h6>\\n\\t\\t\\t\\t\\t\\t\\t<h5 class=\"u-mt-0\">Are you worried about the pace of innovation in your industry?</h5>\\n\\t\\t\\t\\t\\t\\t\\t<p class=\"c-in-post-report__tagline u-mb-4 u-mt-2\">GlobalData\\'s TMT Themes 2021 Report tells you everything you need to know about disruptive tech themes and which companies are best placed to help you digitally transform your business.</p>\\n\\n                            <a href=\"https://hot-topics.globaldata.com/reports/tech-media-and-telecom-themes-2021-thematic-research/\" class=\"button primary  u-pt-3 u-py-3\" target=\"_blank\">Find out more</a>\\n                          </div>\\n                        </div>\\n\\n                       <!-- <p class=\"c-in-post-report__tagline\">\\n                          <span>Latest report from <img src=\"https://ind-covid-kgi-verdict-network.pantheonsite.io/pharmaceutical-technology/wp-content/uploads/sites/10/2020/07/globaldata-logo.png\" alt=\"\" /></span>\\n\\n                          <span class=\"c-in-post-report__tagline-extra show-for-medium\">\\n                            Browse over 50,000 other reports on our store.\\n                          </span>\\n\\n                          <a href=\"https://store.globaldata.com/\" target=\"_blank\">Visit GlobalData Store</a>\\n                        </p> -->\\n                      </article>\\n                    </aside>\\n\\t\\t\\t\\t\\t</div>\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n<div id=\"Sgpollsputhere\"></div>\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\n \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n    <div id=\"resultnew_third\"></div>             \\n\\t    \\n                \\t   \\n\\t   <!--<aside class=\"c-in-post-companies preview-lat-2019\" style=\"display:none;\"> -->\\n\\t   <aside class=\"c-in-post-companies preview-lat-2019\">\\n\\t<h4 class=\"c-in-post-report__title u-border-top u-pt-4 \">Related Companies</h4>\\n\\t\\t\\n    <div class=\"company-hover-tracking company-hover-data\" id=\"company11708\" data-url=\"https://www.offshore-technology.com/contractors/design-engineering-construction/beta-sa/\">\\n\\t<div class=\"activator\">\\n\\t\\t<article class=\"c-in-post-post__article\">\\n\\t\\t\\t<div class=\"c-post-content fxl-figbtt\">\\n\\t\\t\\t<a href=\"https://www.offshore-technology.com/contractors/design-engineering-construction/beta-sa/\">\\n               <h3 class=\"c-post-content__title\"> \\n                        BETA</h3></a>\\n                                       <p class=\"c-post-content__excerpt\">\\n                Chemical, Petrochemical and Oil and Gas Equipment Manufacture            </p>\\n        \\t\\t\\t\\t<div class=\"c-post-content__meta-after\">\\n\\t\\t\\t\\t\\t<span class=\"c-post-content__publish-date\">28 Aug 2020</span>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</div>\\n\\t\\t\\t<figure class=\"fxl-figbl\">                          \\n<img src=\"https://www.offshore-technology.com/wp-content/uploads/sites/6/2017/09/main-906.jpg\">\\t\\t\\t\\t\\n\\t\\t\\t\\t<div class=\"vis-compblock\">\\n\\t\\t\\t\\t\\t<a id=\"#\" class=\"primary hollow button expanded\" href=\"https://www.offshore-technology.com/contractors/design-engineering-construction/beta-sa/\">Visit Profile</a>\\n\\t\\t\\t\\t</div>                 \\n\\t\\t\\t</figure>\\n\\t\\t</article>\\n\\t</div>\\n</div>\\n\\t\\t\\t\\t\\t  \\t\\n    <div class=\"company-hover-tracking company-hover-data\" id=\"company10123\" data-url=\"https://www.offshore-technology.com/contractors/pipes/ats/\">\\n\\t<div class=\"activator\">\\n\\t\\t<article class=\"c-in-post-post__article\">\\n\\t\\t\\t<div class=\"c-post-content fxl-figbtt\">\\n\\t\\t\\t<a href=\"https://www.offshore-technology.com/contractors/pipes/ats/\">\\n               <h3 class=\"c-post-content__title\"> \\n                        Acute Technological Services</h3></a>\\n                                       <p class=\"c-post-content__excerpt\">\\n                Worldwide Engineering and Welding for the Offshore Industry            </p>\\n        \\t\\t\\t\\t<div class=\"c-post-content__meta-after\">\\n\\t\\t\\t\\t\\t<span class=\"c-post-content__publish-date\">28 Aug 2020</span>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</div>\\n\\t\\t\\t<figure class=\"fxl-figbl\">                          \\n<img src=\"https://www.offshore-technology.com/wp-content/uploads/sites/6/2017/09/1-ats.jpg\">\\t\\t\\t\\t\\n\\t\\t\\t\\t<div class=\"vis-compblock\">\\n\\t\\t\\t\\t\\t<a id=\"#\" class=\"primary hollow button expanded\" href=\"https://www.offshore-technology.com/contractors/pipes/ats/\">Visit Profile</a>\\n\\t\\t\\t\\t</div>                 \\n\\t\\t\\t</figure>\\n\\t\\t</article>\\n\\t</div>\\n</div>\\n\\t\\t\\t\\t\\t  \\t\\n    <div class=\"company-hover-tracking company-hover-data\" id=\"company9146\" data-url=\"https://www.offshore-technology.com/contractors/installation/marine-fenders/\">\\n\\t<div class=\"activator\">\\n\\t\\t<article class=\"c-in-post-post__article\">\\n\\t\\t\\t<div class=\"c-post-content fxl-figbtt\">\\n\\t\\t\\t<a href=\"https://www.offshore-technology.com/contractors/installation/marine-fenders/\">\\n               <h3 class=\"c-post-content__title\"> \\n                        Marine Fenders International</h3></a>\\n                                       <p class=\"c-post-content__excerpt\">\\n                Foam-Filled Marine Fenders and Offshore Buoys            </p>\\n        \\t\\t\\t\\t<div class=\"c-post-content__meta-after\">\\n\\t\\t\\t\\t\\t<span class=\"c-post-content__publish-date\">28 Aug 2020</span>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t</div>\\n\\t\\t\\t<figure class=\"fxl-figbl\">                          \\n<img src=\"https://www.offshore-technology.com/wp-content/uploads/sites/6/2017/09/main-715.jpg\">\\t\\t\\t\\t\\n\\t\\t\\t\\t<div class=\"vis-compblock\">\\n\\t\\t\\t\\t\\t<a id=\"#\" class=\"primary hollow button expanded\" href=\"https://www.offshore-technology.com/contractors/installation/marine-fenders/\">Visit Profile</a>\\n\\t\\t\\t\\t</div>                 \\n\\t\\t\\t</figure>\\n\\t\\t</article>\\n\\t</div>\\n</div>\\n\\t\\t\\t\\t\\t                      </aside>\\t\\t\\t\\n                    \\n\\n    \\n \\n                    \\n                  </div>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['content'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2021-01-15T00:00:00.000000000')"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data['preview_img_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_drill_contractor(x):\n",
    "    contents=[]\n",
    "    res = ast.literal_eval(x) \n",
    "    for e in res:\n",
    "        soup = BeautifulSoup(e,'lxml')\n",
    "        contents.append(soup.text.replace(u'\\xa0', u''))\n",
    "        \n",
    "    return contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_gas = pd.read_sql_table('natural_gas',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_rig_zone(x,attrs):\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "    #         contents.append(desc)\n",
    "            contents.append(desc)\n",
    "        elif desc.name == 'p' and desc.text ==\"Other oil-market news:\":\n",
    "            break\n",
    "        elif desc.name== 'p' and re.search(r'To contact the author',desc.text):\n",
    "            break\n",
    "        elif desc.name == 'p' and len(desc.text)>1:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "            \n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      January 14, 2021\n",
       "1      January 14, 2021\n",
       "2      January 13, 2021\n",
       "3      January 14, 2021\n",
       "4      January 13, 2021\n",
       "            ...        \n",
       "64    December 21, 2020\n",
       "65    December 18, 2020\n",
       "66    December 18, 2020\n",
       "67    December 21, 2020\n",
       "68    December 21, 2020\n",
       "Name: pub_time, Length: 69, dtype: object"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_gas['pub_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_con = natural_gas['content'].apply(lambda x:wash_inen_tech(x,{'class':'article-body'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "eneregy_voice = pd.read_sql_table('energy_voice_pro',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_pub_time</th>\n",
       "      <th>format_crawl_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2020-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2020-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2020-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>2021-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12986</th>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>2021-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12987</th>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>2021-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12988</th>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>2021-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12989</th>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>2021-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12990 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      format_pub_time format_crawl_time\n",
       "0          2020-12-30        2020-12-30\n",
       "1          2020-12-30        2020-12-30\n",
       "2          2020-12-30        2020-12-30\n",
       "3          2020-12-29        2020-12-30\n",
       "4          2020-12-29        2020-12-30\n",
       "...               ...               ...\n",
       "12985      2021-01-19        2021-01-20\n",
       "12986      2021-01-19        2021-01-20\n",
       "12987      2021-01-19        2021-01-20\n",
       "12988      2021-01-20        2021-01-20\n",
       "12989      2021-01-20        2021-01-20\n",
       "\n",
       "[12990 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eneregy_voice[['format_pub_time','format_crawl_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = return_no_processed_df('energy_voice','energy_voice_pro', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>pre_title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_time</th>\n",
       "      <th>preview_img_link</th>\n",
       "      <th>content</th>\n",
       "      <th>categories</th>\n",
       "      <th>crawl_time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>3298</td>\n",
       "      <td>UK offshore wind decommissioning costs already...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mark Lammey</td>\n",
       "      <td>27/11/2019</td>\n",
       "      <td>https://wpcluster.dctdigital.com/energyvoice/w...</td>\n",
       "      <td>&lt;div class=\"entry-content\"&gt;\\n\\t\\t\\t\\t&lt;figure c...</td>\n",
       "      <td>Decom</td>\n",
       "      <td>12/30/2020 11:26</td>\n",
       "      <td>https://www.energyvoice.com/oilandgas/north-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>3574</td>\n",
       "      <td>N-Sea wins contracts worth £11.6m in Middle East</td>\n",
       "      <td>None</td>\n",
       "      <td>Allister Thomas</td>\n",
       "      <td>28/10/2019</td>\n",
       "      <td>https://wpcluster.dctdigital.com/energyvoice/w...</td>\n",
       "      <td>&lt;div class=\"entry-content\"&gt;\\n\\t\\t\\t\\t&lt;figure c...</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>12/30/2020 11:28</td>\n",
       "      <td>https://www.energyvoice.com/oilandgas/middle-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>4464</td>\n",
       "      <td>EnerMech appoints new chief executive</td>\n",
       "      <td>None</td>\n",
       "      <td>Allister Thomas</td>\n",
       "      <td>17/07/2019</td>\n",
       "      <td>https://wpcluster.dctdigital.com/energyvoice/w...</td>\n",
       "      <td>&lt;div class=\"entry-content\"&gt;\\n\\t\\t\\t\\t&lt;figure c...</td>\n",
       "      <td>Oil &amp; Gas</td>\n",
       "      <td>12/30/2020 11:33</td>\n",
       "      <td>https://www.energyvoice.com/oilandgas/203768/e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>6539</td>\n",
       "      <td>Your chance to shape North Sea skills strategy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>05/12/2018</td>\n",
       "      <td>https://wpcluster.dctdigital.com/energyvoice/w...</td>\n",
       "      <td>&lt;div class=\"entry-content\"&gt;\\n\\t\\t\\t\\t&lt;figure c...</td>\n",
       "      <td>North Sea</td>\n",
       "      <td>12/30/2020 11:46</td>\n",
       "      <td>https://www.energyvoice.com/oilandgas/north-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>7031</td>\n",
       "      <td>Powerful Potential: Growth Opportunities in Af...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>23/10/2018</td>\n",
       "      <td>https://wpcluster.dctdigital.com/energyvoice/w...</td>\n",
       "      <td>&lt;div class=\"entry-content\"&gt;\\n\\t\\t\\t\\t&lt;figure c...</td>\n",
       "      <td>Africa</td>\n",
       "      <td>12/30/2020 11:49</td>\n",
       "      <td>https://www.energyvoice.com/oilandgas/africa/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title pre_title  \\\n",
       "3297  3298  UK offshore wind decommissioning costs already...      None   \n",
       "3573  3574   N-Sea wins contracts worth £11.6m in Middle East      None   \n",
       "4463  4464              EnerMech appoints new chief executive      None   \n",
       "6538  6539     Your chance to shape North Sea skills strategy      None   \n",
       "7030  7031  Powerful Potential: Growth Opportunities in Af...      None   \n",
       "\n",
       "               author    pub_time  \\\n",
       "3297      Mark Lammey  27/11/2019   \n",
       "3573  Allister Thomas  28/10/2019   \n",
       "4463  Allister Thomas  17/07/2019   \n",
       "6538             None  05/12/2018   \n",
       "7030             None  23/10/2018   \n",
       "\n",
       "                                       preview_img_link  \\\n",
       "3297  https://wpcluster.dctdigital.com/energyvoice/w...   \n",
       "3573  https://wpcluster.dctdigital.com/energyvoice/w...   \n",
       "4463  https://wpcluster.dctdigital.com/energyvoice/w...   \n",
       "6538  https://wpcluster.dctdigital.com/energyvoice/w...   \n",
       "7030  https://wpcluster.dctdigital.com/energyvoice/w...   \n",
       "\n",
       "                                                content   categories  \\\n",
       "3297  <div class=\"entry-content\">\\n\\t\\t\\t\\t<figure c...        Decom   \n",
       "3573  <div class=\"entry-content\">\\n\\t\\t\\t\\t<figure c...  Middle East   \n",
       "4463  <div class=\"entry-content\">\\n\\t\\t\\t\\t<figure c...    Oil & Gas   \n",
       "6538  <div class=\"entry-content\">\\n\\t\\t\\t\\t<figure c...    North Sea   \n",
       "7030  <div class=\"entry-content\">\\n\\t\\t\\t\\t<figure c...       Africa   \n",
       "\n",
       "            crawl_time                                                url  \n",
       "3297  12/30/2020 11:26  https://www.energyvoice.com/oilandgas/north-se...  \n",
       "3573  12/30/2020 11:28  https://www.energyvoice.com/oilandgas/middle-e...  \n",
       "4463  12/30/2020 11:33  https://www.energyvoice.com/oilandgas/203768/e...  \n",
       "6538  12/30/2020 11:46  https://www.energyvoice.com/oilandgas/north-se...  \n",
       "7030  12/30/2020 11:49  https://www.energyvoice.com/oilandgas/africa/1...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_no_processed_df(table_name, pro_table_name, engine):\n",
    "    '''\n",
    "    compare with two table extract such row has not processed\n",
    "    '''\n",
    "    ori_df = pd.read_sql_table(table_name, engine)\n",
    "    pro_df = pd.read_sql_table(pro_table_name, engine, index_col='id')\n",
    "    \n",
    "#     print(orid_df.head(),pro_df.head())\n",
    "    ## column id has been processed\n",
    "    id_list = pro_df.orig_id.values.tolist()\n",
    "#     print(id_list,len(id_list))\n",
    "\n",
    "    # # if len(ori_df) == len(pro_df)\n",
    "    # if len(id_list) == 0:\n",
    "    #     return ori_df\n",
    "    # else:\n",
    "#     print(id_list)\n",
    "    return ori_df[~(ori_df['id'].isin(id_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table_pair' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-4dc7a778cf2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sql = f\"\"\"UPDATE {table_pair[1]} \n\u001b[0m\u001b[1;32m      2\u001b[0m                         SET {table_pair[1]}.field_keyword = (\n\u001b[1;32m      3\u001b[0m                             \u001b[0mSELECT\u001b[0m \u001b[0mtemp_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield_keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mFROM\u001b[0m \u001b[0mtemp_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtable_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mWHERE\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtable_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table_pair' is not defined"
     ]
    }
   ],
   "source": [
    "sql = f\"\"\"UPDATE news_oil_oe_pro \n",
    "                        SET news_oil_oe_pro.field_keyword = (\n",
    "                            SELECT temp_table.field_keyword\n",
    "                            FROM temp_table,news_oil_oe_pro \n",
    "                            WHERE temp_table.id = news_oil_oe_pro.id\n",
    "\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_pro = ['news_oil_oe_pro','world_oil_pro','hart_energy_pro','cnpc_news_pro','oil_and_gas_pro',\n",
    "                      'oilfield_tech_pro','in_en_storage_pro','jpt_latest_pro','energy_voice_pro','gulf_oil_gas_pro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_oil_oe_pro\n",
      "world_oil_pro\n",
      "hart_energy_pro\n",
      "cnpc_news_pro\n",
      "oil_and_gas_pro\n",
      "oilfield_tech_pro\n",
      "in_en_storage_pro\n",
      "jpt_latest_pro\n",
      "energy_voice_pro\n",
      "gulf_oil_gas_pro\n"
     ]
    }
   ],
   "source": [
    "for table in table_name_pro:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world_oil_pro has been processed\n",
      "hart_energy_pro has been processed\n",
      "cnpc_news_pro has been processed\n",
      "oil_and_gas_pro has been processed\n",
      "oilfield_tech_pro has been processed\n",
      "in_en_storage_pro has been processed\n",
      "jpt_latest_pro no need to process\n",
      "energy_voice_pro has been processed\n",
      "gulf_oil_gas_pro has been processed\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    test =pd.read_sql_table(table_name_pro[i],engine,index_col='id')\n",
    "    drop_ed = test.drop_duplicates(subset=['url'])\n",
    "    drop_ed = drop_ed.drop_duplicates(subset=['title'])\n",
    "    # drop_ed.to_sql()\n",
    "    if len(drop_ed) == len(test):\n",
    "        print(table_name_pro[i],'no need to process')\n",
    "    else:\n",
    "        drop_ed.to_sql(table_name_pro[i],engine,if_exists='replace')\n",
    "        print(table_name_pro[i],'has been processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_stream = pd.read_sql_table('offshore_energy',engine,index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"wp-content\">\\n    \\n<p><strong>Elon Musk’s SpaceX, an aerospace manufacturer and space transportation services company, reportedly bought two Valaris rigs last year to convert them into floating launchpads for its Starship rockets. </strong></p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img src=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500.jpg\" alt=\"Valaris 8500 rig - Valaris\" class=\"wp-image-419609\" srcset=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500.jpg 673w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500-300x259.jpg 300w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20140033/VALARIS-8500-151x130.jpg 151w\" sizes=\"(max-width: 673px) 100vw, 673px\"><figcaption>Valaris 8500 rig; Source: Valaris</figcaption></figure>\\n\\n\\n\\n<p>According to a <a rel=\"noreferrer noopener\" aria-label=\"Tuesday report by CNBC (opens in a new tab)\" href=\"https://www.cnbc.com/2021/01/19/spacex-bought-former-valaris-oil-rigs-to-build-starship-launchpads.html\" target=\"_blank\">Tuesday report by CNBC</a>, SpaceX bought two Valaris rigs, Valaris 8500 and Valaris 8501, to support the enormous Starship rockets that the company is developing.</p>\\n\\n\\n\\n<p>Before they were bought, the two rigs were preservation stacked in the U.S. Gulf of Mexico, Valaris’ fleet status report shows. They were built in 2008 and 2009, respectively.  </p>\\n\\n\\n\\n<p>Now, CNBC reported, the two rigs have been renamed Deimos and Phobos and they are located in the Port of Brownsville, near SpaceX’s Starship development facility in Boca Chica, Texas.</p>\\n\\n\\n\\n<p>Public records show that the two semi-submersible drilling rigs were sold for $3.5 million each before <a rel=\"noreferrer noopener\" aria-label=\"Valaris filed for Chapter 11 (opens in a new tab)\" href=\"https://www.offshore-energy.biz/valaris-declares-chapter-11-bankruptcy/\" target=\"_blank\">Valaris filed for Chapter 11</a> bankruptcy in August last year in an attempt to restructure its debt.</p>\\n\\n\\n<div class=\"section\">\\n\\t<div class=\"block block-related-article align-wide\">\\n\\t\\t<div class=\"block__header\">\\n\\t\\t\\t<h2 class=\"section__title section__title--bordered\">\\n\\t\\t\\t\\tRelated Article\\n\\t\\t\\t</h2>\\n\\t\\t</div>\\n\\t\\t\\t\\t\\t\\n\\n<div class=\"card-rich card-small \">\\n\\t<span class=\"card__lazyload card-rich__image\" style=\"background-image: url(\\'https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2020/08/20094958/Valaris-1024x676.jpg\\');\">\\n\\n\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\t\\t<div class=\"card-rich__element card-rich__time-ago\">\\n\\t\\t\\t\\t<span class=\"screen-reader-text\">Posted:</span> 5 months ago\\n\\t\\t\\t</div>\\n\\t\\t\\t</span>\\n\\n\\t<div class=\"card-rich__content\">\\n\\t\\t\\n\\n\\t\\t<h3 class=\"card-rich__title\">\\n\\t\\t\\t<a href=\"https://www.offshore-energy.biz/valaris-declares-chapter-11-bankruptcy/\" class=\"card-small__link\" aria-label=\"Read more about Valaris declares Chapter 11 bankruptcy\">\\n\\t\\t\\t\\tValaris declares Chapter 11 bankruptcy\\n\\t\\t\\t</a>\\n\\t\\t</h3>\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"card-rich__element card-rich__meta\">\\n\\t\\t\\t\\t\\t<span class=\"screen-reader-text\">Categories:</span>\\n\\t\\t\\t\\t\\t<ul class=\"card-category-list no-list\">\\n\\t\\t\\t\\t\\t\\t<li class=\"card-category-list__item\">Business &amp; Finance</li>\\t\\t\\t\\t\\t</ul>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t\\n\\t\\t<div class=\"card__element card-rich__time-ago\">\\n\\t\\t\\t<span class=\"screen-reader-text\">Posted:</span> 5 months ago\\n\\t\\t</div>\\n\\t</div>\\n</div>\\n\\t\\t\\t</div>\\n</div>\\n\\n\\n\\n<p>Following the Chapter 11 filing, the rig owner received a notice of immediate <a rel=\"noreferrer noopener\" aria-label=\" (opens in a new tab)\" href=\"https://www.offshore-energy.biz/nyse-to-delist-valaris-stock-following-chapter-11-filing/\" target=\"_blank\">suspension of trading</a> and delisting of common stock from the New York Stock Exchange (NYSE).</p>\\n\\n\\n\\n<p>Effective 19 August 2020, the company’s common stock started trading on the OTC Pink marketplace under the symbol “VALPQ.”</p>\\n\\n\\n\\n<p>In late September 2020, <a rel=\"noreferrer noopener\" aria-label=\"Valaris gained access to additional liquidity (opens in a new tab)\" href=\"https://www.offshore-energy.biz/valaris-gains-access-to-additional-liquidity/\" target=\"_blank\">Valaris gained access to additional liquidity</a> following the execution of a new term loan credit agreement. </p>\\n\\n\\n\\n<p>According to SpaceX’s website, <a href=\"https://www.spacex.com/vehicles/starship/\" target=\"_blank\" rel=\"noreferrer noopener\" aria-label=\"Starship (opens in a new tab)\">Starship</a> spacecraft and Super Heavy rocket (collectively referred to as Starship) represent a fully reusable transportation system designed to carry both crew and cargo to Earth orbit, the Moon, Mars and beyond.</p>\\n\\n\\n\\n<p>The company’s Starship SN8 had a test flight last December.</p>\\n\\n\\n\\n<p>As detailed by CNBC, the two rigs were bought in July last year by limited liability corporation Lone Star Mineral Development, which was incorporated in June 2020 and registered in the name of SpaceX CFO <strong>Bret Johnsen</strong>.</p>\\n\\n\\n\\n<p>Offshore Energy has reached out to Valaris seeking confirmation about the sale of the two rigs but the rig owner declined to comment. </p>\\n\\n\\n\\n<figure class=\"wp-block-image size-large\"><img src=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501.jpg\" alt=\"Valaris 8501 rig\" class=\"wp-image-419628\" srcset=\"https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501.jpg 680w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501-300x259.jpg 300w, https://cdn.offshorewind.biz/wp-content/uploads/sites/6/2021/01/20145037/VALARIS-8501-151x130.jpg 151w\" sizes=\"(max-width: 680px) 100vw, 680px\"><figcaption>Valaris 8501 rig; Source: Valaris</figcaption></figure>\\n\\n\\n\\n<p>In related news, U.S. oil company <a rel=\"noreferrer noopener\" aria-label=\"Occidental Petroleum (opens in a new tab)\" href=\"https://www.offshore-energy.biz/occidental-doing-more-than-tesla-to-reduce-carbon-emissions/\" target=\"_blank\">Occidental Petroleum</a> claims that it is doing more than Tesla, an American electric vehicle and clean energy company led by Elon Musk, to reduce greenhouse gas emissions.</p>\\n\\n\\n\\n<p>The statement reflects Occidental’s attempt to build up its carbon management business in response to investor demands over climate change.</p>\\n\\n</div>'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_stream['content'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div data-io-article-url=\"https://www.upstreamonline.com/people/africa-awaits-mercenary-outfit-executive-outcomes-is-reborn/2-1-921836\" class=\"article-body\"><p data-element-type=\"body-first\" class=\"body-first\">Eeben Barlow, South Africa’s fabled \"soldier of fortune\", has revived Executive Outcomes (EO), a private military contractor (PMC) that, between 1989 and its dissolution 10 years later, brought the mercenary business out of the shadows and into the limelight.</p> <div type=\"\" componenttype=\"\" href=\"/v1/content/2-1-685c4d6628e523863068978b44f260b3\" rel=\"inline\" source=\"drpublish\" class=\"card inline factbox float-right\"><div class=\"card-body\"><div class=\"ff-flama fs-md text-uppercase border-bottom mb-0 d-flex justify-content-between card-title\">SIGN UP FOR OUR NEW ENERGY TRANSITION NEWSLETTER<svg aria-hidden=\"true\" focusable=\"false\" data-prefix=\"fal\" data-icon=\"chevron-down\" class=\"svg-inline--fa fa-chevron-down fa-w-14\" role=\"img\" xmlns=\"http://www.w3.org/2000/svg\" viewbox=\"0 0 448 512\"><path fill=\"currentColor\" d=\"M443.5 162.6l-7.1-7.1c-4.7-4.7-12.3-4.7-17 0L224 351 28.5 155.5c-4.7-4.7-12.3-4.7-17 0l-7.1 7.1c-4.7 4.7-4.7 12.3 0 17l211 211.1c4.7 4.7 12.3 4.7 17 0l211-211.1c4.8-4.7 4.8-12.3.1-17z\"></path></svg></div> <div class=\"d-none d-sm-block mt-2\"><!----> <div class=\"body ff-flama fs-sm\"><p>Gain valuable insight into the global oil and gas industry\\'s energy transition from <i><b>Accelerate</b></i>, the new weekly newsletter from <i>Upstream</i> and <i>Recharge</i>.<br> <a href=\"https://rechargenews.us1.list-manage.com/subscribe?u=9ce2040dca4d38f9282025975&amp;id=15f1e05c69\" target=\"_blank\">Sign up here</a>.</p></div></div></div></div> <p>Rather than operating below the radar, South Africa-based EO was a high-profile group that operated globally, but was heavily involved in Africa.</p> <p>In 1993, EO was tasked by Angola’s state oil company Sonangol to protect oil facilities in Soyo, and was later asked by then-president Eduardo dos Santos’s MPLA government to train its soldiers, a move that helped turn the tide against the forces of Jonas Savimbi’s UNITA opposition movement.</p> <span componenttype=\"\" href=\"/v1/content/2-1-857587\" rel=\"inline\" source=\"drpublish\" class=\"dn-inline-relations-item\"><div class=\"card inline news float-left\"><div class=\"card-body\"><a href=\"/news/2-1-857587\" class=\"text-reset card-link\"><!---->\\n  \\n  <figure image-src=\"https://images-global.nhst.tech/image/Wms0M1VtY2oycjlOd1N5d2RoUTM5OXJ5MmM1VHBHeVU2TERmeFlKZllkTT0=/nhst/binary/1568120d881e1e76fe93a1319e782910\" class=\"mb-2\"><div class=\"img-wrapper \"><img src=\"https://static-global.nhst.tech/resources/landscape.gif\" sizes=\"(min-width: 576px) 300px, 300px\" class=\"progressive-image\"></div> <!----></figure> <div class=\"ff-flama fs-md fw-medium mb-3 col-black card-title\">Mozambique port near giant LNG schemes falls to Islamist insurgents</div> <!----></a> <a href=\"/news/2-1-857587\" class=\"ff-flama fs-sm lh-12 float-right card-link\"><!---->\\n  Read more\\n   <!----></a></div></div></span> <p>EO was also heavily involved in the civil war in Sierra Leone in the 1990s.</p> <p>Other work secured by the PMC included covert surveillance in Namibia and Botswana for diamond miner De Beers, as well as military training in Mozambique, Malawi, Zambia and Uganda.</p> <p>Executive Outcomes was dissolved in 1998, although Barlow states on his LinkedIn page that \"contrary to the false media reports, EO was never forced to close its doors by the SA government.\"</p> <p>However, EO\\'s demise came at a time when South Africa’s government brought in legislation to regulate domestic PMCs, meaning they could only work for foreign governments if Pretoria rubber-stamped the arrangement.</p> <span componenttype=\"\" href=\"/v1/content/2-1-854522\" rel=\"inline\" source=\"drpublish\" class=\"dn-inline-relations-item\"><div class=\"card inline news float-left\"><div class=\"card-body\"><a href=\"/news/2-1-854522\" class=\"text-reset card-link\"><!---->\\n  \\n  <figure image-src=\"https://images-global.nhst.tech/image/WTN1MS8vRmdjczZCaXNzVFg3bXR1bDJYd0RMUWdJWkxSYXhKdjRjUWhWaz0=/nhst/binary/b1429f3307450db2fc8b753789a6dc8b\" class=\"mb-2\"><div class=\"img-wrapper \"><img src=\"https://static-global.nhst.tech/resources/landscape.gif\" sizes=\"(min-width: 576px) 300px, 300px\" class=\"progressive-image\"></div> <!----></figure> <div class=\"ff-flama fs-md fw-medium mb-3 col-black card-title\">\\'More virulent and more dangerous\\': US warns of Islamic State involvement in Mozambique insurgency</div> <!----></a> <a href=\"/news/2-1-854522\" class=\"ff-flama fs-sm lh-12 float-right card-link\"><!---->\\n  Read more\\n   <!----></a></div></div></span> <p>Barlow later set up STTEP, another PMC — which has worked with Nigeria’s government to counter the Boko Haram extremists — before recently stepping down as chairman.</p> <p>He has also found time to write a book — \"The War For Africa: Conflict, Crime, Corruption &amp; Foreign Interests\" — published in November.</p> <p>Then, last week, on his Facebook page, Barlow announced the “rebirth” of EO “after some consideration” and apparently at the behest of African governments who approached him after he reduced his involvement in STTEP.</p> <p>He wrote that EO has put in place strategic partnerships with two companies that “have a likewise reputation for adding value to governments... Executives Outcomes will once again provide successful African solutions, by Africans, for African problems.”</p> <span componenttype=\"\" href=\"/v1/content/1-1-1120094\" rel=\"inline\" source=\"escenic\" class=\"dn-inline-relations-item\"><div class=\"card inline news float-left\"><div class=\"card-body\"><a href=\"/news/1-1-1120094\" class=\"text-reset card-link\"><!---->\\n  \\n  <figure image-src=\"https://images-global.nhst.tech/image/eDF3WjNDV1dOekpiZUsvMUxscTYvQT09/nhst/binary/e3ea8d7e94b0ba0c787de4cf149eb74c\" class=\"mb-2\"><div class=\"img-wrapper \"><img src=\"https://static-global.nhst.tech/resources/landscape.gif\" sizes=\"(min-width: 576px) 300px, 300px\" class=\"progressive-image\"></div> <!----></figure> <div class=\"ff-flama fs-md fw-medium mb-3 col-black card-title\">SinoTech blasts \\'mercenary\\' allegations</div> <!----></a> <a href=\"/news/1-1-1120094\" class=\"ff-flama fs-sm lh-12 float-right card-link\"><!---->\\n  Read more\\n   <!----></a></div></div></span> <p>Maybe his first port of call could be northern Mozambique where an Islamist insurgency could yet threaten gas investments in the country.</p> <span componenttype=\"\" href=\"/v1/content/2-1-795996\" rel=\"inline\" source=\"drpublish\" class=\"dn-inline-relations-item\"><div class=\"card inline news float-left\"><div class=\"card-body\"><a href=\"/news/2-1-795996\" class=\"text-reset card-link\"><!---->\\n  \\n  <figure image-src=\"https://images-global.nhst.tech/image/S2RoTDFnckpYV21idlAwSU10SlpNUWoxSlhxMFMxcDdrdVUvMGxzVjd6RT0=/nhst/binary/a24abd559d678348e71276c741a74d24\" class=\"mb-2\"><div class=\"img-wrapper \"><img src=\"https://static-global.nhst.tech/resources/landscape.gif\" sizes=\"(min-width: 576px) 300px, 300px\" class=\"progressive-image\"></div> <!----></figure> <div class=\"ff-flama fs-md fw-medium mb-3 col-black card-title\">Warning over Afungi militant attack danger in Mozambique</div> <!----></a> <a href=\"/news/2-1-795996\" class=\"ff-flama fs-sm lh-12 float-right card-link\"><!---->\\n  Read more\\n   <!----></a></div></div></span> <p>Barlow is primed for the barrage of vilification that will come his way, but warned critics that part of EO’s “mission” will be to expose media and intelligence actors who “thrive on lying for secret payments” and investigate academics and scholars “that create fiction and publish deception\".</p> <p>Strap in for the ride!</p> <p>* Article updated to incorporate extra information on EO\\'s dissolution. </p></div>'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_stream['content'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(up_stream['content'].values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(up_stream['content'].values[0],'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_content =up_stream['content'].apply(lambda x: wash_upstream(x,attrs={'class':\"article-body\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_content.values[5] is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find('div',attrs={'class':\"article-body\"})\n",
    "\n",
    "def wash_upstream(x,attrs):\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    if soup:\n",
    "    #     break\n",
    "        ancestor = soup.find('div', attrs=attrs)\n",
    "#         img_src = None\n",
    "        for desc in ancestor.descendants:\n",
    "            if desc.name == 'p' :\n",
    "                contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "    if len(contents)>1:\n",
    "        return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_stream['new_content'] = up_stream['content'].apply(lambda x: wash_upstream(x,attrs={'class':'article-body'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-48a1d28ff9ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# up_stream['format_pub_time']= up_stream['pub_time'].apply(lambda x:datetime.strptime(x,'%d %B %Y %H:%M') \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#                                             if x is not None else x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mup_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_content'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mup_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwash_upstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'article-body'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mup_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-194-48a1d28ff9ae>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#                                             if x is not None else x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mup_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_content'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mup_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwash_upstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'article-body'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mup_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-165-443fb7cc47bd>\u001b[0m in \u001b[0;36mwash_upstream\u001b[0;34m(x, attrs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwash_upstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mrejections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         for (self.markup, self.original_encoding, self.declared_html_encoding,\n\u001b[0m\u001b[1;32m    343\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains_replacement_characters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m              self.builder.prepare_markup(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mprepare_markup\u001b[0;34m(self, markup, user_specified_encoding, exclude_encodings, document_declared_encoding)\u001b[0m\n\u001b[1;32m    184\u001b[0m         detector = EncodingDetector(\n\u001b[1;32m    185\u001b[0m             markup, try_encodings, is_html, exclude_encodings)\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_declared_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/bs4/dammit.py\u001b[0m in \u001b[0;36mencodings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# declaration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeclared_encoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             self.declared_encoding = self.find_declared_encoding(\n\u001b[0m\u001b[1;32m    302\u001b[0m                 self.markup, self.is_html)\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_usable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeclared_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/bs4/dammit.py\u001b[0m in \u001b[0;36mfind_declared_encoding\u001b[0;34m(cls, markup, is_html, search_entire_document)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mhtml_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mdeclared_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mdeclared_encoding_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxml_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxml_endpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdeclared_encoding_match\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_html\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mdeclared_encoding_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhtml_endpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# up_stream['format_pub_time']= up_stream['pub_time'].apply(lambda x:datetime.strptime(x,'%d %B %Y %H:%M') \\\n",
    "#                                             if x is not None else x)\n",
    "up_stream['new_content'] = up_stream['content'] \\\n",
    "                .apply(lambda x: wash_upstream(x, attrs={'class':'article-body'}) if x is not None else x)\n",
    "up_stream.dropna(axis=0,subset=['new_content'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5463"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(up_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [data for data in new_con if data is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5412"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1     2020-12-21\n",
       "2     2020-12-23\n",
       "3     2020-12-21\n",
       "4     2020-12-31\n",
       "5     2020-12-28\n",
       "         ...    \n",
       "259   2021-01-14\n",
       "260   2021-01-01\n",
       "261   2021-01-08\n",
       "262   2021-01-14\n",
       "263   2021-01-14\n",
       "Name: pub_time, Length: 263, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drill_con['pub_time'].apply(lambda x:datetime.strptime(x,'%m/%d/%Y')) \\\n",
    "                    .apply(lambda x: x if datetime.now(dt.timezone.utc).date()> x \\\n",
    "                           else datetime.now(dt.timezone.utc).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime(2020,12,12) >datetime(2020,12,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.replace('[','').replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = x.strip('][').split(', ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ast.literal_eval(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_drill_contractor(x):\n",
    "    contents=[]\n",
    "    res = ast.literal_eval(x) \n",
    "    for e in res:\n",
    "        soup = BeautifulSoup(e,'lxml')\n",
    "        contents.append(soup.text)\n",
    "        \n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = drill_con['content'].apply(lambda x:wash_drill_contractor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = drill_con['pub_time'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "46      [BP, Eni, Equinor, Galp, Occidental, Repsol, R...\n",
       "47      [After successfully being converted to a hybri...\n",
       "48      [Odfjell Drilling and CIMC Raffles announced a...\n",
       "49      [Independence Contract Drilling (ICD) announce...\n",
       "50      [Petrobras, working on behalf of the Libra Con...\n",
       "                              ...                        \n",
       "4723    [Neptune Energy announced agreement with Conce...\n",
       "4724    [By Jay Stracke, Editorial Coordinator, In rec...\n",
       "4725    [By Stephen Whitfield, Associate Editor, The I...\n",
       "4726    [Independent Oil and Gas (IOG) recently awarde...\n",
       "4727    [As part of an overall sustainability strategy...\n",
       "Name: content, Length: 4682, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " drill_con['content'].apply(lambda x: wash_drill_contractor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = drill_con['pub_time'] \\\n",
    "                    .apply(lambda x: datetime.strptime(x, \"%b %d, %Y\").strftime('%Y/%m/%d') if x is not None else x) \\\n",
    "                    .apply(lambda x: datetime.strptime(x, \"%Y/%m/%d\") if x is not None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "46     2020-12-17\n",
       "47     2020-12-17\n",
       "48     2021-01-07\n",
       "49     2021-01-04\n",
       "50     2021-01-11\n",
       "          ...    \n",
       "4723   2020-10-08\n",
       "4724   2020-11-05\n",
       "4725   2020-10-27\n",
       "4726   2020-11-03\n",
       "4727   2020-09-18\n",
       "Name: pub_time, Length: 4682, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents=[]\n",
    "# ancestor = soup.find('p')\n",
    "for desc in ancestor.descendants:\n",
    "    if desc.name == 'img' and desc.has_attr('src'):\n",
    "#         contents.append(desc)\n",
    "        contents.append(desc)\n",
    "    elif desc.name == 'p' and len(desc.text)>0:\n",
    "        contents.append(desc.text.replace(u'\\xa0', u''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_inen_tech(x,attrs):\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "    #         contents.append(desc)\n",
    "            contents.append(desc)\n",
    "        elif desc.name == 'p' and len(desc.text)>0:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['近日，中国海洋石油集团有限公司(以下简称“中国海油”)7日对外宣布，中国自主研发的旋转导向和随钻测井系统中的高速率脉冲遥传技术在渤海油田南堡区块实现重要突破，传输速率同比提升24倍，同比提高钻井时效20%。',\n",
       " '这标志着旋转导向和随钻测井系统成功突破“限速”，正式跻身世界前列，为大规模产业化应用“插上翅膀”。十余载磨一剑。由中国海油自主研发的随钻测井及旋转导向钻井系统技术，打破了多年来西方石油公司的垄断。',\n",
       " <img alt=\"\" src=\"https://img.in-en.com/upload/202101/11/09155635236084.png\" title=\"\"/>,\n",
       " '旋转导向钻井和随钻测井系统被业界形象地称为“贪吃蛇”技术，代表着当今世界钻井技术发展的最高水平，被誉为石油钻井技术“皇冠上的明珠”。据介绍，该项技术可以在石油钻井中保持旋转钻进，根据需要及时调整轨迹，实施三维定向井轨迹控制。通过这套系统，地面工程师可以控制地下几千米的钻头“瞄着”油层去，“闻着”油味钻，就好像一条“贪吃蛇”，在地层中穿行。',\n",
       " '中海油服油田技术研究院院长尚捷指出，高速率脉冲遥传技术是旋转导向和随钻测井系统的关键组成，它的重大突破大幅提升了地面工程师接收信息和发送指令的速率，提高了实时数据分辨率和钻井时效，将显著降低油田开发成本。',\n",
       " '传奇故事竟然从车库起步',\n",
       " '2006年年底，尚捷从清华大学精密仪器专业博士毕业，在位于燕郊的中海油服油田技术研究院一间普通会议室里参加一场面试。当时技术中心总工程师卢涛意味深长地问眼前这个年轻人：我们离国际上最新的钻井技术还比较落后，你们能不能下决心干出来？',\n",
       " '彼时29岁的尚捷，戴着眼镜，满身书卷气，一口答应下来。“当时有种无知者无畏的勇气，就感觉我们不能总跟在别人后面打酱油，要有自主的核心技术才硬气。”很快，他就知道要攻克横亘在眼前的这项世界级技术难题，如同摘取皇冠顶尖的明珠。',\n",
       " <img alt=\"\" src=\"https://img.in-en.com/upload/202101/11/09231736236084.png\" title=\"\"/>,\n",
       " '随钻测井和旋转导向钻井技术，是令所有油气企业垂涎不已的高端技术。它能够探入地下，如同一条灵敏贪吃的蛇，把地层中的油藏“吃干榨净”。这一顶级技术一直被3家西方顶尖石油技术公司垄断，只租不卖，中国的石油企业每年都要向其支付高昂的租赁费用。',\n",
       " '尚捷当时组建起一个平均年龄不到30岁的团队。2008年，团队在创业初期只有4间办公室、6台电脑、7名工程师。没有测试仪器的地方，他们把一个停用的车库重新装修，带着兄弟们在里面“苦中作乐”，打趣说要创造中国的“车库传奇”。',\n",
       " '国内无成功先例，国外死死封锁，他带着四五名研发人员夜以继日啃遍资料，寻找各种机会奔走仪修车间、作业现场，在半年时间内吃透设计思路和技术细节，整理编制出20多万字的技术文档和上百张图纸，用了整整一年，推开“贪吃蛇”技术的一道门缝。',\n",
       " '通过几年的不懈努力，尚捷和他的团队突破了10余项关键技术瓶颈，自主设计建造试验测试装置近100种，研究开发出40余种高温电路、数千个机械液压部件、上百万行程序代码。经过上百次改进，“贪吃蛇”系统的第一版样机终于问世。',\n",
       " '尚捷干脆吃住在现场，每天只睡三四个小时。“再坚持下一次井，再坚持打一米”，峰回路转，国产“贪吃蛇”技术最终让这口井“起死回生”。',\n",
       " '尚捷敏锐地意识到，仪器的稳定性问题是“贪吃蛇”占领市场的绊脚石。“贪吃蛇”集合了20多种学科的应用、1000多道高端工艺组装、几百万个代码控制，任何一环都不能掉链子。',\n",
       " '尚捷立下了军令状，他率先建立起闭环的故障关闭管理机制，从故障出发，从作业公司的需求出发，全面升级完善“贪吃蛇”基础型的技术及功能。自仪器应用以来关闭故障近百个，成为“贪吃蛇”在四海站稳脚跟的关键。',\n",
       " '贪吃蛇大获成功',\n",
       " '历经多年技术攻关，中国海油在2014年成功研发中国首套旋转导向和随钻测井系统。尚捷介绍说，该技术问世以来，中国海油已在全球建成5家研发及测试中心，与40余家高校院所建立合作关系，推动旋转导向和随钻测井系统的商业应用规模化和技术研发迭代发展，目前可胜任不同井径、不同地质特性的广泛作业需求。',\n",
       " '2011年实钻试验的成功，宣告“贪吃蛇”研发成功，较行业龙头的差距整整缩短4年。2015年，“贪吃蛇”首次海上试作业一举成功，震动世界钻井技术领域，标志着中国海油成为国内首家、全球第四家完全掌握该项技术的公司。',\n",
       " <img alt=\"\" src=\"https://img.in-en.com/upload/202101/11/09233594236084.png\" title=\"\"/>,\n",
       " '“贪吃蛇”亮相后，国际油服巨头立即改变只租不卖的策略，将高昂的日费大幅降低。这让尚捷更加坚定地认为，外租、分包都是权宜之计，只有拥有自己的核心技术，别人才会真的服你。',\n",
       " '目前，尚捷团队研发的“贪吃蛇”技术产品已在我国主要石油天然气产区实现规模化应用，新技术产品累计实现产值超过100亿元，大幅降低了我国油气勘探开发成本，保障了我国油气增储上产。尚捷团队凭借一系列新成果，获得国家授权专利798项、关键技术国际专利9项。',\n",
       " '并非没有来自外界的高薪诱惑，但在尚捷心中总有一种家国情怀，“总要在自己的国家干事情，这就像一种基因，已经融入血脉中”。',\n",
       " '谈及未来打算，尚捷摊开一张图，上面清晰标识着“贪吃蛇”世界技术阵营，“我们在缩小差距，但前三名的位置一直没有被撼动，对标世界一流，要不断刷新升级‘贪吃蛇’技术到3.0版，我们还要往前冲，别无选择！”',\n",
       " '数据显示，截至2020年底，中国自主研发的旋转导向和随钻测井系统已在国内成功完成520井次的作业，累计钻进50万米，相当于钻穿57座珠穆朗玛峰，作业范围全面覆盖国内海上和主要陆地油气产区。']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inen_tech['content'].apply(lambda x:wash_inen_tech(x,{'id':'content'}))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_oil_price(x,attrs):\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src') \\\n",
    "                and desc.attrs['src'] \\\n",
    "                not in [e.attrs['src'] for e in contents if isinstance(e,Tag)] :\n",
    "    #         contents.append(desc)\n",
    "            contents.append(desc)\n",
    "        elif desc.name == 'p' and not desc.has_attr('class') \\\n",
    "            and not 'a' in [child.name for child in desc.children] \\\n",
    "            and not 'strong' in [child.name for child in desc.children]:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "s= oil_price['content'].apply(lambda x:wash_oil_price(x,{'class':'singleArticle__content'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_energy_pedia(x,attrs):\n",
    "    contents = []\n",
    "#     index_ori= None\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "    #     if desc.name == 'img' and desc.has_attr('src') :\n",
    "    #         contents.append(desc)\n",
    "        if desc.name == 'p' :\n",
    "            contents.append(desc.text)\n",
    "    \n",
    "    try:\n",
    "        index_ori = contents.index('Original article link')\n",
    "        return contents[:index_ori]\n",
    "    except:\n",
    "        return contents\n",
    "    \n",
    "#     index_source = contents.index('Original article link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_content = energy_pedia['content'].\\\n",
    "            apply(lambda x:wash_energy_pedia(x,{'class':'articlepreview'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boskalis has announced the acquisition of all the shares of Rever Offshore’s subsea services business. Rever, formally known as Bibby Offshore, offers a broad range of solutions in the area of subsea construction, inspection, repair and maintenance.',\n",
       " 'Rever has historically operated in the North Sea out of Aberdeen (United Kingdom) and holds a strong track record. Through this transaction, Boskalis will obtain two diving support vessels of which one is fully owned (Rever Polaris) and a second chartered (Rever Topaz). The group employs an onshore staff of around 130 in addition to approx. 220 offshore workers. The 2020 annual revenue is approx. EUR 90 million, most of which is generated through numerous framework agreements. Based on projected cost synergies, the acquisition payback period is expected to be less than three years.',\n",
       " 'Through this acquisition, Boskalis strengthens its current position in the subsea services market in Northwest Europe, Africa and the Middle East and its capabilities to serve both the traditional oil & gas market and the rapidly expanding offshore wind market. On the important North Sea subsea market, Boskalis is now a solid top three player opening up ample opportunities for operational efficiencies and synergies.']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_content[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_ed = test.drop_duplicates(subset=['title','url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_ed.to_sql(table_name_pro[8],engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dups(df_name):\n",
    "    df =pd.read_sql_table(df_name,engine,index_col='id')\n",
    "    droped_df = df.drop_duplicates(subset=['title','url'])\n",
    "    droped_df.to_sql(df_name,engine,if_exists='replace')\n",
    "    print(df_name, 'has been processed')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_content = test['content'].apply(lambda x:wash_gulf_oilgas(x,{'class':'newsbodytext'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'pre_title', 'author', 'pub_time', 'preview_img_link',\n",
       "       'content', 'categories', 'crawl_time', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_gulf_oilgas(x,attrs):\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor=soup.find('div',attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "            #         desc.attrs['src'] = desc.attrs['src']\n",
    "            contents.append(desc)\n",
    "        if isinstance(desc,NavigableString):\n",
    "            contents.append(re.sub(r'\\r\\n','',str(desc)))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_upstream(x,attrs):\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    if soup:\n",
    "    #     break\n",
    "        ancestor = soup.find('div', attrs=attrs)\n",
    "#         img_src = None\n",
    "        for desc in ancestor.descendants:\n",
    "            if desc.name == 'p' :\n",
    "                contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "    if len(contents)>1:\n",
    "        return contents\n",
    "#     else:\n",
    "#         return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = up_stream['pub_time']. \\\n",
    "    apply(lambda x:datetime.strptime(x,'%d %B %Y %H:%S'))\n",
    "#       .strftime('%Y/%m/%d %H:%S') if x is not None else x) \\\n",
    "#     .apply(lambda x:datetime.strptime(x,'%Y/%m/%d %H:%S'))\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_stream['new_content']= up_stream['content'].apply(lambda x:wash_upstream(x,{'class':'article-body'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'pre_title', 'author', 'pub_time', 'preview_img_link',\n",
       "       'content', 'categories', 'crawl_time', 'url', 'new_content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_stream.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_stream.dropna(axis=0,subset=['new_content'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prev_imgs(x):\n",
    "    \n",
    "    soup = BeautifulSoup(x,'lxml')\n",
    "    if soup is not None:\n",
    "        preview_img = soup.find('img').attrs.get('srcset')  \\\n",
    "                            .split(',')[1].strip().split(' ')[0] \\\n",
    "                            if soup.find('img').attrs.get('srcset') else None\n",
    "        main_img = soup.find('img').attrs.get('srcset') \\\n",
    "                        .split(',')[3].strip().split(' ')[0] \\\n",
    "                        if soup.find('img').attrs.get('srcset') else None\n",
    "        \n",
    "    return (preview_img,main_img)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prev_imgs(x):\n",
    "    \n",
    "    main_img = []\n",
    "    soup = BeautifulSoup(x,'lxml')\n",
    "    if soup is not None:\n",
    "        main_img.append(soup.find('img').attrs.get('srcset') \\\n",
    "                        .split(',')[3].strip().split(' ')[0] \\\n",
    "                        if soup.find('img').attrs.get('srcset') else None)\n",
    "        \n",
    "    return main_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://images-global.nhst.tech/image/UHdDaE1XdjNUcWFjMTNtZnJrVTk2K3N4L0tibXEwUzVZOHhRRWxIejIwND0=/nhst/binary/30889b1e8d9016a95f46e2cd259863cb?image_version=360',\n",
       " 'https://images-global.nhst.tech/image/UHdDaE1XdjNUcWFjMTNtZnJrVTk2K3N4L0tibXEwUzVZOHhRRWxIejIwND0=/nhst/binary/30889b1e8d9016a95f46e2cd259863cb?image_version=640')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_prev_imgs(up_stream['preview_img_link'].values[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_img = up_stream['preview_img_link'].apply(lambda x:extract_prev_imgs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = up_stream['preview_img_link']. \\\n",
    "        apply(lambda x:extract_prev_imgs(x) if x is not None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.insert(0,'st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['st', 1, 1, 2, 3]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://images-global.nhst.tech/image/czA1MTVTYWF6N2Rna0gyS1QrVHZXUnAyQ0VzeS9XdHl4T1pQNmgzU3l4bz0=/nhst/binary/e34db12d665c0e9d20902a761c72fa02?image_version=360',\n",
       " 'https://images-global.nhst.tech/image/czA1MTVTYWF6N2Rna0gyS1QrVHZXUnAyQ0VzeS9XdHl4T1pQNmgzU3l4bz0=/nhst/binary/e34db12d665c0e9d20902a761c72fa02?image_version=640')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrac_prev_img(up_stream['preview_img_link'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_energy_voice(x,attrs):\n",
    "    \n",
    "    contents = []\n",
    "    soup = BeautifulSoup(test['content'][0], 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src') and desc.has_attr('srcset'):\n",
    "            contents.append(desc)\n",
    "        elif desc.name == 'p' \\\n",
    "            and not desc.has_attr('class') \\\n",
    "            and not re.search(r'12.50 per month',desc.text) \\\n",
    "            and not desc.parent.attrs.get('id') == 'recommended-popout':\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_oil_gas_process(x,attrs):\n",
    "    '''\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div', attrs=attrs)\n",
    "    for desc in ancestor.descendants:\n",
    "        if desc.name == 'img' and desc.has_attr('src'):\n",
    "            desc.attrs['src'] = 'https://www.oilandgas360.com/'+desc.attrs['src']\n",
    "            contents.append(desc)\n",
    "        elif desc.name == 'p' and not desc.has_attr('class') \\\n",
    "            and not 'a' in [child.name for child in desc.children]:\n",
    "            contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_links(x):\n",
    "    '''extract img_links from content\n",
    "    '''\n",
    "    img_links = []\n",
    "    for ele in x:\n",
    "        if isinstance(ele, Tag):\n",
    "            if ele.name == 'img' and ele.has_attr('src') and ele.has_attr('alt'):\n",
    "                img_link = ele.attrs['src']\n",
    "                if re.match(r'^http', img_link):\n",
    "                    img_links.append((str(img_link), ele.attrs['alt']))\n",
    "\n",
    "    return img_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['content'] = test['content']. \\\n",
    "        apply(lambda x: wash_oil_gas_process(x,{'class':'entry'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['images'] = test['content'].apply(lambda x:extract_img_links(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'descendants'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-beb0780242f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mancestor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'entry'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mancestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescendants\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'img'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'descendants'"
     ]
    }
   ],
   "source": [
    "contents = []\n",
    "soup = BeautifulSoup(test['content'][0], 'lxml')\n",
    "ancestor = soup.find('div', attrs={'class':'entry'})\n",
    "for desc in ancestor.descendants:\n",
    "    if desc.name == 'img' and desc.has_attr('src'):\n",
    "        contents.append(desc)\n",
    "    elif desc.name == 'p' and not desc.has_attr('class') \\\n",
    "        and not 'a' in [child.name for child in desc.children]:\n",
    "        contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['content'] = test['content']. \\\n",
    "            apply(lambda x:wash_process(x,{'itemprop':\"articleBody\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oil_gas_hot():\n",
    "    headers= {'user-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0'}\n",
    "    titles = []\n",
    "    host = 'https://www.oilandgas360.com/'\n",
    "    res = req.get(host,headers =headers)\n",
    "    soup = BeautifulSoup(res.text, 'lxml')\n",
    "    ancestor = soup.find('div',attrs={'class':'main-area'}).descendants\n",
    "    for child in ancestor:\n",
    "        if child.name=='a' and child.has_attr('title'):\n",
    "            titles.append(child.attrs['title'])\n",
    "    titles =set(titles)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_hart_energy_process(x,attrs):\n",
    "    '''\n",
    "    '''\n",
    "    contents = []\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    ancestor = soup.find('div',attrs=attrs)\n",
    "    if ancestor is not None:\n",
    "        for child in [child for child in ancestor.children if not isinstance(child,NavigableString)][:2]:\n",
    "            for desc in child.descendants:\n",
    "                if desc.name == 'img' and desc.has_attr('src'):\n",
    "                    desc.attrs['src'] = 'https://www.hartenergy.com'+desc.attrs['src']\n",
    "                    contents.append(desc)\n",
    "                if desc.name == 'p' and not desc.has_attr('class'):\n",
    "                    contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "                if desc.name == 'div' and desc.has_attr('class') and desc.attrs['class']==\"userAlready\":\n",
    "                    break\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wash_jpt_process(x,attrs):\n",
    "    '''\n",
    "    '''\n",
    "    contents = []\n",
    "    if x is not None:\n",
    "        soup = BeautifulSoup(x, 'lxml')\n",
    "        ancestor = soup.find('div', attrs=attrs)\n",
    "        # if ancestor is not None:\n",
    "        for desc in ancestor.descendants:\n",
    "            if desc.name == 'img' and desc.has_attr('src') and re.search(r'/media',desc.attrs['src'])::\n",
    "                desc.attrs['src'] =  'https://pubs.spe.org'+ desc.attrs['src']\n",
    "                contents.append(desc)\n",
    "            elif desc.name == 'p' and not desc.has_attr('class'):\n",
    "                contents.append(desc.text.replace(u'\\xa0', u''))\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_no_processed_df(table_name, pro_table_name, engine):\n",
    "    '''\n",
    "    compare with two table extract such row has not processed\n",
    "    '''\n",
    "    ori_df = pd.read_sql_table(table_name, engine)\n",
    "    pro_df = pd.read_sql_table(pro_table_name, engine, index_col='id')\n",
    "    ori_df.dropna(subset=['content'],inplace=True)\n",
    "    ori_df.drop_duplicates(subset=['url'],inplace=True)\n",
    "    ori_df.drop_duplicates(subset=['title'],inplace=True)\n",
    "    \n",
    "    \n",
    "#     print(orid_df.head(),pro_df.head())\n",
    "    ## column id has been processed\n",
    "    id_list = pro_df.orig_id.values.tolist()\n",
    "    print(id_list)\n",
    "    print(ori_df['id'].values)\n",
    "    # # if len(ori_df) == len(pro_df)\n",
    "    # if len(id_list) == 0:\n",
    "    #     return ori_df\n",
    "    # else:\n",
    "#     print(id_list)\n",
    "    return ori_df[~(ori_df['id'].isin(id_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460, 465, 469, 474, 477, 482, 484, 486, 489, 492, 494, 495, 496, 497, 499, 500, 501, 502, 503, 504, 505, 507, 508, 509, 510, 511, 512, 513, 516, 517, 518, 519, 525, 526, 531, 535, 543, 552, 554, 556, 565, 576, 578, 580, 581, 582, 584, 587, 589, 595, 650, 12707, 12712, 12714, 12715, 13371, 15217, 15220, 15224, 15256, 15265, 15296, 15326, 15330, 15332, 15498, 15503, 15513, 15594]\n",
      "[15762 15763 15764 15765 15766 15767 15768 15769 15770 15771 15772 15773\n",
      " 15774 15775 15776 15777 15778 15779 15780 15781 15782 15783 15784 15785\n",
      " 15786 15787 15788 15789 15790 15791 15792 15793 15794 15795 15796 15797\n",
      " 15798 15799 15800 15801 15802 15803 15804 15805 15806 15807 15808 15809\n",
      " 15810 15811 15812 15813 15814 15815 15816 15817 15818 15819 15820 15821\n",
      " 15822 15823 15824 15825 15826 15827 15828 15829 15830 15831 15832 15833\n",
      " 15834 15835 15836 15837 15838 15839 15840 15841 15842 15843 15844 15845\n",
      " 15846 15847 15848 15849 15850 15851 15852 15853 15854 15855 15856 15857\n",
      " 15858 15859 15860 15861 15862 15863 15864 15865 15866 15867 15868 15869\n",
      " 15870 15871 15872 15873 15874 15875 15876 15877 15878 15879 15880 15881\n",
      " 15882 15883 15884 15885 15886 15887 15888 15889 15890 15891 15892 15893\n",
      " 15894 15895 15896 15897 15898 15899 15900]\n"
     ]
    }
   ],
   "source": [
    "s =return_no_processed_df('up_stream','up_stream_pro',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 127 entries, 0 to 15155\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                127 non-null    int64 \n",
      " 1   title             127 non-null    object\n",
      " 2   pre_title         124 non-null    object\n",
      " 3   author            127 non-null    object\n",
      " 4   pub_time          127 non-null    object\n",
      " 5   preview_img_link  117 non-null    object\n",
      " 6   content           127 non-null    object\n",
      " 7   categories        127 non-null    object\n",
      " 8   crawl_time        127 non-null    object\n",
      " 9   url               127 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 10.9+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = test['content'].apply(lambda x:wash_hart_energy_process(x,{'class':'article-content-wrapper'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_pro = ['news_oil_oe_pro','world_oil_pro','hart_energy_pro','cnpc_news_pro','oilfield_tech_pro',\\\n",
    "            'oil_and_gas_pro','in_en_storage_pro','jpt_latest_pro','energy_voice_pro','gulf_oil_gas_pro',\\\n",
    "            'energy_pedia_pro','up_stream_pro','oil_price_pro','inen_tech_pro','inen_newenergy_pro',\\\n",
    "            'drill_contractor_pro','rog_tech_pro','natural_gas_pro','rig_zone_pro','offshore_tech_pro',\n",
    "            'energy_year_pro','energy_china_pro','china_five_pro']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pro =  pd.read_sql_table('jpt_latest_pro',engine,columns=['title','format_pub_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' cannot use operands with types dtype('<M8[ns]') and dtype('O')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-8d50d2108e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable_pro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'format_pub_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2021-01-23'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'subtract' cannot use operands with types dtype('<M8[ns]') and dtype('O')"
     ]
    }
   ],
   "source": [
    "table_pro['format_pub_time'].values[0]- datetime.strptime('2021-01-23','%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.timedelta64(-1900800000000000,'ns')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_pro['format_pub_time'].values[0] - np.datetime64(new_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'datetime.datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-8cb9fd2a4261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'datetime.datetime'"
     ]
    }
   ],
   "source": [
    "datetime(np.datetime64(new_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time = datetime.strptime('2021-01-23','%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2021-01-21T00:00:00.000000000')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_pro['format_pub_time'].values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-01-23T00:00:00.000000'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_oil_oe_pro has the lastest of  2021-01-25T00:00:00.000000000\n",
      "world_oil_pro has the lastest of  NaT\n",
      "hart_energy_pro has the lastest of  NaT\n",
      "cnpc_news_pro has the lastest of  2021-01-25T00:00:00.000000000\n",
      "oilfield_tech_pro has the lastest of  2021-01-22T14:00:30.000000000\n",
      "oil_and_gas_pro has the lastest of  NaT\n",
      "in_en_storage_pro has the lastest of  NaT\n",
      "jpt_latest_pro has the lastest of  2021-01-21T00:00:00.000000000\n",
      "energy_voice_pro has the lastest of  2021-01-25T00:00:00.000000000\n",
      "gulf_oil_gas_pro has the lastest of  2021-01-25T00:00:00.000000000\n",
      "energy_pedia_pro has the lastest of  2021-01-09T00:00:00.000000000\n",
      "up_stream_pro has the lastest of  2021-01-21T07:06:00.000000000\n",
      "oil_price_pro has the lastest of  2021-01-22T16:26:00.000000000\n",
      "inen_tech_pro has the lastest of  2021-01-22T00:00:00.000000000\n",
      "inen_newenergy_pro has the lastest of  2021-01-25T00:00:00.000000000\n",
      "drill_contractor_pro has the lastest of  2021-01-21T00:00:00.000000000\n",
      "rog_tech_pro has the lastest of  2021-01-20T00:00:00.000000000\n",
      "natural_gas_pro has the lastest of  2021-01-22T00:00:00.000000000\n",
      "rig_zone_pro has the lastest of  2021-01-24T00:00:00.000000000\n",
      "offshore_tech_pro has the lastest of  2021-01-22T00:00:00.000000000\n",
      "energy_year_pro has the lastest of  2021-01-25T00:00:00.000000000\n",
      "energy_china_pro has the lastest of  2021-01-22T00:00:00.000000000\n",
      "china_five_pro has the lastest of  2021-01-22T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "for table in table_name_pro:\n",
    "    jpt = pd.read_sql_table(table,engine,columns=['title','format_pub_time'])\n",
    "    latesttime = jpt['format_pub_time'].values.max()\n",
    "    print(table,'has the lastest of ',str(latesttime) )\n",
    "#     if jpt['formata_pub_time']>datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_con = jpt['content'].apply(lambda x: wash_process(x,{'class':'articleBodyText'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s ='''<img alt=\"Ashtead Technology chief executive Allan Pirie \n",
    "\n",
    "ABERDEEN, SCOTLAND - SEPTEMBER 02, 2019:\n",
    "Ashtead Technology Westhill Aberdeen. See Press Release from BIG\n",
    "\n",
    "(Photo by Ross Johnston/Newsline Media)\" class=\"attachment-large size-large wp-post-image\" height=\"413\" loading=\"lazy\" sizes=\"(max-width: 620px) 100vw, 620px\" src=\"https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-846x564.jpg\" srcset=\"https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-846x564.jpg 846w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-270x180.jpg 270w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-768x512.jpg 768w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-558x372.jpg 558w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-126x84.jpg 126w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-72x48.jpg 72w\" width=\"620\"/>\n",
    "Ashtead Technology’s boss said yesterday that the firm was “well positioned” for future growth despite the challenges thrown up by Covid-19.\n",
    "Chief executive Allan Pirie said virus-related restrictions meant mobilising people and equipment had been more difficult since last March.\n",
    "But specialist subsea equipment firm, which is headquartered in Westhill, Aberdeenshire, is “continuing to deliver solid financial performance”, he said.\n",
    "The pandemic has forced the company to more quickly integrate its recent acquisitions to streamline and enhance its offering to clients.\n",
    "This has helped Ashtead keep hold of its core oil and gas and marine customers and secure “a raft of new business” in the offshore renewables and decommissioning markets.\n",
    "The company has made five acquisitions since it was taken over by Buckthorn Partners and Arab Petroleum Investments Corporation in 2016.\n",
    "Additions include TES Survey Equipment Services, Forum Subsea Rentals, Aqua-Tech Solutions, Welaptega and Underwater Cutting Solutions.\n",
    "Ashtead now employs more than 170 globally, including 91 in Aberdeenshire.\n",
    "The firm has also “realigned its lending agreements” to reflect its “positive financial position and strong 2021 trading book”.\n",
    "Recent talks with lenders on resetting certain 2021 covenant tests had a positive outcome, a spokeswoman added.\n",
    "The updates followed the publication of parent Bp INV2 Holdco’s accounts for 2019, which showed pre-tax profits of £2.76 million, up from £823,000 in 2018, on revenues of £48m, up 27% year-on-year.\n",
    "<img alt=\"SKILL: RSE supplies products and services to the utility, industrial and energy industries. Picture by Sandy McCook.\" class=\"attachment-flyout-thumb size-flyout-thumb wp-post-image\" height=\"64\" loading=\"lazy\" sizes=\"(max-width: 86px) 100vw, 86px\" src=\"https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2021/01/031PJNO0901MAIN_A_2-Image-1-Read-Only-86x64.jpg\" srcset=\"https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2021/01/031PJNO0901MAIN_A_2-Image-1-Read-Only-86x64.jpg 86w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2021/01/031PJNO0901MAIN_A_2-Image-1-Read-Only-66x48.jpg 66w\" width=\"86\"/>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 're' has no attribute 'pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ce52d1b09276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'<img .*>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 're' has no attribute 'pattern'"
     ]
    }
   ],
   "source": [
    "sub_img = re.(r'<img .*>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = re.sub(r'<img .+/>','',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<img alt=\"Ashtead Technology chief executive Allan Pirie \\n\\nABERDEEN, SCOTLAND - SEPTEMBER 02, 2019:\\nAshtead Technology Westhill Aberdeen. See Press Release from BIG\\n\\n(Photo by Ross Johnston/Newsline Media)\" class=\"attachment-large size-large wp-post-image\" height=\"413\" loading=\"lazy\" sizes=\"(max-width: 620px) 100vw, 620px\" src=\"https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-846x564.jpg\" srcset=\"https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-846x564.jpg 846w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-270x180.jpg 270w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-768x512.jpg 768w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-558x372.jpg 558w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-126x84.jpg 126w, https://wpcluster.dctdigital.com/energyvoice/wp-content/uploads/sites/4/2019/09/031NO2809PJA_Story__2-1-a-Read-Only-72x48.jpg 72w\" width=\"620\"/>\\nAshtead Technology’s boss said yesterday that the firm was “well positioned” for future growth despite the challenges thrown up by Covid-19.\\nChief executive Allan Pirie said virus-related restrictions meant mobilising people and equipment had been more difficult since last March.\\nBut specialist subsea equipment firm, which is headquartered in Westhill, Aberdeenshire, is “continuing to deliver solid financial performance”, he said.\\nThe pandemic has forced the company to more quickly integrate its recent acquisitions to streamline and enhance its offering to clients.\\nThis has helped Ashtead keep hold of its core oil and gas and marine customers and secure “a raft of new business” in the offshore renewables and decommissioning markets.\\nThe company has made five acquisitions since it was taken over by Buckthorn Partners and Arab Petroleum Investments Corporation in 2016.\\nAdditions include TES Survey Equipment Services, Forum Subsea Rentals, Aqua-Tech Solutions, Welaptega and Underwater Cutting Solutions.\\nAshtead now employs more than 170 globally, including 91 in Aberdeenshire.\\nThe firm has also “realigned its lending agreements” to reflect its “positive financial position and strong 2021 trading book”.\\nRecent talks with lenders on resetting certain 2021 covenant tests had a positive outcome, a spokeswoman added.\\nThe updates followed the publication of parent Bp INV2 Holdco’s accounts for 2019, which showed pre-tax profits of £2.76 million, up from £823,000 in 2018, on revenues of £48m, up 27% year-on-year.\\n\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'<img .+/>','',new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
